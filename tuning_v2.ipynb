{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "657f2027-12a1-4c82-9fdf-61f717b92d40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:02:18.452267Z",
     "iopub.status.busy": "2023-10-09T12:02:18.451050Z",
     "iopub.status.idle": "2023-10-09T12:03:25.006893Z",
     "shell.execute_reply": "2023-10-09T12:03:25.005409Z",
     "shell.execute_reply.started": "2023-10-09T12:02:18.452267Z"
    }
   },
   "source": [
    "%pip install keras_tuner\n",
    "%pip install tensorflow\n",
    "%pip install yfinance\n",
    "%pip install pandas_ta\n",
    "%pip install plotly\n",
    "%pip install scikit-learn\n",
    "%pip install pyarrow\n",
    "%pip install fastparquet\n",
    "%pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bfb449-ae34-4adc-baf0-20014faede33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:03:41.346590Z",
     "iopub.status.busy": "2023-10-09T12:03:41.346193Z",
     "iopub.status.idle": "2023-10-09T12:03:45.981224Z",
     "shell.execute_reply": "2023-10-09T12:03:45.980212Z",
     "shell.execute_reply.started": "2023-10-09T12:03:41.346563Z"
    }
   },
   "source": [
    "%pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ebdd33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:43:39.369697Z",
     "iopub.status.busy": "2023-10-09T12:43:39.368223Z",
     "iopub.status.idle": "2023-10-09T12:43:49.466122Z",
     "shell.execute_reply": "2023-10-09T12:43:49.464683Z",
     "shell.execute_reply.started": "2023-10-09T12:43:39.369697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importa librerieUsing TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............=\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Importa librerie\", end=\"\", flush=True)\n",
    "from keras_tuner import HyperModel, RandomSearch, Hyperband, BayesianOptimization\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, Dropout, TimeDistributed, Dense\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.models import Sequential\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras import metrics\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import pandas as pd\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import yfinance as yf\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import numpy as np\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import tensorflow as tf\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import funzioni as fx\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from sklearn.base import clone\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import gc\n",
    "print(\".\", end=\"\", flush=True)\n",
    "gc.enable()\n",
    "import os\n",
    "print(\"=\", end=\"\\n\", flush=True)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d842bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:43:49.470083Z",
     "iopub.status.busy": "2023-10-09T12:43:49.469344Z",
     "iopub.status.idle": "2023-10-09T12:43:49.490557Z",
     "shell.execute_reply": "2023-10-09T12:43:49.488266Z",
     "shell.execute_reply.started": "2023-10-09T12:43:49.469966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "simbolo_test = \"BTG\"\n",
    "simbolo_validazione = \"DHT\"\n",
    "n_simboli_addestramento = 500\n",
    "crea_dati_addestramento = False\n",
    "epochs=50\n",
    "batch_size=5000\n",
    "n_timesteps = 60 # n. barre del periodo passato per la ricerca di pattern, inclusa ultima data disponibile\n",
    "giorni_previsione = 1 # n. barre nel futuro di cui si desidera prevedere il prezzo\n",
    "set_file_x_y = f\"_{n_simboli_addestramento}\"\n",
    "initial_lr = 0.001\n",
    "\n",
    "features_prezzo = [\n",
    "    \"Close\",\n",
    "#    \"EMA_5\", \n",
    "    \"EMA_20\", \n",
    "    \"EMA_50\",\n",
    "    \"Open\",  \n",
    "    \"High\",\n",
    "    \"Low\",\n",
    "    \"PSAR\",\n",
    "    \"SUPERT\", \n",
    "]\n",
    "\n",
    "features_da_scalare_singolarmente = [\n",
    "    \"Volume\",\n",
    "    \"ATR\",\n",
    "    \"PSARaf\",\n",
    "    \"ADX\",\n",
    "]\n",
    "\n",
    "features_meno_piu = [\n",
    "    \"MACDh\",    \n",
    "    \"AROONOSC\",\n",
    "    \"TRIX\",\n",
    "    \"TRIXs\",\n",
    "    \"DM_OSC\",\n",
    "]\n",
    "\n",
    "features_no_scala = [\n",
    "    \"SUPERTd\",  \n",
    "    \"PSARr\"\n",
    "]\n",
    "\n",
    "features_candele = [\n",
    "#    \"CDL_2CROWS\", \"CDL_3BLACKCROWS\", \"CDL_3INSIDE\", \"CDL_3LINESTRIKE\", \"CDL_3OUTSIDE\", \"CDL_3STARSINSOUTH\", \"CDL_3WHITESOLDIERS\", \"CDL_ABANDONEDBABY\", \"CDL_ADVANCEBLOCK\", \"CDL_BELTHOLD\", \"CDL_BREAKAWAY\", \"CDL_CLOSINGMARUBOZU\", \"CDL_CONCEALBABYSWALL\", \"CDL_COUNTERATTACK\", \"CDL_DARKCLOUDCOVER\", \"CDL_DOJI_10_0.1\", \"CDL_DOJISTAR\", \"CDL_DRAGONFLYDOJI\", \"CDL_ENGULFING\", \"CDL_EVENINGDOJISTAR\", \"CDL_EVENINGSTAR\", \"CDL_GAPSIDESIDEWHITE\", \"CDL_GRAVESTONEDOJI\", \"CDL_HAMMER\", \"CDL_HANGINGMAN\", \"CDL_HARAMI\", \"CDL_HARAMICROSS\", \"CDL_HIGHWAVE\", \"CDL_HIKKAKE\", \"CDL_HIKKAKEMOD\", \"CDL_HOMINGPIGEON\", \"CDL_IDENTICAL3CROWS\", \"CDL_INNECK\", \"CDL_INSIDE\", \"CDL_INVERTEDHAMMER\", \"CDL_KICKING\", \"CDL_KICKINGBYLENGTH\", \"CDL_LADDERBOTTOM\", \"CDL_LONGLEGGEDDOJI\", \"CDL_LONGLINE\", \"CDL_MARUBOZU\", \"CDL_MATCHINGLOW\", \"CDL_MATHOLD\", \"CDL_MORNINGDOJISTAR\", \"CDL_MORNINGSTAR\", \"CDL_ONNECK\", \"CDL_PIERCING\", \"CDL_RICKSHAWMAN\", \"CDL_RISEFALL3METHODS\", \"CDL_SEPARATINGLINES\", \"CDL_SHOOTINGSTAR\", \"CDL_SHORTLINE\", \"CDL_SPINNINGTOP\", \"CDL_STALLEDPATTERN\", \"CDL_STICKSANDWICH\", \"CDL_TAKURI\", \"CDL_TASUKIGAP\", \"CDL_THRUSTING\", \"CDL_TRISTAR\", \"CDL_UNIQUE3RIVER\", \"CDL_UPSIDEGAP2CROWS\", \"CDL_XSIDEGAP3METHODS\",\n",
    "]\n",
    "\n",
    "elenco_targets = [\n",
    "#    \"EMA_5\",\n",
    "#    \"EMA_20\", \n",
    "#    \"EMA_50\",\n",
    "    #\"Open\",\n",
    "    #\"High\",\n",
    "    #\"Low\",\n",
    "    \"Target\"\n",
    "]\n",
    "\n",
    "col_features_prezzo = {col: idx for idx, col in enumerate(features_prezzo)}\n",
    "col_features_da_scalare_singolarmente = {col: idx for idx, col in enumerate(features_da_scalare_singolarmente)}\n",
    "col_features_meno_piu = {col: idx for idx, col in enumerate(features_meno_piu)}\n",
    "col_features_no_scala = {col: idx for idx, col in enumerate(features_no_scala)}\n",
    "col_features_candele = {col: idx for idx, col in enumerate(features_candele)}\n",
    "col_targets = {col: idx for idx, col in enumerate(elenco_targets)}\n",
    "n_features = len(col_features_prezzo) + len(col_features_da_scalare_singolarmente) + len(col_features_meno_piu) + len(col_features_no_scala) + len(col_features_candele) \n",
    "n_targets = len(col_targets) \n",
    "\n",
    "class MixedHyperModel(HyperModel):\n",
    "    def __init__(self, n_timesteps, n_features, n_targets, giorni_previsione):\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.n_features = n_features\n",
    "        self.n_targets = n_targets\n",
    "        self.giorni_previsione = giorni_previsione\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "\n",
    "        # Layer LSTM iniziale\n",
    "        model.add(LSTM(hp.Int('lstm_units_1', 50, 500, step=50),\n",
    "                       input_shape=(self.n_timesteps, self.n_features), kernel_initializer='glorot_uniform'))\n",
    "        model.add(RepeatVector(self.giorni_previsione))\n",
    "\n",
    "        # Aggiunta di layer LSTM intermedi\n",
    "        for i in range(hp.Int('num_lstm_layers', 1, 4)):\n",
    "            model.add(LSTM(hp.Int(f'lstm_units_{i+2}', 50, 500, step=50), return_sequences=True,\n",
    "                           kernel_regularizer=l2(hp.Float(f'l2_rate_{i+2}', 0.000001, 5, step=0.001)), kernel_initializer='glorot_uniform'))\n",
    "            model.add(Dropout(hp.Float(f'lstm_dropout_{i+2}', 0, 0.5, step=0.1)))\n",
    "\n",
    "        # Aggiunta di layer Dense\n",
    "        for i in range(hp.Int('num_dense_layers', 1, 4)):\n",
    "            model.add(TimeDistributed(Dense(hp.Int(f'dense_units_{i}', 50, 500, step=50), activation='relu', kernel_initializer='glorot_uniform')))\n",
    "            model.add(Dropout(hp.Float(f'dense_dropout_{i}', 0, 0.5, step=0.1)))\n",
    "\n",
    "        model.add(TimeDistributed(Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform')))\n",
    "\n",
    "        model.compile(optimizer=\"adam\", \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy', \n",
    "                       metrics.Precision(name='precision'), \n",
    "                       metrics.Recall(name='recall'), \n",
    "                       metrics.AUC(name='auc')])\n",
    "        \n",
    "        return model\n",
    "\n",
    "input_shape = (n_timesteps, n_features)\n",
    "output_shape = (giorni_previsione, n_targets)\n",
    "hypermodel = MixedHyperModel(n_timesteps, n_features, n_targets, giorni_previsione)\n",
    "print(\"ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f1e0f91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:43:49.492036Z",
     "iopub.status.busy": "2023-10-09T12:43:49.491702Z",
     "iopub.status.idle": "2023-10-09T12:43:52.955111Z",
     "shell.execute_reply": "2023-10-09T12:43:52.953983Z",
     "shell.execute_reply.started": "2023-10-09T12:43:49.492006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento lista_ticker esistente\n",
      "Caricamento dati ticker validazione\n",
      "Definizione features e target ticker validazione\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"lista_ticker.parquet\"):\n",
    "    print(\"Caricamento lista_ticker esistente\", flush=True)\n",
    "    lista_ticker = pd.read_parquet(\"lista_ticker.parquet\")\n",
    "else:\n",
    "    print(\"Download lista ticker\", flush=True)\n",
    "    lista_ticker = pd.read_parquet(\"Tickers_De_Giro.parquet\")\n",
    "    lista_ticker = lista_ticker.sample(frac=1).reset_index(drop=True)\n",
    "    lista_ticker = lista_ticker.loc[(lista_ticker[\"Ticker\"] != simbolo_test) & (lista_ticker[\"Ticker\"] != simbolo_validazione) & (lista_ticker[\"Categoria\"] != \"D\"), :]\n",
    "    lista_ticker.to_parquet(\"lista_ticker.parquet\")\n",
    "\n",
    "if os.path.exists(\"ticker_val.parquet\"):\n",
    "    print(\"Caricamento dati ticker validazione\", flush=True)\n",
    "    ticker_val = pd.read_parquet(\"ticker_val.parquet\")\n",
    "else:\n",
    "    print(\"Download dati ticker validazione\")\n",
    "    ticker_val = yf.download(simbolo_validazione, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "    ticker_val.index = ticker_val.index.date\n",
    "    print(\"Calcolo indicatori ticker validazione\")\n",
    "    ticker_val = fx.crea_indicatori(ticker_val)\n",
    "    ticker_val.dropna(axis=0, inplace=True)\n",
    "    ticker_val.to_parquet(\"ticker_val.parquet\")\n",
    "\n",
    "print(\"Definizione features e target ticker validazione\", flush=True)\n",
    "idx_val, X_val, Y_val, _ = fx.to_XY(ticker_val, features_prezzo, features_da_scalare_singolarmente, features_meno_piu, features_candele, features_no_scala, elenco_targets, n_timesteps, giorni_previsione, addestramento=True)\n",
    "\n",
    "if os.path.exists(\"indice.npy\"):    \n",
    "    inizio = np.load(\"indice.npy\")\n",
    "    inizio += 1\n",
    "else:\n",
    "    inizio = 0\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df52d98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:43:52.958040Z",
     "iopub.status.busy": "2023-10-09T12:43:52.957266Z",
     "iopub.status.idle": "2023-10-09T12:44:28.228643Z",
     "shell.execute_reply": "2023-10-09T12:44:28.227596Z",
     "shell.execute_reply.started": "2023-10-09T12:43:52.958012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento X e Y\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(f\"dati/X{set_file_x_y}.npy\") and os.path.exists(f\"dati/Y{set_file_x_y}.npy\"):\n",
    "    print(\"Caricamento X e Y\")\n",
    "    X = np.load(f'dati/X{set_file_x_y}.npy')\n",
    "    Y = np.load(f'dati/Y{set_file_x_y}.npy')\n",
    "else:\n",
    "    X = np.zeros((0, n_timesteps, n_features))\n",
    "    #Y = np.zeros((0, giorni_previsione, n_targets)) #togliere in caso di classificazione binaria\n",
    "    Y = np.zeros((0, 1)) #solo per classificazione binaria\n",
    "if crea_dati_addestramento:\n",
    "    lista_x, lista_y = [], []\n",
    "    for i_ticker in range (inizio, n_simboli_addestramento):\n",
    "        nome_simbolo = lista_ticker[\"Ticker\"].iloc[i_ticker]\n",
    "        print(f\"\\033[48;5;42m{i_ticker+1} di {n_simboli_addestramento}: Ticker {nome_simbolo}\\033[0m\")\n",
    "        print(\"Download dati ticker\", flush=True)\n",
    "        try:\n",
    "            ticker = yf.download(nome_simbolo, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "            if ticker[\"Close\"].iloc[-1] >= 1:\n",
    "                ticker.index = ticker.index.date\n",
    "                print(\"Calcolo indicatori ticker\", flush=True)\n",
    "                ticker = fx.crea_indicatori(ticker)\n",
    "                ticker.dropna(axis=0, inplace=True)\n",
    "\n",
    "                print(\"Definizione features e target\", flush=True)\n",
    "                idx, X_train, Y_train, _ = fx.to_XY(ticker, features_prezzo, features_da_scalare_singolarmente, features_meno_piu, features_candele, features_no_scala, elenco_targets, n_timesteps, giorni_previsione, addestramento=True)\n",
    "\n",
    "                print(\"Aggiunta dati a liste X e Y\", flush=True)\n",
    "                lista_x.append(X_train)        \n",
    "                lista_y.append(Y_train)   \n",
    "                if (i_ticker % 100 == 0) and (i_ticker > 0):\n",
    "                    print(\"Concatenamento su X, Y\", flush=True)\n",
    "                    X_arr = np.vstack(lista_x)\n",
    "                    Y_arr = np.vstack(lista_y)\n",
    "                    X = np.vstack((X, X_arr))\n",
    "                    Y = np.vstack((Y, Y_arr))\n",
    "                    print(\"Salvataggio X e Y su file\", flush=True)\n",
    "                    np.save(f'dati/X{set_file_x_y}', X)\n",
    "                    np.save(f'dati/Y{set_file_x_y}', Y)\n",
    "                    np.save(\"indice\", i_ticker)\n",
    "                    lista_x, lista_y = [], []\n",
    "                gc.collect()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            gc.collect()\n",
    "            continue\n",
    "            \n",
    "    print(\"Concatenamento su X, Y\", flush=True)\n",
    "    X_arr = np.vstack(lista_x)\n",
    "    Y_arr = np.vstack(lista_y)\n",
    "    X = np.vstack((X, X_arr))\n",
    "    Y = np.vstack((Y, Y_arr))\n",
    "    print(\"Salvataggio X e Y su file\", flush=True)\n",
    "    np.save(f'dati/X{set_file_x_y}', X)\n",
    "    np.save(f'dati/Y{set_file_x_y}', Y)\n",
    "    np.save(\"indice\", i_ticker)\n",
    "    lista_x, lista_y = [], []\n",
    "\n",
    "    gc.collect()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34bf8d90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:44:28.230002Z",
     "iopub.status.busy": "2023-10-09T12:44:28.229729Z",
     "iopub.status.idle": "2023-10-09T12:44:28.239906Z",
     "shell.execute_reply": "2023-10-09T12:44:28.237702Z",
     "shell.execute_reply.started": "2023-10-09T12:44:28.229976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def rd(hypermodel, X_train, Y_train, X_val, Y_val):\n",
    "    random_tuner = RandomSearch(\n",
    "        hypermodel,\n",
    "        objective='val_loss',\n",
    "        max_trials=50,\n",
    "        executions_per_trial=2,\n",
    "        directory='random_search',\n",
    "        project_name='random_tuning'\n",
    "    )\n",
    "    random_tuner.search_space_summary()\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    random_tuner.search(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, Y_val), callbacks=[early_stopping, reduce_lr])\n",
    "    # Ottieni il miglior modello e i migliori iperparametri\n",
    "    best_model_random = random_tuner.get_best_models(num_models=1)[0]\n",
    "    best_hyperparameters_random = random_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(\"Migliori iperparametri per Random Search:\", best_hyperparameters_random.values)\n",
    "    \n",
    "    return best_model_random, best_hyperparameters_random\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20d4f88c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:44:28.241685Z",
     "iopub.status.busy": "2023-10-09T12:44:28.241355Z",
     "iopub.status.idle": "2023-10-09T12:44:28.250459Z",
     "shell.execute_reply": "2023-10-09T12:44:28.249051Z",
     "shell.execute_reply.started": "2023-10-09T12:44:28.241657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def hb(hypermodel, X_train, Y_train, X_val, Y_val):\n",
    "    hyperband_tuner = Hyperband(\n",
    "        hypermodel,\n",
    "        objective='val_loss',\n",
    "        max_trials=50,\n",
    "        directory='hyperband_search',\n",
    "        project_name='hyperband_tuning'\n",
    "    )\n",
    "    \n",
    "    hyperband_tuner.search_space_summary()\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    hyperband_tuner.search(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, Y_val), callbacks=[early_stopping, reduce_lr])\n",
    "    \n",
    "    best_model_hyperband = hyperband_tuner.get_best_models(num_models=1)[0]\n",
    "    best_hyperparameters_hyperband = hyperband_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(\"Migliori iperparametri per Hyperband:\", best_hyperparameters_hyperband.values)\n",
    "    \n",
    "    return best_model_hyperband, best_hyperparameters_hyperband\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2378b50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:44:28.251646Z",
     "iopub.status.busy": "2023-10-09T12:44:28.251359Z",
     "iopub.status.idle": "2023-10-09T12:44:28.261611Z",
     "shell.execute_reply": "2023-10-09T12:44:28.260717Z",
     "shell.execute_reply.started": "2023-10-09T12:44:28.251616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def bay(hypermodel, X_train, Y_train, X_val, Y_val):\n",
    "    bayesian_tuner = BayesianOptimization(\n",
    "        hypermodel,\n",
    "        objective='val_loss',\n",
    "        max_trials=50,\n",
    "        directory='bayesian_search',\n",
    "        project_name='bayesian_tuning'\n",
    "    )\n",
    "    \n",
    "    bayesian_tuner.search_space_summary()\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    bayesian_tuner.search(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, Y_val), callbacks=[early_stopping, reduce_lr])\n",
    "    \n",
    "    best_model_bayesian = bayesian_tuner.get_best_models(num_models=1)[0]\n",
    "    best_hyperparameters_bayesian = bayesian_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(\"Migliori iperparametri per Bayesian Optimization:\", best_hyperparameters_bayesian.values)\n",
    "    \n",
    "    return best_model_bayesian, best_hyperparameters_bayesian\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a8f563a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T12:44:28.262923Z",
     "iopub.status.busy": "2023-10-09T12:44:28.262658Z",
     "iopub.status.idle": "2023-10-09T13:28:52.889590Z",
     "shell.execute_reply": "2023-10-09T13:28:52.887643Z",
     "shell.execute_reply.started": "2023-10-09T12:44:28.262896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 36m 45s]\n",
      "val_loss: 0.051736876368522644\n",
      "\n",
      "Best val_loss So Far: 0.051736876368522644\n",
      "Total elapsed time: 00h 36m 45s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "500               |300               |lstm_units_1\n",
      "3                 |4                 |num_lstm_layers\n",
      "400               |100               |lstm_units_2\n",
      "2.886             |0.814             |l2_rate_2\n",
      "0.2               |0.2               |lstm_dropout_2\n",
      "2                 |2                 |num_dense_layers\n",
      "350               |100               |dense_units_0\n",
      "0                 |0.2               |dense_dropout_0\n",
      "350               |50                |lstm_units_3\n",
      "3.229             |1e-06             |l2_rate_3\n",
      "0.4               |0                 |lstm_dropout_3\n",
      "300               |50                |lstm_units_4\n",
      "1.517             |1e-06             |l2_rate_4\n",
      "0.3               |0                 |lstm_dropout_4\n",
      "100               |50                |lstm_units_5\n",
      "4.235             |1e-06             |l2_rate_5\n",
      "0.1               |0                 |lstm_dropout_5\n",
      "400               |50                |dense_units_1\n",
      "0.2               |0                 |dense_dropout_1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 13:21:24.092600: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 6043810320 exceeds 10% of free system memory.\n",
      "2023-10-09 13:21:31.430651: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 6043810320 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   6/1295 [..............................] - ETA: 2:23 - loss: 4403.1655 - accuracy: 0.8763WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0433s vs `on_train_batch_end` time: 0.0670s). Check your callbacks.\n",
      "1295/1295 [==============================] - 154s 114ms/step - loss: 61.4556 - accuracy: 0.9832 - val_loss: 0.0789 - val_accuracy: 0.9848 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1295/1295 [==============================] - 146s 112ms/step - loss: 0.0836 - accuracy: 0.9837 - val_loss: 0.0790 - val_accuracy: 0.9848 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1204/1295 [==========================>...] - ETA: 10s - loss: 0.0838 - accuracy: 0.9837"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddestramento\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model, par \u001b[38;5;241m=\u001b[39m \u001b[43mbay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [8], line 15\u001b[0m, in \u001b[0;36mbay\u001b[0;34m(hypermodel, X_train, Y_train, X_val, Y_val)\u001b[0m\n\u001b[1;32m     12\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m     13\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mbayesian_tuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m best_model_bayesian \u001b[38;5;241m=\u001b[39m bayesian_tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m best_hyperparameters_bayesian \u001b[38;5;241m=\u001b[39m bayesian_tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/src/engine/base_tuner.py:230\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/src/engine/base_tuner.py:270\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/src/engine/base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 235\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    238\u001b[0m     ):\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    243\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    251\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/src/engine/hypermodel.py:144\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py:1414\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1414\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1416\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py:1107\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m   logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m-> 1107\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/generic_utils.py:976\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    973\u001b[0m     info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    975\u001b[0m   message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m info\n\u001b[0;32m--> 976\u001b[0m   \u001b[43mio_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m   message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/io_utils.py:77\u001b[0m, in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     75\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(message \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     76\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m   sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py:555\u001b[0m, in \u001b[0;36mOutStream.write\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schedule_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py:461\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_schedule_in_thread\u001b[39m():\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_loop\u001b[38;5;241m.\u001b[39mcall_later(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_interval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_schedule_in_thread\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py:210\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     f()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/zmq/sugar/socket.py:688\u001b[0m, in \u001b[0;36mSocket.send\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    681\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[1;32m    682\u001b[0m             data,\n\u001b[1;32m    683\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[1;32m    684\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    685\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[1;32m    686\u001b[0m         )\n\u001b[1;32m    687\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m--> 688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:742\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:789\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/zmq/backend/cython/checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Addestramento\")\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, Y_resampled = rus.fit_resample(X, Y)\n",
    "model, par = bay(hypermodel, X_resampled, Y_resampled, X_val, Y_val)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e322baa",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-10-09T13:28:52.890618Z",
     "iopub.status.idle": "2023-10-09T13:28:52.891148Z",
     "shell.execute_reply": "2023-10-09T13:28:52.890868Z",
     "shell.execute_reply.started": "2023-10-09T13:28:52.890839Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"tuning.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
