{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1ebdd33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T15:22:47.900636Z",
     "iopub.status.busy": "2023-10-13T15:22:47.899643Z",
     "iopub.status.idle": "2023-10-13T15:22:51.363045Z",
     "shell.execute_reply": "2023-10-13T15:22:51.361927Z",
     "shell.execute_reply.started": "2023-10-13T15:22:47.900579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importa librerie..Using TensorFlow backend\n",
      ".......=\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Importa librerie\", end=\"\", flush=True)\n",
    "import tensorflow as tf\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from sklearn.metrics import f1_score\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import keras_tuner as kt\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import pandas as pd\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import yfinance as yf\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import numpy as np\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import funzioni as fx\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import pickle\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import gc\n",
    "print(\".\", end=\"\", flush=True)\n",
    "gc.enable()\n",
    "import os\n",
    "print(\"=\", end=\"\\n\", flush=True)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a669b3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versione TensorFlow: 2.14.0\n",
      "Versione CUDA: 11.8\n",
      "Versione cuDNN: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Versione TensorFlow:\", tf.__version__)\n",
    "print(\"Versione CUDA:\", tf.sysconfig.get_build_info()['cuda_version'])\n",
    "print(\"Versione cuDNN:\", tf.sysconfig.get_build_info()['cudnn_version'])\n",
    "import psutil\n",
    "\n",
    "def print_memory_usage():\n",
    "    print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07d842bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T15:22:51.365894Z",
     "iopub.status.busy": "2023-10-13T15:22:51.365245Z",
     "iopub.status.idle": "2023-10-13T15:50:40.741887Z",
     "shell.execute_reply": "2023-10-13T15:50:40.740591Z",
     "shell.execute_reply.started": "2023-10-13T15:22:51.365873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento lista_ticker esistente\n",
      "Caricamento dati ticker validazione\n",
      "Definizione features e target ticker validazione\n",
      "2580\n",
      "Caricamento X e Y\n",
      "Tuning\n",
      "Memory usage: 72.9%\n",
      "Memory usage: 72.9%\n",
      "Search space summary\n",
      "Default search space size: 8\n",
      "lstm_units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 50, 'max_value': 500, 'step': 50, 'sampling': 'linear'}\n",
      "num_lstm_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 4, 'step': 1, 'sampling': 'linear'}\n",
      "lstm_units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 50, 'max_value': 500, 'step': 50, 'sampling': 'linear'}\n",
      "l2_rate_2 (Float)\n",
      "{'default': 1e-06, 'conditions': [], 'min_value': 1e-06, 'max_value': 5.0, 'step': 0.001, 'sampling': 'linear'}\n",
      "lstm_dropout_2 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "num_dense_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 4, 'step': 1, 'sampling': 'linear'}\n",
      "dense_units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 50, 'max_value': 500, 'step': 50, 'sampling': 'linear'}\n",
      "dense_dropout_0 (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "300               |300               |lstm_units_1\n",
      "4                 |4                 |num_lstm_layers\n",
      "400               |400               |lstm_units_2\n",
      "3.036             |3.036             |l2_rate_2\n",
      "0.1               |0.1               |lstm_dropout_2\n",
      "3                 |3                 |num_dense_layers\n",
      "300               |300               |dense_units_0\n",
      "0.4               |0.4               |dense_dropout_0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 14:20:36.384751: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 992575200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/enrico/Documenti/Borsa/tuning_v2.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/tuning_v2.ipynb#W4sZmlsZQ%3D%3D?line=352'>353</a>\u001b[0m hypermodel \u001b[39m=\u001b[39m MixedHyperModel(n_timesteps, n_features, n_targets, giorni_previsione)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/tuning_v2.ipynb#W4sZmlsZQ%3D%3D?line=353'>354</a>\u001b[0m print_memory_usage()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/tuning_v2.ipynb#W4sZmlsZQ%3D%3D?line=354'>355</a>\u001b[0m model, par, bayesian_search \u001b[39m=\u001b[39m bay(hypermodel, X, Y, X_val, Y_val)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/tuning_v2.ipynb#W4sZmlsZQ%3D%3D?line=355'>356</a>\u001b[0m print_memory_usage()\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/tuning_v2.ipynb#W4sZmlsZQ%3D%3D?line=357'>358</a>\u001b[0m trials \u001b[39m=\u001b[39m bayesian_search\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mtrials\n",
      "\u001b[1;32m/home/enrico/Documenti/Borsa/tuning_v2.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/tuning_v2.ipynb#W4sZmlsZQ%3D%3D?line=244'>245</a>\u001b[0m bayesian_tuner \u001b[39m=\u001b[39m kt\u001b[39m.\u001b[39mtuners\u001b[39m.\u001b[39mBayesianOptimization(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/tuning_v2.ipynb#W4sZmlsZQ%3D%3D?line=245'>246</a>\u001b[0m     hypermodel,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/tuning_v2.ipynb#W4sZmlsZQ%3D%3D?line=246'>247</a>\u001b[0m     objective\u001b[39m=\u001b[39mobjective,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/tuning_v2.ipynb#W4sZmlsZQ%3D%3D?line=249'>250</a>\u001b[0m     project_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbayesian_tuning\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/tuning_v2.ipynb#W4sZmlsZQ%3D%3D?line=250'>251</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/tuning_v2.ipynb#W4sZmlsZQ%3D%3D?line=252'>253</a>\u001b[0m bayesian_tuner\u001b[39m.\u001b[39msearch_space_summary()    \n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/tuning_v2.ipynb#W4sZmlsZQ%3D%3D?line=254'>255</a>\u001b[0m bayesian_tuner\u001b[39m.\u001b[39;49msearch(X_train, Y_train, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, validation_data\u001b[39m=\u001b[39;49m(X_val, Y_val), callbacks\u001b[39m=\u001b[39;49mcallbacks)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/tuning_v2.ipynb#W4sZmlsZQ%3D%3D?line=256'>257</a>\u001b[0m best_model_bayesian \u001b[39m=\u001b[39m bayesian_tuner\u001b[39m.\u001b[39mget_best_models(num_models\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/tuning_v2.ipynb#W4sZmlsZQ%3D%3D?line=257'>258</a>\u001b[0m best_hyperparameters_bayesian \u001b[39m=\u001b[39m bayesian_tuner\u001b[39m.\u001b[39mget_best_hyperparameters(num_trials\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:233\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 233\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    234\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    235\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:273\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m    272\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    274\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[1;32m    275\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:238\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 238\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    239\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[1;32m    240\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[1;32m    241\u001b[0m     ):\n\u001b[1;32m    242\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    243\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    246\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    254\u001b[0m         )\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    316\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    235\u001b[0m \u001b[39m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/keras/src/engine/training.py:1721\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cluster_coordinator \u001b[39m=\u001b[39m (\n\u001b[1;32m   1712\u001b[0m         tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mcoordinator\u001b[39m.\u001b[39mClusterCoordinator(\n\u001b[1;32m   1713\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\n\u001b[1;32m   1714\u001b[0m         )\n\u001b[1;32m   1715\u001b[0m     )\n\u001b[1;32m   1717\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mscope(), training_utils\u001b[39m.\u001b[39mRespectCompiledTrainableState(  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[1;32m   1718\u001b[0m     \u001b[39mself\u001b[39m\n\u001b[1;32m   1719\u001b[0m ):\n\u001b[1;32m   1720\u001b[0m     \u001b[39m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> 1721\u001b[0m     data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   1722\u001b[0m         x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   1723\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   1724\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1725\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1726\u001b[0m         steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1727\u001b[0m         initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m   1728\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   1729\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1730\u001b[0m         class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   1731\u001b[0m         max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1732\u001b[0m         workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1733\u001b[0m         use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1734\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1735\u001b[0m         steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[1;32m   1736\u001b[0m     )\n\u001b[1;32m   1738\u001b[0m     \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1687\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1688\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   1291\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1292\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1293\u001b[0m     x,\n\u001b[1;32m   1294\u001b[0m     y,\n\u001b[1;32m   1295\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1296\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1297\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[1;32m   1298\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1299\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1300\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1301\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1302\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1303\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[1;32m   1304\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1305\u001b[0m     pss_evaluation_shards\u001b[39m=\u001b[39;49mpss_evaluation_shards,\n\u001b[1;32m   1306\u001b[0m )\n\u001b[1;32m   1308\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:253\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    241\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    242\u001b[0m     x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    251\u001b[0m ):\n\u001b[1;32m    252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(x, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 253\u001b[0m     x, y, sample_weights \u001b[39m=\u001b[39m _process_tensorlike((x, y, sample_weights))\n\u001b[1;32m    254\u001b[0m     sample_weight_modes \u001b[39m=\u001b[39m broadcast_sample_weight_modes(\n\u001b[1;32m    255\u001b[0m         sample_weights, sample_weight_modes\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    258\u001b[0m     \u001b[39m# If sample_weights are not specified for an output use 1.0 as weights.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1163\u001b[0m, in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[39mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001b[1;32m   1161\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n\u001b[0;32m-> 1163\u001b[0m inputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_convert_single_tensor, inputs)\n\u001b[1;32m   1164\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mlist_to_tuple(inputs)\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/tensorflow/python/util/nest.py:629\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnest.map_structure\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    544\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap_structure\u001b[39m(func, \u001b[39m*\u001b[39mstructure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    545\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \n\u001b[1;32m    547\u001b[0m \u001b[39m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 629\u001b[0m   \u001b[39mreturn\u001b[39;00m nest_util\u001b[39m.\u001b[39;49mmap_structure(\n\u001b[1;32m    630\u001b[0m       nest_util\u001b[39m.\u001b[39;49mModality\u001b[39m.\u001b[39;49mCORE, func, \u001b[39m*\u001b[39;49mstructure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    631\u001b[0m   )\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1168\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \n\u001b[1;32m   1073\u001b[0m \u001b[39m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[39m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m \u001b[39mif\u001b[39;00m modality \u001b[39m==\u001b[39m Modality\u001b[39m.\u001b[39mCORE:\n\u001b[0;32m-> 1168\u001b[0m   \u001b[39mreturn\u001b[39;00m _tf_core_map_structure(func, \u001b[39m*\u001b[39;49mstructure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1169\u001b[0m \u001b[39melif\u001b[39;00m modality \u001b[39m==\u001b[39m Modality\u001b[39m.\u001b[39mDATA:\n\u001b[1;32m   1170\u001b[0m   \u001b[39mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[39m*\u001b[39mstructure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1208\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1203\u001b[0m flat_structure \u001b[39m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m   1204\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m   1206\u001b[0m \u001b[39mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1207\u001b[0m     structure[\u001b[39m0\u001b[39m],\n\u001b[0;32m-> 1208\u001b[0m     [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m   1209\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites,\n\u001b[1;32m   1210\u001b[0m )\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1208\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1203\u001b[0m flat_structure \u001b[39m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m   1204\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m   1206\u001b[0m \u001b[39mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1207\u001b[0m     structure[\u001b[39m0\u001b[39m],\n\u001b[0;32m-> 1208\u001b[0m     [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m   1209\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites,\n\u001b[1;32m   1210\u001b[0m )\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1158\u001b[0m, in \u001b[0;36m_process_tensorlike.<locals>._convert_single_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(x\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, np\u001b[39m.\u001b[39mfloating):\n\u001b[1;32m   1157\u001b[0m         dtype \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mfloatx()\n\u001b[0;32m-> 1158\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mconvert_to_tensor(x, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m   1159\u001b[0m \u001b[39melif\u001b[39;00m _is_scipy_sparse(x):\n\u001b[1;32m   1160\u001b[0m     \u001b[39mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion.py:161\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39m@tf_export\u001b[39m\u001b[39m.\u001b[39mtf_export(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m     97\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[1;32m     99\u001b[0m     value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype_hint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m tensor_lib\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    101\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[39m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m   \u001b[39mreturn\u001b[39;00m convert_to_tensor_v2(\n\u001b[1;32m    162\u001b[0m       value, dtype\u001b[39m=\u001b[39;49mdtype, dtype_hint\u001b[39m=\u001b[39;49mdtype_hint, name\u001b[39m=\u001b[39;49mname\n\u001b[1;32m    163\u001b[0m   )\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion.py:171\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m tensor_conversion_registry\u001b[39m.\u001b[39;49mconvert(\n\u001b[1;32m    172\u001b[0m     value, dtype, name, preferred_dtype\u001b[39m=\u001b[39;49mdtype_hint\n\u001b[1;32m    173\u001b[0m )\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:328\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    326\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    327\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[0;32m--> 328\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    281\u001b[0m const_tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39m_create_graph_constant(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[39mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    288\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    290\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/Documenti/Borsa/envborsa/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "simbolo_test = \"BTG\"\n",
    "simbolo_validazione = \"DHT\"\n",
    "n_simboli_addestramento = \"Tutti\"\n",
    "epochs=50\n",
    "batch_size=10000\n",
    "n_timesteps = 60 # n. barre del periodo passato per la ricerca di pattern, inclusa ultima data disponibile\n",
    "giorni_previsione = 1 # n. barre nel futuro di cui si desidera prevedere il prezzo\n",
    "perc_dati = \"dati\"\n",
    "set_file_x_y = f\"_{n_simboli_addestramento}\"\n",
    "initial_lr = 0.001\n",
    "\n",
    "features_prezzo = [\n",
    "    \"Close\",\n",
    "#    \"EMA_5\", \n",
    "    \"EMA_20\", \n",
    "    \"EMA_50\",\n",
    "    \"Open\",  \n",
    "    \"High\",\n",
    "    \"Low\",\n",
    "    \"PSAR\",\n",
    "    \"SUPERT\", \n",
    "]\n",
    "\n",
    "features_da_scalare_singolarmente = [\n",
    "    \"Volume\",\n",
    "    \"ATR\",\n",
    "    \"PSARaf\",\n",
    "    \"ADX\",\n",
    "]\n",
    "\n",
    "features_meno_piu = [\n",
    "    \"MACDh\",    \n",
    "    \"AROONOSC\",\n",
    "    \"TRIX\",\n",
    "    \"TRIXs\",\n",
    "    \"DM_OSC\",\n",
    "]\n",
    "\n",
    "features_no_scala = [\n",
    "    \"SUPERTd\",  \n",
    "    \"PSARr\"\n",
    "]\n",
    "\n",
    "features_candele = [\n",
    "#    \"CDL_2CROWS\", \"CDL_3BLACKCROWS\", \"CDL_3INSIDE\", \"CDL_3LINESTRIKE\", \"CDL_3OUTSIDE\", \"CDL_3STARSINSOUTH\", \"CDL_3WHITESOLDIERS\", \"CDL_ABANDONEDBABY\", \"CDL_ADVANCEBLOCK\", \"CDL_BELTHOLD\", \"CDL_BREAKAWAY\", \"CDL_CLOSINGMARUBOZU\", \"CDL_CONCEALBABYSWALL\", \"CDL_COUNTERATTACK\", \"CDL_DARKCLOUDCOVER\", \"CDL_DOJI_10_0.1\", \"CDL_DOJISTAR\", \"CDL_DRAGONFLYDOJI\", \"CDL_ENGULFING\", \"CDL_EVENINGDOJISTAR\", \"CDL_EVENINGSTAR\", \"CDL_GAPSIDESIDEWHITE\", \"CDL_GRAVESTONEDOJI\", \"CDL_HAMMER\", \"CDL_HANGINGMAN\", \"CDL_HARAMI\", \"CDL_HARAMICROSS\", \"CDL_HIGHWAVE\", \"CDL_HIKKAKE\", \"CDL_HIKKAKEMOD\", \"CDL_HOMINGPIGEON\", \"CDL_IDENTICAL3CROWS\", \"CDL_INNECK\", \"CDL_INSIDE\", \"CDL_INVERTEDHAMMER\", \"CDL_KICKING\", \"CDL_KICKINGBYLENGTH\", \"CDL_LADDERBOTTOM\", \"CDL_LONGLEGGEDDOJI\", \"CDL_LONGLINE\", \"CDL_MARUBOZU\", \"CDL_MATCHINGLOW\", \"CDL_MATHOLD\", \"CDL_MORNINGDOJISTAR\", \"CDL_MORNINGSTAR\", \"CDL_ONNECK\", \"CDL_PIERCING\", \"CDL_RICKSHAWMAN\", \"CDL_RISEFALL3METHODS\", \"CDL_SEPARATINGLINES\", \"CDL_SHOOTINGSTAR\", \"CDL_SHORTLINE\", \"CDL_SPINNINGTOP\", \"CDL_STALLEDPATTERN\", \"CDL_STICKSANDWICH\", \"CDL_TAKURI\", \"CDL_TASUKIGAP\", \"CDL_THRUSTING\", \"CDL_TRISTAR\", \"CDL_UNIQUE3RIVER\", \"CDL_UPSIDEGAP2CROWS\", \"CDL_XSIDEGAP3METHODS\",\n",
    "]\n",
    "\n",
    "elenco_targets = [\n",
    "#    \"EMA_5\",\n",
    "#    \"EMA_20\", \n",
    "#    \"EMA_50\",\n",
    "    #\"Open\",\n",
    "    #\"High\",\n",
    "    #\"Low\",\n",
    "    \"Target\"\n",
    "]\n",
    "\n",
    "col_features_prezzo = {col: idx for idx, col in enumerate(features_prezzo)}\n",
    "col_features_da_scalare_singolarmente = {col: idx for idx, col in enumerate(features_da_scalare_singolarmente)}\n",
    "col_features_meno_piu = {col: idx for idx, col in enumerate(features_meno_piu)}\n",
    "col_features_no_scala = {col: idx for idx, col in enumerate(features_no_scala)}\n",
    "col_features_candele = {col: idx for idx, col in enumerate(features_candele)}\n",
    "col_targets = {col: idx for idx, col in enumerate(elenco_targets)}\n",
    "n_features = len(col_features_prezzo) + len(col_features_da_scalare_singolarmente) + len(col_features_meno_piu) + len(col_features_no_scala) + len(col_features_candele) \n",
    "n_targets = len(col_targets) \n",
    "\n",
    "def set_di_tuning(lista_ticker):\n",
    "    if os.path.exists(\"dati/indice.npy\"):    \n",
    "        inizio = np.load(\"dati/indice.npy\")\n",
    "        print(inizio)\n",
    "    else:\n",
    "        inizio = 0\n",
    "\n",
    "    if os.path.exists(f\"{perc_dati}/X{set_file_x_y}.npy\") and os.path.exists(f\"{perc_dati}/Y{set_file_x_y}.npy\"):\n",
    "        print(\"Caricamento X e Y\")\n",
    "        X = np.load(f'{perc_dati}/X{set_file_x_y}.npy')\n",
    "        Y = np.load(f'{perc_dati}/Y{set_file_x_y}.npy')\n",
    "    else:\n",
    "        X = np.zeros((0, n_timesteps, n_features))\n",
    "        #Y = np.zeros((0, giorni_previsione, n_targets)) #togliere in caso di classificazione binaria\n",
    "        Y = np.zeros((0, 1)) #solo per classificazione binaria\n",
    "    if inizio < n_simboli_addestramento:\n",
    "        lista_x, lista_y = [], []\n",
    "        for i_ticker in range (inizio, n_simboli_addestramento):\n",
    "            nome_simbolo = lista_ticker[\"Ticker\"].iloc[i_ticker]\n",
    "            print(f\"\\033[48;5;42m{i_ticker+1} di {n_simboli_addestramento}: Ticker {nome_simbolo}\\033[0m\")\n",
    "            print(\"Download dati ticker\", flush=True)\n",
    "            try:\n",
    "                ticker = yf.download(nome_simbolo, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "                if ticker[\"Close\"].iloc[-1] >= 1:\n",
    "                    ticker.index = ticker.index.date\n",
    "                    print(\"Calcolo indicatori ticker\", flush=True)\n",
    "                    ticker = fx.crea_indicatori(ticker)\n",
    "                    ticker.dropna(axis=0, inplace=True)\n",
    "\n",
    "                    print(\"Definizione features e target\", flush=True)\n",
    "                    _, X_train, Y_train, _ = fx.to_XY(ticker, features_prezzo, features_da_scalare_singolarmente, features_meno_piu, features_candele, features_no_scala, elenco_targets, n_timesteps, giorni_previsione, addestramento=True)\n",
    "\n",
    "                    print(\"Aggiunta dati a liste X e Y\", flush=True)\n",
    "                    lista_x.append(X_train)  \n",
    "                    print(X_train.shape)      \n",
    "                    lista_y.append(Y_train)   \n",
    "                    print(Y_train.shape)\n",
    "                    if ((i_ticker + 1) % 100 == 0):\n",
    "                        print(\"Concatenamento su X, Y\", flush=True)\n",
    "                        X_arr = np.concatenate(lista_x, axis=0)\n",
    "                        Y_arr = np.concatenate(lista_y, axis=0)\n",
    "                        X = np.concatenate((X, X_arr), axis=0)\n",
    "                        Y = np.concatenate((Y, Y_arr), axis=0)\n",
    "                        print(\"Salvataggio X e Y su file\", flush=True)\n",
    "                        np.save(f'{perc_dati}/X{set_file_x_y}', X)\n",
    "                        np.save(f'{perc_dati}/Y{set_file_x_y}', Y)\n",
    "                        np.save(f\"{perc_dati}/indice\", i_ticker)\n",
    "                        lista_x, lista_y = [], []\n",
    "                    gc.collect()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                gc.collect()\n",
    "                continue\n",
    "                \n",
    "        print(\"Concatenamento su X, Y\", flush=True)\n",
    "        X_arr = np.vstack(lista_x)\n",
    "        Y_arr = np.vstack(lista_y)\n",
    "        X = np.vstack((X, X_arr))\n",
    "        Y = np.vstack((Y, Y_arr))\n",
    "        print(\"Salvataggio X e Y su file\", flush=True)\n",
    "        np.save(f'{perc_dati}/X{set_file_x_y}', X)\n",
    "        np.save(f'{perc_dati}/Y{set_file_x_y}', Y)\n",
    "        np.save(f\"{perc_dati}/indice\", i_ticker)\n",
    "        lista_x, lista_y = [], []\n",
    "\n",
    "        gc.collect()\n",
    "    return X, Y\n",
    "        \n",
    "def addestramento(lista_ticker):\n",
    "    model = tf.keras.models.load_model(\"tuning.keras\")\n",
    "    \n",
    "    if os.path.exists(f\"{perc_dati}/indice_addestramento.npy\"):    \n",
    "        inizio = np.load(f\"{perc_dati}/indice_addestramento.npy\")\n",
    "    else:\n",
    "        inizio = 0\n",
    "    print(\"ok\")\n",
    "    X = np.zeros((0, n_timesteps, n_features))\n",
    "    #Y = np.zeros((0, giorni_previsione, n_targets)) #togliere in caso di classificazione binaria\n",
    "    Y = np.zeros((0, 1)) #solo per classificazione binaria\n",
    "    if inizio < n_simboli_addestramento:\n",
    "        for i_ticker in range (inizio, n_simboli_addestramento):\n",
    "            nome_simbolo = lista_ticker[\"Ticker\"].iloc[i_ticker]\n",
    "            print(f\"\\033[48;5;42m{i_ticker+1} di {n_simboli_addestramento}: Ticker {nome_simbolo}\\033[0m\")\n",
    "            print(\"Download dati ticker\", flush=True)\n",
    "            try:\n",
    "                ticker = yf.download(nome_simbolo, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "                if ticker[\"Close\"].iloc[-1] >= 1:\n",
    "                    ticker.index = ticker.index.date\n",
    "                    print(\"Calcolo indicatori ticker\", flush=True)\n",
    "                    ticker = fx.crea_indicatori(ticker)\n",
    "                    ticker.dropna(axis=0, inplace=True)\n",
    "\n",
    "                    print(\"Definizione features e target\", flush=True)\n",
    "                    _, X_train, Y_train, _ = fx.to_XY(ticker, features_prezzo, features_da_scalare_singolarmente, features_meno_piu, features_candele, features_no_scala, elenco_targets, n_timesteps, giorni_previsione, addestramento=True)\n",
    "\n",
    "                    print(f\"Addestramento simbolo {nome_simbolo}\", flush=True)\n",
    "                    model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, Y_val))\n",
    "                    np.save(f\"{perc_dati}/indice_addestramento\", i_ticker)\n",
    "                    model.save('addestramento.keras')\n",
    "\n",
    "                    gc.collect()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                gc.collect()\n",
    "                continue\n",
    "\n",
    "def weighted_binary_crossentropy(pos_weight):\n",
    "    def loss(y_true, y_pred):\n",
    "        logloss = tf.keras.backend.mean(tf.keras.backend.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "        return logloss * (1 + (pos_weight - 1) * y_true)\n",
    "    return loss\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n",
    "    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n",
    "    true_positives = tf.cast(true_positives, dtype=tf.float64)\n",
    "    predicted_positives = tf.cast(predicted_positives, dtype=tf.float64)\n",
    "    possible_positives = tf.cast(possible_positives, dtype=tf.float64)\n",
    "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
    "    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
    "    f1_val = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "class MixedHyperModel(kt.engine.hypermodel.HyperModel):\n",
    "    def __init__(self, n_timesteps, n_features, n_targets, giorni_previsione):\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.n_features = n_features\n",
    "        self.n_targets = n_targets\n",
    "        self.giorni_previsione = giorni_previsione\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = tf.keras.models.Sequential()\n",
    "\n",
    "        # Layer LSTM iniziale\n",
    "        model.add(tf.keras.layers.LSTM(hp.Int('lstm_units_1', 50, 500, step=50),\n",
    "                       input_shape=(self.n_timesteps, self.n_features), kernel_initializer='glorot_uniform'))\n",
    "        model.add(tf.keras.layers.RepeatVector(self.giorni_previsione))\n",
    "\n",
    "        # Aggiunta di layer LSTM intermedi\n",
    "        for i in range(hp.Int('num_lstm_layers', 1, 4)):\n",
    "            model.add(tf.keras.layers.LSTM(hp.Int(f'lstm_units_{i+2}', 50, 500, step=50), return_sequences=True,\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(hp.Float(f'l2_rate_{i+2}', 0.000001, 5, step=0.001)), kernel_initializer='glorot_uniform'))\n",
    "            model.add(tf.keras.layers.Dropout(hp.Float(f'lstm_dropout_{i+2}', 0, 0.5, step=0.1)))\n",
    "\n",
    "        # Aggiunta di layer Dense\n",
    "        for i in range(hp.Int('num_dense_layers', 1, 4)):\n",
    "            model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(hp.Int(f'dense_units_{i}', 50, 500, step=50), activation='relu', kernel_initializer='glorot_uniform')))\n",
    "            model.add(tf.keras.layers.Dropout(hp.Float(f'dense_dropout_{i}', 0, 0.5, step=0.1)))\n",
    "\n",
    "        model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform')))\n",
    "\n",
    "        model.compile(optimizer=\"adam\", \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy', \n",
    "                       tf.keras.metrics.Precision(name='precision'), \n",
    "                       tf.keras.metrics.Recall(name='recall'), \n",
    "                       tf.keras.metrics.AUC(name='auc')])\n",
    "        \n",
    "        return model\n",
    "\n",
    "input_shape = (n_timesteps, n_features)\n",
    "output_shape = (giorni_previsione, n_targets)\n",
    "hypermodel = MixedHyperModel(n_timesteps, n_features, n_targets, giorni_previsione)\n",
    "\n",
    "class F1Metric(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_data): \n",
    "        self.validation_data = validation_data\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict)\n",
    "        logs['val_f1'] = _val_f1\n",
    "\n",
    "def custom_objective(trial):\n",
    "    val_precision = trial.metrics.get('val_precision')\n",
    "    return val_precision\n",
    "\n",
    "def bay(hypermodel, X_train, Y_train, X_val, Y_val):\n",
    "    bayesian_tuner = kt.tuners.BayesianOptimization(\n",
    "        hypermodel,\n",
    "        objective=objective,\n",
    "        max_trials=50,\n",
    "        directory='bayesian_search',\n",
    "        project_name='bayesian_tuning'\n",
    "    )\n",
    "    \n",
    "    bayesian_tuner.search_space_summary()    \n",
    "\n",
    "    bayesian_tuner.search(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, Y_val), callbacks=callbacks)\n",
    "    \n",
    "    best_model_bayesian = bayesian_tuner.get_best_models(num_models=1)[0]\n",
    "    best_hyperparameters_bayesian = bayesian_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(\"Migliori iperparametri per Bayesian Optimization:\", best_hyperparameters_bayesian.values)\n",
    "    \n",
    "    return bayesian_tuner, best_model_bayesian, best_hyperparameters_bayesian\n",
    "\n",
    "def hb(hypermodel, X_train, Y_train, X_val, Y_val):\n",
    "    hyperband_tuner = kt.tuners.Hyperband(\n",
    "        hypermodel,\n",
    "        objective='val_loss',\n",
    "        max_trials=50,\n",
    "        directory='hyperband_search',\n",
    "        project_name='hyperband_tuning'\n",
    "    )\n",
    "    \n",
    "    hyperband_tuner.search_space_summary()\n",
    "    \n",
    "    hyperband_tuner.search(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, Y_val), callbacks=[early_stopping, reduce_lr])\n",
    "    \n",
    "    best_model_hyperband = hyperband_tuner.get_best_models(num_models=1)[0]\n",
    "    best_hyperparameters_hyperband = hyperband_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(\"Migliori iperparametri per Hyperband:\", best_hyperparameters_hyperband.values)\n",
    "    \n",
    "    return best_model_hyperband, best_hyperparameters_hyperband\n",
    "\n",
    "def rd(hypermodel, X_train, Y_train, X_val, Y_val):\n",
    "    random_tuner = kt.tuners.RandomSearch(\n",
    "        hypermodel,\n",
    "        objective='val_loss',\n",
    "        max_trials=50,\n",
    "        executions_per_trial=2,\n",
    "        directory='random_search',\n",
    "        project_name='random_tuning'\n",
    "    )\n",
    "    random_tuner.search_space_summary()\n",
    "    \n",
    "    random_tuner.search(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, Y_val), callbacks=[early_stopping, reduce_lr])\n",
    "    # Ottieni il miglior modello e i migliori iperparametri\n",
    "    best_model_random = random_tuner.get_best_models(num_models=1)[0]\n",
    "    best_hyperparameters_random = random_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(\"Migliori iperparametri per Random Search:\", best_hyperparameters_random.values)\n",
    "    \n",
    "    return best_model_random, best_hyperparameters_random\n",
    "\n",
    "if not os.path.exists('dati'):\n",
    "    os.makedirs('dati')\n",
    "\n",
    "if os.path.exists(\"lista_ticker.parquet\"):\n",
    "    print(\"Caricamento lista_ticker esistente\", flush=True)\n",
    "    lista_ticker = pd.read_parquet(\"lista_ticker.parquet\")\n",
    "else:\n",
    "    print(\"Download lista ticker\", flush=True)\n",
    "    lista_ticker = pd.read_parquet(\"Tickers_De_Giro.parquet\")\n",
    "    lista_ticker = lista_ticker.sample(frac=1).reset_index(drop=True)\n",
    "    lista_ticker = lista_ticker.loc[(lista_ticker[\"Ticker\"] != simbolo_test) & (lista_ticker[\"Ticker\"] != simbolo_validazione) & (lista_ticker[\"Categoria\"] != \"D\"), :]\n",
    "    lista_ticker.to_parquet(\"lista_ticker.parquet\")\n",
    "\n",
    "if n_simboli_addestramento == 'Tutti': \n",
    "    n_simboli_addestramento = len(lista_ticker)\n",
    "\n",
    "if os.path.exists(f\"{perc_dati}/ticker_val.parquet\"):\n",
    "    print(\"Caricamento dati ticker validazione\", flush=True)\n",
    "    ticker_val = pd.read_parquet(f\"{perc_dati}/ticker_val.parquet\")\n",
    "else:\n",
    "    print(\"Download dati ticker validazione\")\n",
    "    ticker_val = yf.download(simbolo_validazione, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "    ticker_val.index = ticker_val.index.date\n",
    "    print(\"Calcolo indicatori ticker validazione\")\n",
    "    ticker_val = fx.crea_indicatori(ticker_val)\n",
    "    ticker_val.dropna(axis=0, inplace=True)\n",
    "    ticker_val.to_parquet(f\"{perc_dati}/ticker_val.parquet\")\n",
    "\n",
    "if os.path.exists(f\"{perc_dati}/X_val.parquet\") and os.path.exists(f\"{perc_dati}/Y_val.parquet\"):\n",
    "    print(\"Caricamento features e target ticker validazione\", flush=True)\n",
    "    X_val = np.load(f'{perc_dati}/X_val.npy')\n",
    "    Y_val = np.load(f'{perc_dati}/Y_val.npy')\n",
    "else:\n",
    "    print(\"Definizione features e target ticker validazione\", flush=True)\n",
    "    _, X_val, Y_val, _ = fx.to_XY(ticker_val, features_prezzo, features_da_scalare_singolarmente, features_meno_piu, features_candele, features_no_scala, elenco_targets, n_timesteps, giorni_previsione, addestramento=True)\n",
    "    np.save(f'{perc_dati}/X_val', X_val)\n",
    "    np.save(f'{perc_dati}/Y_val', Y_val)\n",
    "\n",
    "objective = kt.Objective(\"val_precision\", direction=\"max\")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "f1_metric = F1Metric(validation_data=(X_val, Y_val))\n",
    "callbacks = [early_stopping, reduce_lr, f1_metric]\n",
    "\n",
    "X, Y = set_di_tuning(lista_ticker)\n",
    "\n",
    "print(\"Tuning\")\n",
    "print_memory_usage()\n",
    "hypermodel = MixedHyperModel(n_timesteps, n_features, n_targets, giorni_previsione)\n",
    "print_memory_usage()\n",
    "model, par, bayesian_search = bay(hypermodel, X, Y, X_val, Y_val)\n",
    "print_memory_usage()\n",
    "\n",
    "trials = bayesian_search.oracle.trials\n",
    "\n",
    "results = []\n",
    "\n",
    "for trial in trials.values():\n",
    "    trial_metrics = trial['metrics']\n",
    "    val_f1 = trial_metrics['val_f1']['observations'][0]['value'] \n",
    "    results.append({\n",
    "        'trial_id': trial['trial_id'],\n",
    "        'val_f1': val_f1,  \n",
    "        'hyperparameters': trial['hyperparameters'].values\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_excel('results_df.xlsx')\n",
    "    \n",
    "model.save(\"tuning\")\n",
    "with open('hyperparameters.pkl', 'wb') as f:\n",
    "    pickle.dump(par, f)\n",
    "\n",
    "#addestramento(lista_ticker)\n",
    "#    \n",
    "print(\"ok\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb662f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
