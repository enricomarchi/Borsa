{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b6824b9-4135-4cee-9834-18ab676a5f55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T14:33:39.669478Z",
     "iopub.status.busy": "2023-10-04T14:33:39.668588Z",
     "iopub.status.idle": "2023-10-04T14:34:35.359264Z",
     "shell.execute_reply": "2023-10-04T14:34:35.358037Z",
     "shell.execute_reply.started": "2023-10-04T14:33:39.669438Z"
    }
   },
   "source": [
    "%pip install keras_tuner\n",
    "%pip install tensorflow\n",
    "%pip install yfinance\n",
    "%pip install pandas_ta\n",
    "%pip install plotly\n",
    "%pip install scikit-learn\n",
    "%pip install pyarrow\n",
    "%pip install fastparquet\n",
    "%pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ba66e-433e-4b9e-983c-672e3458c2dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T14:35:08.408666Z",
     "iopub.status.busy": "2023-10-04T14:35:08.408132Z",
     "iopub.status.idle": "2023-10-04T14:35:12.337028Z",
     "shell.execute_reply": "2023-10-04T14:35:12.336167Z",
     "shell.execute_reply.started": "2023-10-04T14:35:08.408632Z"
    }
   },
   "source": [
    "%pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1ebdd33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T19:57:21.277281Z",
     "iopub.status.busy": "2023-10-04T19:57:21.276839Z",
     "iopub.status.idle": "2023-10-04T19:57:21.354621Z",
     "shell.execute_reply": "2023-10-04T19:57:21.353857Z",
     "shell.execute_reply.started": "2023-10-04T19:57:21.277256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importa librerieUsing TensorFlow backend\n",
      "..............=\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"Importa librerie\", end=\"\", flush=True)\n",
    "from keras_tuner import HyperModel, RandomSearch, Hyperband, BayesianOptimization\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, Dropout, TimeDistributed, Dense\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.models import Sequential\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import pandas as pd\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import yfinance as yf\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import numpy as np\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import tensorflow as tf\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import funzioni as fx\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from sklearn.base import clone\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import gc\n",
    "print(\".\", end=\"\", flush=True)\n",
    "gc.enable()\n",
    "import os\n",
    "print(\"=\", end=\"\\n\", flush=True)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d842bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T19:57:21.356308Z",
     "iopub.status.busy": "2023-10-04T19:57:21.356141Z",
     "iopub.status.idle": "2023-10-04T19:57:21.367333Z",
     "shell.execute_reply": "2023-10-04T19:57:21.366413Z",
     "shell.execute_reply.started": "2023-10-04T19:57:21.356298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "simbolo_test = \"BTG\"\n",
    "simbolo_validazione = \"DHT\"\n",
    "n_simboli_addestramento = 1000\n",
    "epochs=100\n",
    "batch_size=10000\n",
    "n_timesteps = 60 # n. barre del periodo passato per la ricerca di pattern, inclusa ultima data disponibile\n",
    "giorni_previsione = 1 # n. barre nel futuro di cui si desidera prevedere il prezzo\n",
    "set_file_x_y = f\"_{n_simboli_addestramento}\"\n",
    "initial_lr = 0.001\n",
    "\n",
    "features_prezzo = [\n",
    "    \"Close\",\n",
    "#    \"EMA_5\", \n",
    "    \"EMA_20\", \n",
    "    \"EMA_50\",\n",
    "    \"Open\",  \n",
    "    \"High\",\n",
    "    \"Low\",\n",
    "    \"PSAR\",\n",
    "    \"SUPERT\", \n",
    "]\n",
    "\n",
    "features_da_scalare_singolarmente = [\n",
    "    \"Volume\",\n",
    "    \"ATR\",\n",
    "    \"PSARaf\",\n",
    "    \"ADX\",\n",
    "]\n",
    "\n",
    "features_meno_piu = [\n",
    "    \"MACDh\",    \n",
    "    \"AROONOSC\",\n",
    "    \"TRIX\",\n",
    "    \"TRIXs\",\n",
    "    \"DM_OSC\",\n",
    "]\n",
    "\n",
    "features_no_scala = [\n",
    "    \"SUPERTd\",  \n",
    "    \"PSARr\"\n",
    "]\n",
    "\n",
    "features_candele = [\n",
    "#    \"CDL_2CROWS\", \"CDL_3BLACKCROWS\", \"CDL_3INSIDE\", \"CDL_3LINESTRIKE\", \"CDL_3OUTSIDE\", \"CDL_3STARSINSOUTH\", \"CDL_3WHITESOLDIERS\", \"CDL_ABANDONEDBABY\", \"CDL_ADVANCEBLOCK\", \"CDL_BELTHOLD\", \"CDL_BREAKAWAY\", \"CDL_CLOSINGMARUBOZU\", \"CDL_CONCEALBABYSWALL\", \"CDL_COUNTERATTACK\", \"CDL_DARKCLOUDCOVER\", \"CDL_DOJI_10_0.1\", \"CDL_DOJISTAR\", \"CDL_DRAGONFLYDOJI\", \"CDL_ENGULFING\", \"CDL_EVENINGDOJISTAR\", \"CDL_EVENINGSTAR\", \"CDL_GAPSIDESIDEWHITE\", \"CDL_GRAVESTONEDOJI\", \"CDL_HAMMER\", \"CDL_HANGINGMAN\", \"CDL_HARAMI\", \"CDL_HARAMICROSS\", \"CDL_HIGHWAVE\", \"CDL_HIKKAKE\", \"CDL_HIKKAKEMOD\", \"CDL_HOMINGPIGEON\", \"CDL_IDENTICAL3CROWS\", \"CDL_INNECK\", \"CDL_INSIDE\", \"CDL_INVERTEDHAMMER\", \"CDL_KICKING\", \"CDL_KICKINGBYLENGTH\", \"CDL_LADDERBOTTOM\", \"CDL_LONGLEGGEDDOJI\", \"CDL_LONGLINE\", \"CDL_MARUBOZU\", \"CDL_MATCHINGLOW\", \"CDL_MATHOLD\", \"CDL_MORNINGDOJISTAR\", \"CDL_MORNINGSTAR\", \"CDL_ONNECK\", \"CDL_PIERCING\", \"CDL_RICKSHAWMAN\", \"CDL_RISEFALL3METHODS\", \"CDL_SEPARATINGLINES\", \"CDL_SHOOTINGSTAR\", \"CDL_SHORTLINE\", \"CDL_SPINNINGTOP\", \"CDL_STALLEDPATTERN\", \"CDL_STICKSANDWICH\", \"CDL_TAKURI\", \"CDL_TASUKIGAP\", \"CDL_THRUSTING\", \"CDL_TRISTAR\", \"CDL_UNIQUE3RIVER\", \"CDL_UPSIDEGAP2CROWS\", \"CDL_XSIDEGAP3METHODS\",\n",
    "]\n",
    "\n",
    "elenco_targets = [\n",
    "#    \"EMA_5\",\n",
    "#    \"EMA_20\", \n",
    "#    \"EMA_50\",\n",
    "    #\"Open\",\n",
    "    #\"High\",\n",
    "    #\"Low\",\n",
    "    \"Target\"\n",
    "]\n",
    "\n",
    "col_features_prezzo = {col: idx for idx, col in enumerate(features_prezzo)}\n",
    "col_features_da_scalare_singolarmente = {col: idx for idx, col in enumerate(features_da_scalare_singolarmente)}\n",
    "col_features_meno_piu = {col: idx for idx, col in enumerate(features_meno_piu)}\n",
    "col_features_no_scala = {col: idx for idx, col in enumerate(features_no_scala)}\n",
    "col_features_candele = {col: idx for idx, col in enumerate(features_candele)}\n",
    "col_targets = {col: idx for idx, col in enumerate(elenco_targets)}\n",
    "n_features = len(col_features_prezzo) + len(col_features_da_scalare_singolarmente) + len(col_features_meno_piu) + len(col_features_no_scala) + len(col_features_candele) \n",
    "n_targets = len(col_targets) \n",
    "\n",
    "class MixedHyperModel(HyperModel):\n",
    "    def __init__(self, n_timesteps, n_features, n_targets, giorni_previsione):\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.n_features = n_features\n",
    "        self.n_targets = n_targets\n",
    "        self.giorni_previsione = giorni_previsione\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "\n",
    "        # Layer LSTM iniziale\n",
    "        model.add(LSTM(hp.Int('lstm_units_1', 50, 500, step=50),\n",
    "                       input_shape=(self.n_timesteps, self.n_features), kernel_initializer='glorot_uniform'))\n",
    "        model.add(RepeatVector(self.giorni_previsione))\n",
    "\n",
    "        # Aggiunta di layer LSTM intermedi\n",
    "        for i in range(hp.Int('num_lstm_layers', 1, 4)):\n",
    "            model.add(LSTM(hp.Int(f'lstm_units_{i+2}', 50, 500, step=50), return_sequences=True,\n",
    "                           kernel_regularizer=l2(hp.Float(f'l2_rate_{i+2}', 0.000001, 5, step=0.001)), kernel_initializer='glorot_uniform'))\n",
    "            model.add(Dropout(hp.Float(f'lstm_dropout_{i+2}', 0, 0.5, step=0.1)))\n",
    "\n",
    "        # Aggiunta di layer Dense\n",
    "        for i in range(hp.Int('num_dense_layers', 1, 4)):\n",
    "            model.add(TimeDistributed(Dense(hp.Int(f'dense_units_{i}', 50, 500, step=50), activation='relu', kernel_initializer='glorot_uniform')))\n",
    "            model.add(Dropout(hp.Float(f'dense_dropout_{i}', 0, 0.5, step=0.1)))\n",
    "\n",
    "        model.add(TimeDistributed(Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform')))\n",
    "\n",
    "        model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "input_shape = (n_timesteps, n_features)\n",
    "output_shape = (giorni_previsione, n_targets)\n",
    "hypermodel = MixedHyperModel(n_timesteps, n_features, n_targets, giorni_previsione)\n",
    "print(\"ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f1e0f91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T19:57:21.368617Z",
     "iopub.status.busy": "2023-10-04T19:57:21.368389Z",
     "iopub.status.idle": "2023-10-04T19:57:22.529907Z",
     "shell.execute_reply": "2023-10-04T19:57:22.529208Z",
     "shell.execute_reply.started": "2023-10-04T19:57:21.368568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download lista ticker\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download dati ticker validazione\n",
      "Calcolo indicatori ticker validazione\n",
      "Definizione features e target ticker validazione\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"lista_ticker.parquet\"):\n",
    "    print(\"Caricamento lista_ticker esistente\", flush=True)\n",
    "    lista_ticker = pd.read_parquet(\"lista_ticker.parquet\")\n",
    "else:\n",
    "    print(\"Download lista ticker\", flush=True)\n",
    "    lista_ticker = pd.read_parquet(\"Tickers_De_Giro.parquet\")\n",
    "    lista_ticker = lista_ticker.sample(frac=1).reset_index(drop=True)\n",
    "    lista_ticker = lista_ticker.loc[(lista_ticker[\"Ticker\"] != simbolo_test) & (lista_ticker[\"Ticker\"] != simbolo_validazione) & (lista_ticker[\"Categoria\"] != \"D\"), :]\n",
    "    lista_ticker.to_parquet(\"lista_ticker.parquet\")\n",
    "\n",
    "if os.path.exists(\"ticker_val.parquet\"):\n",
    "    print(\"Caricamento dati ticker validazione\", flush=True)\n",
    "    ticker_val = pd.read_parquet(\"ticker_val.parquet\")\n",
    "else:\n",
    "    print(\"Download dati ticker validazione\")\n",
    "    ticker_val = yf.download(simbolo_validazione, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "    ticker_val.index = ticker_val.index.date\n",
    "    print(\"Calcolo indicatori ticker validazione\")\n",
    "    ticker_val = fx.crea_indicatori(ticker_val)\n",
    "    ticker_val.dropna(axis=0, inplace=True)\n",
    "    ticker_val.to_parquet(\"ticker_val.parquet\")\n",
    "\n",
    "print(\"Definizione features e target ticker validazione\", flush=True)\n",
    "idx_val, X_val, Y_val, _ = fx.to_XY(ticker_val, features_prezzo, features_da_scalare_singolarmente, features_meno_piu, features_candele, features_no_scala, elenco_targets, n_timesteps, giorni_previsione, addestramento=True)\n",
    "\n",
    "if os.path.exists(\"indice.npy\"):    \n",
    "    inizio = np.load(\"indice.npy\")\n",
    "    inizio += 1\n",
    "else:\n",
    "    inizio = 0\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4df52d98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T19:57:22.531627Z",
     "iopub.status.busy": "2023-10-04T19:57:22.531356Z",
     "iopub.status.idle": "2023-10-04T19:57:23.971567Z",
     "shell.execute_reply": "2023-10-04T19:57:23.970911Z",
     "shell.execute_reply.started": "2023-10-04T19:57:22.531627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;5;42m1 di 1000: Ticker HONE\u001b[0m\n",
      "Download dati ticker\n",
      "Calcolo indicatori ticker\n",
      "Definizione features e target\n",
      "Aggiunta dati a liste X e Y\n",
      "\u001b[48;5;42m2 di 1000: Ticker HUM\u001b[0m\n",
      "Download dati ticker\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\enric\\Documents\\GitHub\\Borsa\\tuning_v2.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enric/Documents/GitHub/Borsa/tuning_v2.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDownload dati ticker\u001b[39m\u001b[39m\"\u001b[39m, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enric/Documents/GitHub/Borsa/tuning_v2.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/enric/Documents/GitHub/Borsa/tuning_v2.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     ticker \u001b[39m=\u001b[39m yf\u001b[39m.\u001b[39;49mdownload(nome_simbolo, start\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m2010-01-01\u001b[39;49m\u001b[39m'\u001b[39;49m, end\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m2023-12-31\u001b[39;49m\u001b[39m'\u001b[39;49m, progress\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enric/Documents/GitHub/Borsa/tuning_v2.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mif\u001b[39;00m ticker[\u001b[39m\"\u001b[39m\u001b[39mClose\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enric/Documents/GitHub/Borsa/tuning_v2.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         ticker\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m ticker\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mdate\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\yfinance\\utils.py:114\u001b[0m, in \u001b[0;36mlog_indent_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEntering \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    113\u001b[0m \u001b[39mwith\u001b[39;00m IndentationContext():\n\u001b[1;32m--> 114\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    116\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mExiting \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    117\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\yfinance\\multi.py:159\u001b[0m, in \u001b[0;36mdownload\u001b[1;34m(tickers, start, end, actions, threads, ignore_tz, group_by, auto_adjust, back_adjust, repair, keepna, progress, period, show_errors, interval, prepost, proxy, rounding, timeout, session)\u001b[0m\n\u001b[0;32m    152\u001b[0m         _download_one_threaded(ticker, period\u001b[39m=\u001b[39mperiod, interval\u001b[39m=\u001b[39minterval,\n\u001b[0;32m    153\u001b[0m                                start\u001b[39m=\u001b[39mstart, end\u001b[39m=\u001b[39mend, prepost\u001b[39m=\u001b[39mprepost,\n\u001b[0;32m    154\u001b[0m                                actions\u001b[39m=\u001b[39mactions, auto_adjust\u001b[39m=\u001b[39mauto_adjust,\n\u001b[0;32m    155\u001b[0m                                back_adjust\u001b[39m=\u001b[39mback_adjust, repair\u001b[39m=\u001b[39mrepair, keepna\u001b[39m=\u001b[39mkeepna,\n\u001b[0;32m    156\u001b[0m                                progress\u001b[39m=\u001b[39m(progress \u001b[39mand\u001b[39;00m i \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m), proxy\u001b[39m=\u001b[39mproxy,\n\u001b[0;32m    157\u001b[0m                                rounding\u001b[39m=\u001b[39mrounding, timeout\u001b[39m=\u001b[39mtimeout, session\u001b[39m=\u001b[39msession)\n\u001b[0;32m    158\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(shared\u001b[39m.\u001b[39m_DFS) \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(tickers):\n\u001b[1;32m--> 159\u001b[0m         _time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[0;32m    160\u001b[0m \u001b[39m# download synchronously\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39mfor\u001b[39;00m i, ticker \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tickers):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if os.path.exists(f\"dati/X{set_file_x_y}.npy\") and os.path.exists(f\"dati/Y{set_file_x_y}.npy\"):\n",
    "    print(\"Caricamento X e Y\")\n",
    "    X = np.load(f'dati/X{set_file_x_y}.npy')\n",
    "    Y = np.load(f'dati/Y{set_file_x_y}.npy')\n",
    "else:\n",
    "    X = np.zeros((0, n_timesteps, n_features))\n",
    "    Y = np.zeros((0, giorni_previsione, n_targets))\n",
    "    lista_x, lista_y = [], []\n",
    "    for i_ticker in range (inizio, n_simboli_addestramento):\n",
    "        nome_simbolo = lista_ticker[\"Ticker\"].iloc[i_ticker]\n",
    "        print(f\"\\033[48;5;42m{i_ticker+1} di {n_simboli_addestramento}: Ticker {nome_simbolo}\\033[0m\")\n",
    "        print(\"Download dati ticker\", flush=True)\n",
    "        try:\n",
    "            ticker = yf.download(nome_simbolo, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "            if ticker[\"Close\"].iloc[-1] >= 1:\n",
    "                ticker.index = ticker.index.date\n",
    "                print(\"Calcolo indicatori ticker\", flush=True)\n",
    "                ticker = fx.crea_indicatori(ticker)\n",
    "                ticker.dropna(axis=0, inplace=True)\n",
    "\n",
    "                print(\"Definizione features e target\", flush=True)\n",
    "                idx, X_train, Y_train, _ = fx.to_XY(ticker, features_prezzo, features_da_scalare_singolarmente, features_meno_piu, features_candele, features_no_scala, elenco_targets, n_timesteps, giorni_previsione, addestramento=True)\n",
    "\n",
    "                print(\"Aggiunta dati a liste X e Y\", flush=True)\n",
    "                lista_x.append(X_train)        \n",
    "                lista_y.append(Y_train)   \n",
    "                if (i_ticker % 100 == 0) and (i_ticker > 0):\n",
    "                    print(\"Concatenamento su X, Y\", flush=True)\n",
    "                    X_arr = np.vstack(lista_x)\n",
    "                    Y_arr = np.vstack(lista_y)\n",
    "                    X = np.vstack((X, X_arr))\n",
    "                    Y = np.vstack((Y, Y_arr))\n",
    "                    print(\"Salvataggio X e Y su file\", flush=True)\n",
    "                    np.save(f'dati/X{set_file_x_y}', X)\n",
    "                    np.save(f'dati/Y{set_file_x_y}', Y)\n",
    "                    np.save(\"indice\", i_ticker)\n",
    "                    lista_x, lista_y = [], []\n",
    "                gc.collect()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            gc.collect()\n",
    "            continue\n",
    "            \n",
    "    print(\"Concatenamento su X, Y\", flush=True)\n",
    "    X_arr = np.vstack(lista_x)\n",
    "    Y_arr = np.vstack(lista_y)\n",
    "    X = np.vstack((X, X_arr))\n",
    "    Y = np.vstack((Y, Y_arr))\n",
    "    print(\"Salvataggio X e Y su file\", flush=True)\n",
    "    np.save(f'dati/X{set_file_x_y}', X)\n",
    "    np.save(f'dati/Y{set_file_x_y}', Y)\n",
    "    np.save(\"indice\", i_ticker)\n",
    "    lista_x, lista_y = [], []\n",
    "\n",
    "    os.remove(\"indice.npy\")\n",
    "    os.remove(\"lista_ticker.parquet\")\n",
    "    gc.collect()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf8d90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T19:57:23.972492Z",
     "iopub.status.busy": "2023-10-04T19:57:23.972314Z",
     "iopub.status.idle": "2023-10-04T19:57:23.978057Z",
     "shell.execute_reply": "2023-10-04T19:57:23.977299Z",
     "shell.execute_reply.started": "2023-10-04T19:57:23.972476Z"
    }
   },
   "outputs": [],
   "source": [
    "def rd(hypermodel, X_train, Y_train, X_val, Y_val):\n",
    "    random_tuner = RandomSearch(\n",
    "        hypermodel,\n",
    "        objective='val_loss',\n",
    "        max_trials=50,\n",
    "        executions_per_trial=2,\n",
    "        directory='random_search',\n",
    "        project_name='random_tuning'\n",
    "    )\n",
    "    random_tuner.search_space_summary()\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    random_tuner.search(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, Y_val), callbacks=[early_stopping, reduce_lr])\n",
    "    # Ottieni il miglior modello e i migliori iperparametri\n",
    "    best_model_random = random_tuner.get_best_models(num_models=1)[0]\n",
    "    best_hyperparameters_random = random_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(\"Migliori iperparametri per Random Search:\", best_hyperparameters_random.values)\n",
    "    \n",
    "    return best_model_random, best_hyperparameters_random\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d4f88c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T19:57:23.978948Z",
     "iopub.status.busy": "2023-10-04T19:57:23.978790Z",
     "iopub.status.idle": "2023-10-04T19:57:23.984223Z",
     "shell.execute_reply": "2023-10-04T19:57:23.983343Z",
     "shell.execute_reply.started": "2023-10-04T19:57:23.978934Z"
    }
   },
   "outputs": [],
   "source": [
    "def hb(hypermodel, X_train, Y_train, X_val, Y_val):\n",
    "    hyperband_tuner = Hyperband(\n",
    "        hypermodel,\n",
    "        objective='val_loss',\n",
    "        max_trials=50,\n",
    "        directory='hyperband_search',\n",
    "        project_name='hyperband_tuning'\n",
    "    )\n",
    "    \n",
    "    hyperband_tuner.search_space_summary()\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    hyperband_tuner.search(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, Y_val), callbacks=[early_stopping, reduce_lr])\n",
    "    \n",
    "    best_model_hyperband = hyperband_tuner.get_best_models(num_models=1)[0]\n",
    "    best_hyperparameters_hyperband = hyperband_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(\"Migliori iperparametri per Hyperband:\", best_hyperparameters_hyperband.values)\n",
    "    \n",
    "    return best_model_hyperband, best_hyperparameters_hyperband\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2378b50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T19:57:23.985114Z",
     "iopub.status.busy": "2023-10-04T19:57:23.984981Z",
     "iopub.status.idle": "2023-10-04T19:57:23.990339Z",
     "shell.execute_reply": "2023-10-04T19:57:23.989709Z",
     "shell.execute_reply.started": "2023-10-04T19:57:23.985114Z"
    }
   },
   "outputs": [],
   "source": [
    "def bay(hypermodel, X_train, Y_train, X_val, Y_val):\n",
    "    bayesian_tuner = BayesianOptimization(\n",
    "        hypermodel,\n",
    "        objective='val_loss',\n",
    "        max_trials=50,\n",
    "        directory='bayesian_search',\n",
    "        project_name='bayesian_tuning'\n",
    "    )\n",
    "    \n",
    "    bayesian_tuner.search_space_summary()\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    bayesian_tuner.search(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, Y_val), callbacks=[early_stopping, reduce_lr])\n",
    "    \n",
    "    best_model_bayesian = bayesian_tuner.get_best_models(num_models=1)[0]\n",
    "    best_hyperparameters_bayesian = bayesian_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    print(\"Migliori iperparametri per Bayesian Optimization:\", best_hyperparameters_bayesian.values)\n",
    "    \n",
    "    return best_model_bayesian, best_hyperparameters_bayesian\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8f563a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T19:57:23.991866Z",
     "iopub.status.busy": "2023-10-04T19:57:23.991705Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Addestramento\")\n",
    "model, par = bay(hypermodel, X, Y, X_val, Y_val)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e322baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"tuning.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
