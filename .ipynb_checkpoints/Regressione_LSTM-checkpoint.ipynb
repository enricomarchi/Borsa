{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99bae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "simbolo_test = \"BTG\"\n",
    "n_simboli_addestramento = 50\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "n_timesteps = 60 # n. barre del periodo passato per la ricerca di pattern, inclusa ultima data disponibile\n",
    "giorni_previsione = 10 # n. barre nel futuro di cui si desidera prevedere il prezzo\n",
    "seed = 10 \n",
    "elenco_features = [\n",
    "    \"Close\",\n",
    "    \"EMA_5\", \n",
    "    \"EMA_20\", \n",
    "    \"EMA_50\",\n",
    "    \"Open\",  \n",
    "    \"High\",\n",
    "    \"Low\",\n",
    "    \"Volume\",\n",
    "    \"MACDh\",\n",
    "    \"PSAR\",\n",
    "    \"PSARaf\",\n",
    "    \"SUPERT\", \n",
    "    \"TRIX\"\n",
    "]\n",
    "elenco_target = [\n",
    "        \"EMA_5\",\n",
    "        \"EMA_20\", \n",
    "        \"EMA_50\"    \n",
    "]\n",
    "\n",
    "def crea_modello(giorni_previsione, n_targets, n_features):\n",
    "    model = Sequential([\n",
    "        LSTM(50, input_shape=(n_timesteps, n_features)),\n",
    "        RepeatVector(giorni_previsione),\n",
    "        LSTM(50, return_sequences=True, kernel_regularizer=l2(0)),\n",
    "        #LSTM(50, return_sequences=True, kernel_regularizer=l2(0)),\n",
    "        #Dropout(0.2),\n",
    "        #LSTM(100, return_sequences=True, recurrent_initializer=\"glorot_uniform\", kernel_initializer=\"uniform\", kernel_regularizer=l2(0.01)),\n",
    "        #Dropout(0.2),\n",
    "        #LSTM(50, recurrent_initializer=\"glorot_uniform\", kernel_initializer=\"uniform\", kernel_regularizer=l2(0.01)),\n",
    "        #Dropout(0.2),\n",
    "        #Dense(64, activation='relu', kernel_initializer=\"glorot_uniform\", kernel_regularizer=l2(0.01)),\n",
    "        #Dropout(0.2),\n",
    "        TimeDistributed(Dense(n_targets, activation='linear'))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import clone\n",
    "scaler = PowerTransformer()\n",
    "#scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25570dc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importa librerie................\n",
      "Download lista ticker\n",
      "Caricamento modello esistente\n"
     ]
    }
   ],
   "source": [
    "print(\"Importa librerie\", end=\"\", flush=True)\n",
    "import pandas as pd\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import yfinance as yf\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import numpy as np\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import tensorflow as tf\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import fx_com\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import funzioni as fx\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.layers import Dropout\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from keras.regularizers import l1, l2\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras import Sequential\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.models import load_model\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import os\n",
    "print(\".\", end=\"\\n\", flush=True)\n",
    "\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "col_features = {col: idx for idx, col in enumerate(elenco_features)}\n",
    "col_targets = {col: idx for idx, col in enumerate(elenco_target)}\n",
    "n_features = len(col_features)\n",
    "n_targets = len(col_targets)\n",
    "\n",
    "print(\"Download lista ticker\")\n",
    "lista_ticker = pd.read_parquet(\"Tickers_De_Giro.parquet\")\n",
    "lista_ticker = lista_ticker.sample(frac=1).reset_index(drop=True)\n",
    "lista_ticker = lista_ticker.loc[lista_ticker[\"Ticker\"] != simbolo_test, :]\n",
    "\n",
    "if os.path.exists('LSTM.keras'):\n",
    "    print(\"Caricamento modello esistente\")\n",
    "    model = load_model(\"LSTM.keras\")\n",
    "else:\n",
    "    print(\"Creazione modello\")\n",
    "    model = crea_modello(giorni_previsione, n_targets, n_features)\n",
    "    print(\"Compilazione modello\")\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "def to_XY(dati_ticker, n_timesteps, giorni_previsione):\n",
    "    features = dati_ticker[elenco_features]\n",
    "    targets = dati_ticker[elenco_target]\n",
    "\n",
    "    i_tot = len(features) - n_timesteps - giorni_previsione + 1\n",
    "    indice = {\n",
    "        \"X_inizio\": features.index[n_timesteps - 1], \n",
    "        \"X_fine\": features.index[i_tot-1 + n_timesteps - 1],\n",
    "        \"Y_inizio\": targets.index[n_timesteps], \n",
    "        \"Y_fine\": targets.index[i_tot-1 + n_timesteps + giorni_previsione - 1]\n",
    "    }\n",
    "    X, Y = [], []\n",
    "    for i in range(i_tot):\n",
    "        X.append(features.iloc[i:i + n_timesteps])\n",
    "        Y.append(targets.iloc[i + n_timesteps:i + n_timesteps + giorni_previsione])\n",
    "        \n",
    "    return indice, np.array(X), np.array(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5390dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_ticker in range (n_simboli_addestramento + 1):\n",
    "    nome_simbolo = lista_ticker[\"Ticker\"].iloc[i_ticker]\n",
    "    print(f\"\\033[48;5;42m{i_ticker} di {n_simboli_addestramento}: Ticker {nome_simbolo}\\033[0m\")\n",
    "    print(\"Download dati ticker\")\n",
    "    ticker = yf.download(nome_simbolo, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "    ticker.index = ticker.index.date\n",
    "    ticker = fx.crea_indicatori(ticker)\n",
    "    ticker.dropna(axis=0, inplace=True)\n",
    "\n",
    "    print(\"Definizione features e target\")\n",
    "    X, Y = to_XY(ticker, n_timesteps, giorni_previsione)\n",
    "\n",
    "    print(\"Scaler\")\n",
    "    X = X.reshape((-1, n_timesteps * n_features))\n",
    "    Y = Y.reshape((-1, giorni_previsione * n_targets))\n",
    "\n",
    "    #X_train, X_test, Y_train, Y_test, idx_train, idx_test = train_test_split(X, Y, idx, test_size=0.2, random_state=seed)\n",
    "    X_train = X\n",
    "    Y_train = Y\n",
    "    \n",
    "    X_scaler = clone(scaler)\n",
    "    Y_scaler = clone(scaler)\n",
    "    X_scaler.fit(X_train)\n",
    "    Y_scaler.fit(Y_train)\n",
    "    X_train = X_scaler.fit_transform(X_train)\n",
    "    #X_test = X_scaler.fit_transform(X_test)\n",
    "    Y_train = Y_scaler.fit_transform(Y_train)\n",
    "    #Y_test = Y_scaler.fit_transform(Y_test)\n",
    "\n",
    "    X_train = X_train.reshape((-1, n_timesteps, n_features))\n",
    "    #X_test = X_test.reshape((-1, n_timesteps, n_features))\n",
    "    Y_train = Y_train.reshape((-1, giorni_previsione, n_targets))\n",
    "    #Y_test = Y_test.reshape((-1, giorni_previsione, n_targets))\n",
    "\n",
    "    print(f\"Addestramento modello epochs={epochs}, batch_size={batch_size}\")\n",
    "    model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size)#, validation_data=(X_test, Y_test))\n",
    "    model.save(\"LSTM.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df7dc8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download dati ticker per previsione\n",
      "106/106 [==============================] - 3s 14ms/step\n",
      "106/106 [==============================] - 5s 11ms/step - loss: 0.0312 - mae: 0.1150\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Download dati ticker per previsione\")\n",
    "dati_previsione = yf.download(simbolo_test, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "#dati_previsione = pd.read_csv(\"BTG.csv\", index_col=0)\n",
    "#dati_previsione = dati_previsione.loc['2020-01-01':'2023-09-10']\n",
    "dati_previsione.index = dati_previsione.index.date\n",
    "dati_previsione = fx.crea_indicatori(dati_previsione)\n",
    "dati_previsione.iloc[:100] = dati_previsione.iloc[:100].dropna(axis=0)\n",
    "\n",
    "indice_prev, X_prev, Y_prev = to_XY(dati_previsione, n_timesteps, giorni_previsione)\n",
    "\n",
    "X_prev = X_prev.reshape(-1, n_timesteps * n_features)\n",
    "Y_prev = Y_prev.reshape(-1, giorni_previsione * n_targets)\n",
    "X_scaler_prev = clone(scaler)\n",
    "Y_scaler_prev = clone(scaler)\n",
    "X_prev = X_scaler_prev.fit_transform(X_prev)\n",
    "Y_prev = Y_scaler_prev.fit_transform(Y_prev)\n",
    "X_prev = X_prev.reshape(-1, n_timesteps, n_features)\n",
    "Y_prev = Y_prev.reshape(-1, giorni_previsione, n_targets)\n",
    "\n",
    "pred = model.predict(X_prev)\n",
    "pred_loss, pred_mae = model.evaluate(X_prev, Y_prev)\n",
    "\n",
    "X_prev = X_prev.reshape(-1, n_timesteps * n_features)\n",
    "X_prev = X_scaler_prev.inverse_transform(X_prev)\n",
    "X_prev = X_prev.reshape(-1, n_timesteps, n_features)\n",
    "\n",
    "Y_prev = Y_prev.reshape(-1, giorni_previsione * n_targets)\n",
    "pred = pred.reshape(-1, giorni_previsione * n_targets)\n",
    "Y_prev = Y_scaler_prev.inverse_transform(Y_prev)\n",
    "pred = Y_scaler_prev.inverse_transform(pred)\n",
    "Y_prev = Y_prev.reshape(-1, giorni_previsione, n_targets)\n",
    "pred = pred.reshape(-1, giorni_previsione, n_targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "155f0df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m col_analisi \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEMA_5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m idx_prev \u001b[38;5;241m=\u001b[39m dati_previsione\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;28mmin\u001b[39m(indice_prev[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_inizio\u001b[39m\u001b[38;5;124m\"\u001b[39m], indice_prev[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_inizio\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\u001b[38;5;28mmax\u001b[39m(indice_prev[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_fine\u001b[39m\u001b[38;5;124m\"\u001b[39m], indice_prev[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_fine\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\n\u001b[0;32m      3\u001b[0m risultato \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m: X_prev[:, n_timesteps\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, col_features[col_analisi]], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: Y_prev[:, giorni_previsione\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, col_targets[col_analisi]]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrevisione\u001b[39m\u001b[38;5;124m\"\u001b[39m: pred[:, giorni_previsione\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, col_targets[col_analisi]]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)}, index\u001b[38;5;241m=\u001b[39midx_prev)\n\u001b[0;32m      5\u001b[0m fx_com\u001b[38;5;241m.\u001b[39mgrafico(risultato, pred_mae)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5325\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5320\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m getitem(key)\n\u001b[0;32m   5322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   5323\u001b[0m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[0;32m   5324\u001b[0m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[1;32m-> 5325\u001b[0m     result \u001b[38;5;241m=\u001b[39m getitem(key)\n\u001b[0;32m   5326\u001b[0m     \u001b[38;5;66;03m# Going through simple_new for performance.\u001b[39;00m\n\u001b[0;32m   5327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_simple_new(result, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name)\n",
      "\u001b[1;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "col_analisi = \"EMA_5\"\n",
    "idx_prev = dati_previsione.index[min(indice_prev[\"X_inizio\"], indice_prev[\"Y_inizio\"]):max(indice_prev[\"X_fine\"], indice_prev[\"Y_fine\"])]\n",
    "risultato = pd.DataFrame({\"Feature\": X_prev[:, n_timesteps-1, col_features[col_analisi]], \"Target\": Y_prev[:, giorni_previsione-1, col_targets[col_analisi]].round(2), \"Previsione\": pred[:, giorni_previsione-1, col_targets[col_analisi]].round(2)}, index=idx_prev)\n",
    "\n",
    "fx_com.grafico(risultato, pred_mae)\n",
    "#risultato.to_excel(\"ris.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0da56148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_inizio': datetime.date(2010, 3, 30),\n",
       " 'X_fine': datetime.date(2023, 8, 25),\n",
       " 'Y_inizio': datetime.date(2010, 3, 31),\n",
       " 'Y_fine': datetime.date(2023, 9, 11)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7df313a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 9, 11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(indice_prev[\"X_fine\"], indice_prev[\"Y_fine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56574137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
