{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99bae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "simbolo = \"BTG\"\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "n_timesteps = 10 # n. barre del periodo passato per la ricerca di pattern, inclusa ultima data disponibile\n",
    "giorni_previsione = 5 # n. barre nel futuro di cui si desidera prevedere il prezzo\n",
    "seed = 10 \n",
    "\n",
    "def crea_modello(n_timesteps, n_features):\n",
    "    model = Sequential([\n",
    "        #BatchNormalization(input_shape=(n_timesteps, n_features)),\n",
    "        LSTM(50, return_sequences=False, recurrent_initializer=\"glorot_uniform\", kernel_initializer=\"uniform\"),\n",
    "        #Dropout(0.2),\n",
    "        #LSTM(100, return_sequences=True, recurrent_initializer=\"glorot_uniform\", kernel_initializer=\"uniform\", kernel_regularizer=l2(0.01)),\n",
    "        #Dropout(0.2),\n",
    "        #LSTM(50, recurrent_initializer=\"glorot_uniform\", kernel_initializer=\"uniform\", kernel_regularizer=l2(0.01)),\n",
    "        #Dropout(0.2),\n",
    "        #Dense(64, activation='relu', kernel_initializer=\"glorot_uniform\", kernel_regularizer=l2(0.01)),\n",
    "        #Dropout(0.2),\n",
    "        Dense(giorni_previsione, activation='linear', kernel_initializer=\"glorot_uniform\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def to_ft(dati_ticker, giorni_pervisione):\n",
    "    features = dati_ticker[[\n",
    "        \"Close\",\n",
    "        \"EMA_5\", \n",
    "        \"EMA_20\",\n",
    "        \"EMA_50\",\n",
    "        #\"ATR\",\n",
    "        \"Volume\",\n",
    "        #\"PSAR\",\n",
    "        #\"MACDh\",\n",
    "        \"Open\",  \n",
    "        \"High\",\n",
    "        \"Low\"\n",
    "    ]]\n",
    "    target = pd.concat([dati_ticker[\"Close\"].shift(-i) for i in range(1, giorni_previsione + 1)], axis=1)\n",
    "    target.columns = [f\"Target_{i}\" for i in range(1, giorni_pervisione + 1)]\n",
    "    return features.iloc[:-giorni_previsione], target.iloc[:-giorni_previsione]\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.base import clone\n",
    "scaler = PowerTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25570dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download dati ticker\n",
      "Definizione features e target\n",
      "Preparazione array X e Y\n",
      "Creazione modello\n",
      "Compilazione modello\n",
      "Reshape\n",
      "Reshape ai valori originari\n",
      "Addestramento modello epochs=50, batch_size=32\n",
      "Epoch 1/50\n",
      "58/58 [==============================] - 7s 32ms/step - loss: 0.2767 - mae: 0.3680 - val_loss: 0.0805 - val_mae: 0.2227\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0720 - mae: 0.2034 - val_loss: 0.0631 - val_mae: 0.1919\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0622 - mae: 0.1871 - val_loss: 0.0558 - val_mae: 0.1812\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0592 - mae: 0.1813 - val_loss: 0.0532 - val_mae: 0.1765\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0560 - mae: 0.1758 - val_loss: 0.0489 - val_mae: 0.1687\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0552 - mae: 0.1739 - val_loss: 0.0501 - val_mae: 0.1727\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0533 - mae: 0.1714 - val_loss: 0.0466 - val_mae: 0.1655\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0522 - mae: 0.1688 - val_loss: 0.0451 - val_mae: 0.1611\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0512 - mae: 0.1666 - val_loss: 0.0433 - val_mae: 0.1581\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0496 - mae: 0.1639 - val_loss: 0.0437 - val_mae: 0.1591\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0483 - mae: 0.1613 - val_loss: 0.0428 - val_mae: 0.1585\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0480 - mae: 0.1612 - val_loss: 0.0404 - val_mae: 0.1528\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0465 - mae: 0.1573 - val_loss: 0.0400 - val_mae: 0.1512\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0464 - mae: 0.1569 - val_loss: 0.0412 - val_mae: 0.1517\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0471 - mae: 0.1581 - val_loss: 0.0410 - val_mae: 0.1512\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0455 - mae: 0.1555 - val_loss: 0.0383 - val_mae: 0.1472\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0451 - mae: 0.1544 - val_loss: 0.0380 - val_mae: 0.1471\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0447 - mae: 0.1542 - val_loss: 0.0381 - val_mae: 0.1472\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0450 - mae: 0.1539 - val_loss: 0.0388 - val_mae: 0.1478\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - 1s 10ms/step - loss: 0.0445 - mae: 0.1538 - val_loss: 0.0384 - val_mae: 0.1477\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0443 - mae: 0.1527 - val_loss: 0.0369 - val_mae: 0.1434\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0443 - mae: 0.1524 - val_loss: 0.0372 - val_mae: 0.1443\n",
      "Epoch 23/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0436 - mae: 0.1519 - val_loss: 0.0381 - val_mae: 0.1450\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0439 - mae: 0.1522 - val_loss: 0.0383 - val_mae: 0.1463\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.0435 - mae: 0.1513 - val_loss: 0.0368 - val_mae: 0.1443\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0429 - mae: 0.1506 - val_loss: 0.0359 - val_mae: 0.1414\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0424 - mae: 0.1494 - val_loss: 0.0361 - val_mae: 0.1418\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0434 - mae: 0.1511 - val_loss: 0.0361 - val_mae: 0.1410\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0426 - mae: 0.1494 - val_loss: 0.0357 - val_mae: 0.1414\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0425 - mae: 0.1500 - val_loss: 0.0367 - val_mae: 0.1432\n",
      "Epoch 31/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0428 - mae: 0.1502 - val_loss: 0.0376 - val_mae: 0.1443\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0425 - mae: 0.1492 - val_loss: 0.0357 - val_mae: 0.1412\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0418 - mae: 0.1482 - val_loss: 0.0368 - val_mae: 0.1445\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0418 - mae: 0.1485 - val_loss: 0.0356 - val_mae: 0.1407\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0422 - mae: 0.1484 - val_loss: 0.0369 - val_mae: 0.1425\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0417 - mae: 0.1479 - val_loss: 0.0356 - val_mae: 0.1407\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0413 - mae: 0.1473 - val_loss: 0.0370 - val_mae: 0.1424\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0413 - mae: 0.1469 - val_loss: 0.0375 - val_mae: 0.1465\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0415 - mae: 0.1475 - val_loss: 0.0362 - val_mae: 0.1420\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0414 - mae: 0.1477 - val_loss: 0.0362 - val_mae: 0.1425\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0415 - mae: 0.1480 - val_loss: 0.0350 - val_mae: 0.1401\n",
      "Epoch 42/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0412 - mae: 0.1467 - val_loss: 0.0350 - val_mae: 0.1392\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0409 - mae: 0.1466 - val_loss: 0.0353 - val_mae: 0.1405\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0410 - mae: 0.1462 - val_loss: 0.0355 - val_mae: 0.1407\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0409 - mae: 0.1463 - val_loss: 0.0360 - val_mae: 0.1416\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0406 - mae: 0.1459 - val_loss: 0.0360 - val_mae: 0.1398\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0409 - mae: 0.1466 - val_loss: 0.0351 - val_mae: 0.1392\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0409 - mae: 0.1469 - val_loss: 0.0355 - val_mae: 0.1398\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0404 - mae: 0.1452 - val_loss: 0.0344 - val_mae: 0.1384\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0412 - mae: 0.1472 - val_loss: 0.0354 - val_mae: 0.1392\n",
      "Scrittura risultati su file parquet\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0354 - mae: 0.1392\n"
     ]
    }
   ],
   "source": [
    "print(\"Download dati ticker\")\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import fx_com\n",
    "import funzioni as fx\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "ticker = yf.download(simbolo, start='2010-01-01', end='2019-12-31', progress=False)\n",
    "ticker.index = ticker.index.date\n",
    "ticker = fx.crea_indicatori(ticker)\n",
    "\n",
    "print(\"Definizione features e target\")\n",
    "features, target = to_ft(ticker, giorni_previsione)\n",
    "n_features = features.shape[1]\n",
    "\n",
    "print(\"Preparazione array X e Y\")\n",
    "def to_XY(features, target, n_timesteps):\n",
    "    i_tot = len(features) - n_timesteps + 1\n",
    "    idx, X, Y = [], [], []\n",
    "    for i in range(i_tot):\n",
    "        idx.append(features.index[i + n_timesteps - 1])\n",
    "        X.append(features.iloc[i:i + n_timesteps])\n",
    "        Y.append(target.iloc[i + n_timesteps - 1].values)\n",
    "    return idx, np.array(X), np.array(Y)\n",
    "\n",
    "idx, X, Y = to_XY(features, target, n_timesteps)\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization\n",
    "\n",
    "print(\"Creazione modello\")\n",
    "model = crea_modello(n_timesteps, n_features)\n",
    "\n",
    "print(\"Compilazione modello\")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "print(\"Reshape\")\n",
    "n_samples = X.shape[0]\n",
    "X = X.reshape((n_samples, n_timesteps * n_features))\n",
    "\n",
    "X_scaler = clone(scaler)\n",
    "Y_scaler = clone(scaler)\n",
    "X = X_scaler.fit_transform(X)\n",
    "Y = Y_scaler.fit_transform(Y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test, idx_train, idx_test = train_test_split(X, Y, idx, test_size=0.2, random_state=seed)\n",
    "\n",
    "print(\"Reshape ai valori originari\")\n",
    "X_train = X_train.reshape((X_train.shape[0], n_timesteps, n_features))\n",
    "X_test = X_test.reshape((X_test.shape[0], n_timesteps, n_features))\n",
    "\n",
    "print(f\"Addestramento modello epochs={epochs}, batch_size={batch_size}\")\n",
    "model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, Y_test))\n",
    "\n",
    "print(\"Scrittura risultati su file parquet\")\n",
    "import os\n",
    "test_loss, test_mae = model.evaluate(X_test, Y_test)\n",
    "if os.path.exists('metriche.parquet'):\n",
    "    metriche = pd.read_parquet(\"metriche.parquet\")\n",
    "else:\n",
    "    metriche = pd.DataFrame()\n",
    "nuova_riga_metriche = pd.DataFrame([{\n",
    "    \"scaler\": type(scaler).__name__,\n",
    "    \"epochs\": epochs,\n",
    "    \"eatch_size\": batch_size,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"n_timesteps\": n_timesteps,\n",
    "    \"giorni_previsione\": giorni_previsione,\n",
    "    \"seed\": seed,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_mae\": test_mae\n",
    "}])\n",
    "for i, layer in enumerate(model.layers):\n",
    "    config = layer.get_config()\n",
    "    kernel_regularizer_config = config.get('kernel_regularizer', None)\n",
    "    str_temp = f\"{type(layer).__name__}\"    \n",
    "    if 'units' in config:\n",
    "        str_temp += f\", units({config['units']})\"\n",
    "    if 'rate' in config:\n",
    "        str_temp += f\", rate({config['rate']})\" \n",
    "    if kernel_regularizer_config:\n",
    "        class_name = kernel_regularizer_config.get('class_name', None)\n",
    "        if class_name:\n",
    "            str_temp += f\", reg({class_name})\" \n",
    "    nuova_riga_metriche[f\"Layer_{i+1}\"] = str_temp\n",
    "metriche = pd.concat([metriche, nuova_riga_metriche], ignore_index=True)\n",
    "metriche.to_parquet(\"metriche.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a1cadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaler</th>\n",
       "      <th>epochs</th>\n",
       "      <th>eatch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_timesteps</th>\n",
       "      <th>giorni_previsione</th>\n",
       "      <th>seed</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>Layer_1</th>\n",
       "      <th>Layer_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.034761</td>\n",
       "      <td>LSTM, units(50)</td>\n",
       "      <td>Dense, units(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>0.079968</td>\n",
       "      <td>LSTM, units(50)</td>\n",
       "      <td>Dense, units(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.035445</td>\n",
       "      <td>0.139193</td>\n",
       "      <td>LSTM, units(50)</td>\n",
       "      <td>Dense, units(5)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scaler  epochs  eatch_size  learning_rate  n_timesteps  \\\n",
       "0  PowerTransformer      50          32          0.001           10   \n",
       "1  PowerTransformer      50          32          0.001           10   \n",
       "2  PowerTransformer      50          32          0.001           10   \n",
       "\n",
       "   giorni_previsione  seed  test_loss  test_mae          Layer_1  \\\n",
       "0                  5    10   0.002443  0.034761  LSTM, units(50)   \n",
       "1                  5    10   0.012620  0.079968  LSTM, units(50)   \n",
       "2                  5    10   0.035445  0.139193  LSTM, units(50)   \n",
       "\n",
       "           Layer_2  \n",
       "0  Dense, units(5)  \n",
       "1  Dense, units(5)  \n",
       "2  Dense, units(5)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7dc8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download dati ticker per previsione\n",
      "23/23 [==============================] - 1s 4ms/step\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.0607 - mae: 0.1868\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Download dati ticker per previsione\")\n",
    "dati_previsione = yf.download(simbolo, start='2020-01-01', end='2023-12-31', progress=False)\n",
    "dati_previsione.index = dati_previsione.index.date\n",
    "dati_previsione = fx.crea_indicatori(dati_previsione)\n",
    "\n",
    "features_prev, target_prev = to_ft(dati_previsione, giorni_previsione)\n",
    "idx_prev, X_prev, Y_prev = to_XY(features_prev, target_prev, n_timesteps)\n",
    "\n",
    "X_prev = X_prev.reshape(-1, n_timesteps * n_features)\n",
    "X_scaler_prev = clone(scaler)\n",
    "Y_scaler_prev = clone(scaler)\n",
    "X_prev = X_scaler_prev.fit_transform(X_prev)\n",
    "Y_prev = Y_scaler_prev.fit_transform(Y_prev)\n",
    "X_prev = X_prev.reshape(-1, n_timesteps, n_features)\n",
    "\n",
    "pred = model.predict(X_prev)\n",
    "pred_loss, pred_mae = model.evaluate(X_prev, Y_prev)\n",
    "\n",
    "X_prev = X_prev.reshape(-1, n_timesteps * n_features)\n",
    "X_prev = X_scaler_prev.inverse_transform(X_prev)\n",
    "X_prev = X_prev.reshape(-1, n_timesteps, n_features)\n",
    "\n",
    "Y_prev = Y_scaler_prev.inverse_transform(Y_prev)\n",
    "pred = Y_scaler_prev.inverse_transform(pred)\n",
    "\n",
    "risultato = pd.DataFrame({\"Close\": X_prev[:, n_timesteps-1, 0], \"Target\": Y_prev[:, giorni_previsione - 1].round(2), \"Previsione\": pred[:, giorni_previsione - 1].round(2)}, index=idx_prev)\n",
    "\n",
    "fx_com.grafico(risultato, pred_mae)\n",
    "#risultato.to_excel(\"ris.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52dd03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
