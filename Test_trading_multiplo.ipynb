{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85a9176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from multiprocessing import Pool, cpu_count, Manager, Value\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Sequential, Model\n",
    "from tensorflow.keras.layers import Bidirectional, BatchNormalization, LSTM, Dropout, Dense, Conv1D, Flatten, GRU, Attention, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import os\n",
    "from functools import partial\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas_ta as ta\n",
    "import random\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "import plotly.subplots as sp\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "_features_scala_prezzo_tutte = [\n",
    "    \"Close\",\n",
    "    \"EMA_5\", \n",
    "    \"EMA_20\", \n",
    "    \"EMA_50\",\n",
    "    \"EMA_100\",\n",
    "    \"Open\",  \n",
    "    \"High\",\n",
    "    \"Low\",\n",
    "    \"PSAR\",\n",
    "    \"SUPERT\"\n",
    "]\n",
    "\n",
    "_features_da_scalare_singolarmente_tutte = [\n",
    "    \"Volume\",\n",
    "    \"ATR\",\n",
    "    \"PSARaf\",\n",
    "    \"ADX\",\n",
    "    \"OBV\"\n",
    "]\n",
    "\n",
    "_features_oscillatori_tutte = [\n",
    "    \"MACDh\",    \n",
    "    \"MACD\",\n",
    "    \"MACDs\",\n",
    "    \"AROONOSC\",\n",
    "    \"TRIX\",\n",
    "    \"TRIXs\",\n",
    "    \"DM_OSC\",\n",
    "    \"TSI\",\n",
    "    \"TSIs\",\n",
    "    \"ROC_10\",\n",
    "    \"KVO\",\n",
    "    \"KVOs\",\n",
    "    \"VI_OSC\"\n",
    "]\n",
    "\n",
    "_features_no_scala_tutte = [\n",
    "    \"SUPERTd\",  \n",
    "    \"PSARr\",\n",
    "    \"CMF\",\n",
    "    \"VHF\",\n",
    "    \"VTX_OSC\"\n",
    "]\n",
    "\n",
    "_features_candele_tutte = [\n",
    "    \"CDL_2CROWS\", \"CDL_3BLACKCROWS\", \"CDL_3INSIDE\", \"CDL_3LINESTRIKE\", \"CDL_3OUTSIDE\", \"CDL_3STARSINSOUTH\", \"CDL_3WHITESOLDIERS\", \"CDL_ABANDONEDBABY\", \"CDL_ADVANCEBLOCK\", \"CDL_BELTHOLD\", \"CDL_BREAKAWAY\", \"CDL_CLOSINGMARUBOZU\", \"CDL_CONCEALBABYSWALL\", \"CDL_COUNTERATTACK\", \"CDL_DARKCLOUDCOVER\", \"CDL_DOJI_10_0.1\", \"CDL_DOJISTAR\", \"CDL_DRAGONFLYDOJI\", \"CDL_ENGULFING\", \"CDL_EVENINGDOJISTAR\", \"CDL_EVENINGSTAR\", \"CDL_GAPSIDESIDEWHITE\", \"CDL_GRAVESTONEDOJI\", \"CDL_HAMMER\", \"CDL_HANGINGMAN\", \"CDL_HARAMI\", \"CDL_HARAMICROSS\", \"CDL_HIGHWAVE\", \"CDL_HIKKAKE\", \"CDL_HIKKAKEMOD\", \"CDL_HOMINGPIGEON\", \"CDL_IDENTICAL3CROWS\", \"CDL_INNECK\", \"CDL_INSIDE\", \"CDL_INVERTEDHAMMER\", \"CDL_KICKING\", \"CDL_KICKINGBYLENGTH\", \"CDL_LADDERBOTTOM\", \"CDL_LONGLEGGEDDOJI\", \"CDL_LONGLINE\", \"CDL_MARUBOZU\", \"CDL_MATCHINGLOW\", \"CDL_MATHOLD\", \"CDL_MORNINGDOJISTAR\", \"CDL_MORNINGSTAR\", \"CDL_ONNECK\", \"CDL_PIERCING\", \"CDL_RICKSHAWMAN\", \"CDL_RISEFALL3METHODS\", \"CDL_SEPARATINGLINES\", \"CDL_SHOOTINGSTAR\", \"CDL_SHORTLINE\", \"CDL_SPINNINGTOP\", \"CDL_STALLEDPATTERN\", \"CDL_STICKSANDWICH\", \"CDL_TAKURI\", \"CDL_TASUKIGAP\", \"CDL_THRUSTING\", \"CDL_TRISTAR\", \"CDL_UNIQUE3RIVER\", \"CDL_UPSIDEGAP2CROWS\", \"CDL_XSIDEGAP3METHODS\",\n",
    "]\n",
    "\n",
    "def inizializza_gpu():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "                tf.config.experimental.set_visible_devices(gpu, 'GPU')\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    else:\n",
    "        print(\"nessuna GPU\")\n",
    "    \n",
    "def pct_change(valore_iniziale, valore_finale):\n",
    "    try:\n",
    "        return ((valore_finale - valore_iniziale) / valore_iniziale) * 100\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "def analizza_ticker(nome_simbolo, start, end, progress=True, dropna_iniziali=False, dropna_finali=False):\n",
    "    start_str = start.strftime('%Y-%m-%d')\n",
    "    end_str = end.strftime('%Y-%m-%d')\n",
    "    df = yf.download(nome_simbolo, start=start_str, end=end_str, progress=progress)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = crea_indicatori(df)\n",
    "    if dropna_iniziali:\n",
    "        idx = df[df.notna().all(axis=1) == True].index[0]\n",
    "        df = df[idx:]\n",
    "    if dropna_finali:\n",
    "        idx = df[df.notna().all(axis=1) == True].index[-1]\n",
    "        df = df[:idx]\n",
    "    return df\n",
    "\n",
    "def dropna_iniziali(df):\n",
    "    idx = df[df.notna().all(axis=1) == True].index[0]\n",
    "    df = df[idx:]\n",
    "    return df\n",
    "\n",
    "def dropna_finali(df):\n",
    "    idx = df[df.notna().all(axis=1) == True].index[-1]\n",
    "    df = df[:idx]\n",
    "    return df\n",
    "\n",
    "def imposta_target(df):\n",
    "    def __calcolo_drawdown_gain(df, periodo):\n",
    "        df[f\"Max_High_Futuro_{periodo}d\"] = df[\"High\"].shift(-periodo).rolling(periodo).max()\n",
    "        df[f\"Min_Low_Futuro_{periodo}d\"] = df[\"Low\"].shift(-periodo).rolling(periodo).min()\n",
    "        df[f\"Drawdown_{periodo}d\"] = df[\"Open\"] - df[f\"Min_Low_Futuro_{periodo}d\"]\n",
    "        df[f\"Drawdown_{periodo}d\"] = df[f\"Drawdown_{periodo}d\"].where(df[f\"Drawdown_{periodo}d\"] > 0, 0)\n",
    "        df[f\"Perc_Max_High_Futuro_{periodo}d\"] = ((df[f\"Max_High_Futuro_{periodo}d\"] - df[\"Open\"]) / df[\"Open\"]) * 100\n",
    "        df[f\"Perc_Drawdown_{periodo}d\"] = ((df[f\"Drawdown_{periodo}d\"]) / df[\"Open\"]) * 100 \n",
    "        df[f\"Perc_Drawdown_{periodo}d\"] = df[f\"Perc_Drawdown_{periodo}d\"].where(df[f\"Perc_Drawdown_{periodo}d\"] > 0, 0)\n",
    "        df.drop(columns=[f\"Max_High_Futuro_{periodo}d\", f\"Min_Low_Futuro_{periodo}d\", f\"Drawdown_{periodo}d\"], axis=1, inplace=True)\n",
    "        return df\n",
    "    def __trova_massimi_minimi(df, periodo):\n",
    "        mezzo_periodo = periodo // 2\n",
    "\n",
    "        massimi_passati = df['Close'].shift(1).rolling(mezzo_periodo).max()\n",
    "        massimi_futuri = df['Close'][::-1].shift(1).rolling(mezzo_periodo).max()[::-1]\n",
    "        idx_massimi = (df[\"Close\"] >= massimi_passati) & (df[\"Close\"] >= massimi_futuri)\n",
    "        df.loc[idx_massimi, \"MaxMinRel\"] = periodo\n",
    "\n",
    "        minimi_passati = df['Close'].shift(1).rolling(mezzo_periodo).min()\n",
    "        minimi_futuri = df['Close'][::-1].shift(1).rolling(mezzo_periodo).min()[::-1]\n",
    "        idx_minimi = (df[\"Close\"] <= minimi_passati) & (df[\"Close\"] <= minimi_futuri)\n",
    "        df.loc[idx_minimi, \"MaxMinRel\"] = -periodo\n",
    "            \n",
    "        return df\n",
    "    df = __calcolo_drawdown_gain(df, 5)\n",
    "    # df = __calcolo_drawdown_gain(df, 50)\n",
    "    # df = __calcolo_drawdown_gain(df, 100)\n",
    "    # df[\"max_gain\"] = df[[\"Perc_Max_High_Futuro_20d\", \"Perc_Max_High_Futuro_50d\", \"Perc_Max_High_Futuro_100d\"]].max(axis=1)\n",
    "    # df[\"max_drawdown\"] = df[[\"Perc_Drawdown_20d\", \"Perc_Drawdown_50d\", \"Perc_Drawdown_100d\"]].min(axis=1)\n",
    "\n",
    "    df['EMA_20_5d'] = df['EMA_20'].shift(-5)\n",
    "    df['EMA_20_10d'] = df['EMA_20'].shift(-10)\n",
    "    df['EMA_20_15d'] = df['EMA_20'].shift(-15)\n",
    "    df['EMA_20_20d'] = df['EMA_20'].shift(-20)\n",
    "    \n",
    "    df['EMA_50_5d'] = df['EMA_50'].shift(-5)\n",
    "    df['EMA_50_10d'] = df['EMA_50'].shift(-10)\n",
    "    df['EMA_50_15d'] = df['EMA_50'].shift(-15)\n",
    "    df['EMA_50_20d'] = df['EMA_50'].shift(-20)\n",
    "    \n",
    "    df['Close_5d'] = df['Close'].shift(-5)\n",
    "    df['Close_10d'] = df['Close'].shift(-10)\n",
    "    df['Close_15d'] = df['Close'].shift(-15)\n",
    "    df['Close_20d'] = df['Close'].shift(-20)\n",
    "    \n",
    "    df['EMA_5_5d'] = df['EMA_5'].shift(-5)\n",
    "    df['EMA_5_10d'] = df['EMA_5'].shift(-10)\n",
    "    df['EMA_5_15d'] = df['EMA_5'].shift(-15)\n",
    "    df['EMA_5_20d'] = df['EMA_5'].shift(-20)\n",
    "    #df['Close_1d'] = df['Close'].shift(-1)\n",
    "    #df['perc_EMA_5_20d'] = ((df['EMA_5_20d'] - df['EMA_5']) / df['EMA_5']) * 100\n",
    "    #df['perc_Close_20d'] = ((df['Close_20d'] - df['Close']) / df['Close']) * 100\n",
    "    #df['incrocio_verde_gialla'] = (ta.cross(df['EMA_20'], df['EMA_50'], above=True)).astype(\"int8\")\n",
    "    #df[\"incrocio_passato_verde_gialla_10d\"] = df[\"incrocio_verde_gialla\"].rolling(10).sum()\n",
    "    df['Max_Close_20d'] = df['Close'].shift(-20).rolling(window=20, min_periods=1).max()\n",
    "    df['pct_change_20d'] = df.apply(lambda row: pct_change(row['Close'], row['Max_Close_20d']), axis=1)\n",
    "    df.drop(columns=[\"Max_Close_20d\"], inplace=True, axis=1)\n",
    "\n",
    "    # df[\"MaxMinRel\"] = 0\n",
    "    # df = __trova_massimi_minimi(df, 20)   \n",
    "    # df = __trova_massimi_minimi(df, 50)   \n",
    "    # df = __trova_massimi_minimi(df, 100)         \n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    df['Target_ingresso'] = (\n",
    "        (df['pct_change_20d'] > 20)\n",
    "    )\n",
    "    df['Target_uscita'] = (\n",
    "        (df['EMA_5'] > df['EMA_20']) & (df['EMA_5_5d'] < df['EMA_20_5d']) & (df['EMA_5_10d'] < df['EMA_20_10d'])\n",
    "    )    \n",
    "    \n",
    "    df['Target_mod_2_in'] = (\n",
    "        (df[f\"Perc_Max_High_Futuro_5d\"] > 5)\n",
    "    )\n",
    "    return df\n",
    "    \n",
    "def grafico(df):\n",
    "    close = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = df['Close'],\n",
    "        mode = 'lines',\n",
    "        line = dict(color='rgba(0, 0, 0, .9)'),\n",
    "        name = 'Close'\n",
    "    )\n",
    "\n",
    "    close2 = go.Scatter( # serve solo per il fill del supertrend\n",
    "        x = df.index,\n",
    "        y = df['Close'],\n",
    "        mode = 'lines',\n",
    "        line = dict(color='rgba(0, 0, 0, 0)'),\n",
    "        showlegend=False,\n",
    "        name = 'Close2'\n",
    "    )\n",
    "\n",
    "    # min5 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == -5].index,\n",
    "    #     y = df[df['MaxMinRel'] == -5]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 5,\n",
    "    #         color = 'rgba(255, 0, 0, .9)'\n",
    "    #     ),\n",
    "    #     name = 'MinRel5'\n",
    "    # )\n",
    "  \n",
    "    # max5 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == 5].index,\n",
    "    #     y = df[df['MaxMinRel'] == 5]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 5,\n",
    "    #         color = 'rgba(50, 205, 50, .9)'\n",
    "    #     ),\n",
    "    #     name = 'MaxRel5'\n",
    "    # )\n",
    "\n",
    "    # min10 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == -10].index,\n",
    "    #     y = df[df['MaxMinRel'] == -10]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 15,\n",
    "    #         color = 'rgba(255, 0, 0, .4)'\n",
    "    #     ),\n",
    "    #     name = 'MinRel10'\n",
    "    # )\n",
    "  \n",
    "    # max10 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == 10].index,\n",
    "    #     y = df[df['MaxMinRel'] == 10]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 15,\n",
    "    #         color = 'rgba(50, 205, 50, .4)'\n",
    "    #     ),\n",
    "    #     name = 'MaxRel10'\n",
    "    # )\n",
    "\n",
    "    # min20 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == -20].index,\n",
    "    #     y = df[df['MaxMinRel'] == -20]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 25,\n",
    "    #         color = 'rgba(255, 0, 0, .2)'\n",
    "    #     ),\n",
    "    #     name = 'MinRel20'\n",
    "    # )\n",
    "  \n",
    "    # max20 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == 20].index,\n",
    "    #     y = df[df['MaxMinRel'] == 20]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 25,\n",
    "    #         color = 'rgba(50, 205, 50, .2)'\n",
    "    #     ),\n",
    "    #     name = 'MaxRel20'\n",
    "    # )\n",
    "\n",
    "    # min60 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == -60].index,\n",
    "    #     y = df[df['MaxMinRel'] == -60]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 35,\n",
    "    #         color = 'rgba(255, 0, 0, .1)'\n",
    "    #     ),\n",
    "    #     name = 'MinRel60'\n",
    "    # )\n",
    "  \n",
    "    # max60 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == 60].index,\n",
    "    #     y = df[df['MaxMinRel'] == 60]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 35,\n",
    "    #         color = 'rgba(50, 205, 50, .1)'\n",
    "    #     ),\n",
    "    #     name = 'MaxRel60'\n",
    "    # )\n",
    "\n",
    "    ema5 = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = df['EMA_5'],\n",
    "        mode = 'lines',\n",
    "        line = dict(color='blue'),\n",
    "        name = 'EMA5'\n",
    "    )\n",
    "\n",
    "    ema20 = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = df['EMA_20'],\n",
    "        mode = 'lines',\n",
    "        line = dict(color='limegreen'),\n",
    "        name = 'EMA20'\n",
    "    )\n",
    "\n",
    "    ema50 = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = df['EMA_50'],\n",
    "        mode = 'lines',\n",
    "        line = dict(color='orange'),\n",
    "        name = 'EMA50'\n",
    "    )\n",
    "    \n",
    "    ema100 = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = df['EMA_100'],\n",
    "        mode = 'lines',\n",
    "        line = dict(color='red'),\n",
    "        name = 'EMA100'\n",
    "    )\n",
    "    \n",
    "    psar = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = df['PSAR'], \n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = 2, \n",
    "            color = 'rgba(0, 0, 0, .8)',  \n",
    "        ),\n",
    "        visible = False,\n",
    "        showlegend=True,\n",
    "        name = 'SAR Parabolico'\n",
    "    )\n",
    "    \n",
    "    stup = np.where(df['SUPERTd'] == 1, df['SUPERT'], np.nan)\n",
    "    stdown = np.where(df['SUPERTd'] == -1, df['SUPERT'], np.nan)\n",
    "    stupfill = np.where(df['SUPERTd'] == 1, df['SUPERT'], df['Close'])\n",
    "    stdownfill = np.where(df['SUPERTd'] == -1, df['SUPERT'], df['Close'])\n",
    "    \n",
    "    strendup = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = stup, \n",
    "        mode = 'lines',\n",
    "        line = dict(\n",
    "            color='limegreen',\n",
    "            width=1\n",
    "        ),\n",
    "        visible = False,\n",
    "        showlegend=True,\n",
    "        connectgaps = False,\n",
    "        name = 'SuperTrend'\n",
    "    )\n",
    "        \n",
    "    strendupfill = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = stupfill, \n",
    "        mode = 'lines',\n",
    "        line = dict(\n",
    "            color='rgba(0,0,0,0)',\n",
    "            width=1\n",
    "        ),\n",
    "        connectgaps = False,\n",
    "        visible = False,\n",
    "        showlegend=True,\n",
    "        fill='tonexty',   \n",
    "        fillcolor='rgba(50, 205, 50, 0.1)', \n",
    "        name = 'SuperTrend'\n",
    "    )\n",
    "        \n",
    "    strenddown = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = stdown, \n",
    "        mode = 'lines',\n",
    "        line = dict(\n",
    "            color='red',\n",
    "            width=1\n",
    "        ),\n",
    "        connectgaps = False,\n",
    "        visible = False,\n",
    "        showlegend=True,\n",
    "        name = 'SuperTrend'\n",
    "    )\n",
    "    \n",
    "    strenddownfill = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = stdownfill, \n",
    "        mode = 'lines',\n",
    "        line = dict(\n",
    "            color='rgba(0,0,0,0)',\n",
    "            width=1\n",
    "        ),\n",
    "        fill='tonexty',   \n",
    "        fillcolor='rgba(255, 0, 0, 0.1)', \n",
    "        connectgaps = False,\n",
    "        visible = False,\n",
    "        showlegend=True,\n",
    "        name = 'SuperTrend'\n",
    "    )\n",
    "    \n",
    "    target_in = go.Scatter(\n",
    "        x = df[df['Target_ingresso'] == 1].index,\n",
    "        y = df[df['Target_ingresso'] == 1]['Close'],\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgba(0, 200, 0, .9)'\n",
    "        ),\n",
    "        name = 'target_in'\n",
    "    )\n",
    "    \n",
    "    target_out = go.Scatter(\n",
    "        x = df[df['Target_uscita'] == 1].index,\n",
    "        y = df[df['Target_uscita'] == 1]['Close'],\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgba(220, 0, 0, .9)'\n",
    "        ),\n",
    "        name = 'target_out'\n",
    "    )\n",
    "        \n",
    "    layout = dict(xaxis = dict(autorange=True),\n",
    "                  yaxis = dict(title = 'Close', autorange=True),\n",
    "                  autosize = True,\n",
    "                  margin = go.layout.Margin(\n",
    "                      l=0,  # Sinistra\n",
    "                      r=0,  # Destra\n",
    "                      b=0,  # Basso\n",
    "                      t=50,  # Alto\n",
    "                      pad=0  # Padding\n",
    "                  ),\n",
    "                  legend = dict(traceorder = 'normal', bordercolor = 'black')\n",
    "    )\n",
    "        \n",
    "    fig = sp.make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "    fig.update_layout(layout)\n",
    "    \n",
    "    # RIGA 1\n",
    "\n",
    "    fig.add_trace(close, row=1, col=1)\n",
    "    fig.add_trace(strendupfill, row=1, col=1)\n",
    "    fig.add_trace(strendup, row=1, col=1)\n",
    "    fig.add_trace(close2, row=1, col=1)\n",
    "    fig.add_trace(strenddownfill, row=1, col=1)\n",
    "    fig.add_trace(strenddown, row=1, col=1)\n",
    "    #fig.add_trace(min5, row=1, col=1); fig.add_trace(max5, row=1, col=1)\n",
    "    #fig.add_trace(min10, row=1, col=1); fig.add_trace(max10, row=1, col=1)\n",
    "    #fig.add_trace(min20, row=1, col=1); fig.add_trace(max20, row=1, col=1)\n",
    "    #fig.add_trace(min60, row=1, col=1); fig.add_trace(max60, row=1, col=1)\n",
    "    fig.add_trace(target_in, row=1, col=1); fig.add_trace(target_out, row=1, col=1)\n",
    "    fig.add_trace(ema5, row=1, col=1); fig.add_trace(ema20, row=1, col=1); fig.add_trace(ema50, row=1, col=1); fig.add_trace(ema100, row=1, col=1)\n",
    "    fig.add_trace(psar, row=1, col=1)\n",
    "    \n",
    "    pyo.plot(fig, filename=\"grafico_target.html\", auto_open=True)\n",
    "    \n",
    "    return fig\n",
    "    \n",
    "def crea_indicatori(df):\n",
    "    def __rinomina_colonne(df):\n",
    "        df = df.rename(columns={\n",
    "            'PSARaf_0.02_0.2': 'PSARaf',\n",
    "            'PSARr_0.02_0.2': 'PSARr',\n",
    "            'MACD_20_50_9': 'MACD',\n",
    "            'MACDh_20_50_9': 'MACDh',\n",
    "            'MACDs_20_50_9': 'MACDs',\n",
    "            'TSI_13_25_13': 'TSI',\n",
    "            'TSIs_13_25_13': 'TSIs',\n",
    "            'SUPERT_20_3.0': 'SUPERT',\n",
    "            'SUPERTd_20_3.0': 'SUPERTd',\n",
    "            'ADX_20': 'ADX',\n",
    "            'DMP_20': 'DMP',\n",
    "            'DMN_20': 'DMN',\n",
    "            'CMF_10': 'CMF',\n",
    "            'TRIX_18_9': 'TRIX',\n",
    "            'TRIXs_18_9': 'TRIXs',\n",
    "            'KVO_34_55_13': 'KVO',\n",
    "            'KVOs_34_55_13': 'KVOs',\n",
    "            'DCL_20_20': 'DCL',\n",
    "            'DCM_20_20': 'DCM',\n",
    "            'DCU_20_20': 'DCU',\n",
    "            'VTXP_20': 'VTXP',\n",
    "            'VTXM_20': 'VTXM',\n",
    "            'AROOND_20': 'AROOND',\n",
    "            'AROONU_20': 'AROONU',\n",
    "            'AROONOSC_20': 'AROONOSC',\n",
    "            'NVI_1': 'NVI',\n",
    "            'PVI_1': 'PVI',\n",
    "            'VHF_20': 'VHF',\n",
    "            'ATRr_14': 'ATR'\n",
    "        })\n",
    "        return df\n",
    "    \n",
    "    psar = ta.psar(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"], af0=0.02, af=0.02, max_af=0.2)\n",
    "    psar[\"PSAR\"] = psar[\"PSARl_0.02_0.2\"].combine_first(psar[\"PSARs_0.02_0.2\"])\n",
    "    psar.drop([\"PSARl_0.02_0.2\", \"PSARs_0.02_0.2\"], axis=1, inplace=True)\n",
    "    macd = ta.macd(close=df[\"Close\"], fast=20, slow=50, signal=9)\n",
    "    tsi = ta.tsi(close=df[\"Close\"], fast=13, slow=25)\n",
    "    supertrend = ta.supertrend(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"], length=20, multiplier=3)\n",
    "    supertrend.drop([\"SUPERTl_20_3.0\", \"SUPERTs_20_3.0\"], axis=1, inplace=True)\n",
    "    ema5 = ta.ema(close=df[\"Close\"], length=5)\n",
    "    ema20 = ta.ema(close=df[\"Close\"], length=20)\n",
    "    ema50 = ta.ema(close=df[\"Close\"], length=50)\n",
    "    ema100 = ta.ema(close=df[\"Close\"], length=100)\n",
    "    adx = ta.adx(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"], length=20)\n",
    "    roc = ta.roc(close=df[\"Close\"], length=10)\n",
    "    cmf = ta.cmf(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"], volume=df['Volume'], length=10)\n",
    "    trix = ta.trix(close=df['Close'], length=18)\n",
    "    klinger = ta.kvo(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"], volume=df['Volume'], short=34, long=55)\n",
    "    vi = ta.vortex(high=df['High'], low=df['Low'], close=df['Close'], length=20)\n",
    "    aroon = ta.aroon(high=df['High'], low=df['Low'], close=df['Close'], length=20)\n",
    "    nvi = ta.nvi(close=df['Close'], volume=df['Volume'])\n",
    "    pvi = ta.pvi(close=df['Close'], volume=df['Volume'])\n",
    "    vhf = ta.vhf(close=df['Close'], length=20)\n",
    "    atr = ta.atr(high=df['High'], low=df['Low'], close=df['Close'])\n",
    "    obv = ta.obv(close=df[\"Close\"], volume=df[\"Volume\"])\n",
    "    #candele = ta.cdl_pattern(open_=df[\"Open\"], high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"])\n",
    "\n",
    "    df = pd.concat([df, ema5, ema20, ema50, ema100, psar, macd, tsi, supertrend, adx, trix, vi, aroon, nvi, pvi, atr, cmf, roc, klinger, vhf, obv], axis=1)\n",
    "\n",
    "    df = __rinomina_colonne(df)\n",
    "    \n",
    "    #df['HLC3'] = ((df['High'] + df['Low'] + df['Close']) / 3)\n",
    "    df[\"DM_OSC\"] = (df[\"DMP\"] - df[\"DMN\"])\n",
    "    df[\"VTX_OSC\"] = (df[\"VTXP\"] - df[\"VTXM\"])\n",
    "    df[\"VI_OSC\"] = (df[\"PVI\"] - df[\"NVI\"])\n",
    "    \n",
    "    df.drop(columns=[\"DMP\", \"DMN\", \"VTXP\", \"VTXM\", \"PVI\", \"NVI\", \"AROOND\", \"AROONU\"], inplace=True, axis=1)\n",
    "    \n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    return df\n",
    "\n",
    "def _scarica(nome_simbolo, scarica_prima, scarica_dopo, data_inizio, data_fine, append):\n",
    "    try:\n",
    "        if append == True:\n",
    "            ticker = pd.read_hdf(f'tickers/{nome_simbolo}.h5', \"ticker\")\n",
    "            ti_min = ticker.index.min()\n",
    "            ti_max = ticker.index.max()\n",
    "            if scarica_prima:\n",
    "                inizio = data_inizio - pd.Timedelta(days=365)\n",
    "                fine = ti_min - pd.Timedelta(days=1)\n",
    "                df_inizio = analizza_ticker(nome_simbolo, start=inizio, end=fine, progress=False, dropna_iniziali=True, dropna_finali=False)\n",
    "                ticker = pd.concat([df_inizio, ticker], axis=0, ignore_index=False)\n",
    "            if scarica_dopo:\n",
    "                inizio = ti_max - pd.Timedelta(days=365) \n",
    "                fine = data_fine\n",
    "                df_fine = analizza_ticker(nome_simbolo, start=inizio, end=fine, progress=False, dropna_iniziali=True, dropna_finali=False)\n",
    "                ticker = ticker[ticker.index < df_fine.index.min()]\n",
    "                ticker = pd.concat([ticker, df_fine], axis=0, ignore_index=False)\n",
    "        else:\n",
    "            ticker = analizza_ticker(nome_simbolo, start=data_inizio, end=data_fine, progress=False, dropna_iniziali=True, dropna_finali=False)\n",
    "        return nome_simbolo, ticker, \"\"\n",
    "    except Exception as e:\n",
    "        return nome_simbolo, None, str(e)\n",
    "\n",
    "def _callback_tickers(result, totale_processati, tot_tickers):\n",
    "    nome_simbolo, ticker, error = result\n",
    "    if error == \"\":\n",
    "        ticker.to_hdf(f'tickers/{nome_simbolo}.h5', key='ticker', mode='w')\n",
    "    else:\n",
    "        print(f\"Errore su funzione di callback per {nome_simbolo}: {error}\")\n",
    "\n",
    "    with totale_processati.get_lock(): \n",
    "        totale_processati.value += 1\n",
    "    print(f\"{totale_processati.value}/{tot_tickers}) Scaricato ticker {nome_simbolo}\")   \n",
    "    \n",
    "def _carica_screener(nome_simbolo, lista_scr, prob, percorso_e_nome_file):\n",
    "    try:\n",
    "        df = pd.read_hdf(percorso_e_nome_file, 'screener')\n",
    "        df.index.set_names(['Data'], inplace=True)\n",
    "        df['Ticker'] = nome_simbolo\n",
    "        df.set_index('Ticker', append=True, inplace=True)\n",
    "        df = df.loc[df['Previsione'] > prob]\n",
    "        lista_scr.append(df)\n",
    "        return nome_simbolo, \"\"\n",
    "    except Exception as e:\n",
    "        return nome_simbolo, str(e)\n",
    "\n",
    "def _carica_screener_callback(result, totale_processati, tot_tickers):\n",
    "    nome_simbolo, error = result\n",
    "    if error != \"\":\n",
    "        print(f\"Errore su funzione di callback per {nome_simbolo}: {error}\")\n",
    "\n",
    "    with totale_processati.get_lock(): \n",
    "        totale_processati.value += 1\n",
    "    print(f\"{totale_processati.value}/{tot_tickers}) Caricato su screener ticker {nome_simbolo}\")   \n",
    "\n",
    "def to_XY(dati_ticker, timesteps, giorni_previsione, features, targets, bilanciamento=0):\n",
    "    dati_ticker = imposta_target(dati_ticker)\n",
    "    features_scala_prezzo = [ft for ft in _features_scala_prezzo_tutte if ft in features]\n",
    "    features_da_scalare_singolarmente = [ft for ft in _features_da_scalare_singolarmente_tutte if ft in features]\n",
    "    features_oscillatori = [ft for ft in _features_oscillatori_tutte if ft in features]\n",
    "    features_no_scala = [ft for ft in _features_no_scala_tutte if ft in features]\n",
    "    features_candele = [ft for ft in _features_candele_tutte if ft in features]\n",
    "\n",
    "    scalers_prezzo = []\n",
    "    scaler_meno_piu = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler_standard = MinMaxScaler()\n",
    "\n",
    "    new_dates = pd.bdate_range(start=dati_ticker.index[-1] + pd.Timedelta(days=1), periods=giorni_previsione)\n",
    "    df_new = pd.DataFrame(index=new_dates)\n",
    "    dati_ticker = pd.concat([dati_ticker, df_new])\n",
    "\n",
    "    ft_prezzo = dati_ticker[features_scala_prezzo]\n",
    "    ft_standard = dati_ticker[features_da_scalare_singolarmente]\n",
    "    ft_meno_piu = dati_ticker[features_oscillatori]\n",
    "    ft_no_scala = dati_ticker[features_no_scala]\n",
    "    ft_candele = dati_ticker[features_candele] \n",
    "\n",
    "    _targets = dati_ticker[targets]\n",
    "\n",
    "    i_tot = len(dati_ticker) - giorni_previsione\n",
    "\n",
    "    tot_elementi = i_tot - (timesteps-1)    \n",
    "    \n",
    "    X_prezzo = X_standard = X_meno_piu = X_no_scala = X_candele = None\n",
    "    if len(features_scala_prezzo) > 0:\n",
    "        tot_col_prezzo_x = len(ft_prezzo.columns)\n",
    "        X_prezzo = np.zeros((tot_elementi, timesteps, tot_col_prezzo_x))\n",
    "    if len(features_da_scalare_singolarmente) > 0:\n",
    "        tot_col_standard_x = len(ft_standard.columns)\n",
    "        X_standard = np.zeros((tot_elementi, timesteps, tot_col_standard_x))\n",
    "    if len(features_oscillatori) > 0:\n",
    "        tot_col_meno_piu_x = len(ft_meno_piu.columns)\n",
    "        X_meno_piu = np.zeros((tot_elementi, timesteps, tot_col_meno_piu_x))\n",
    "    if len(features_no_scala) > 0:\n",
    "        tot_col_no_scala_x = len(ft_no_scala.columns)\n",
    "        X_no_scala = np.zeros((tot_elementi, timesteps, tot_col_no_scala_x))\n",
    "    if len(features_candele) > 0:\n",
    "        tot_col_candele_x = len(ft_candele.columns)\n",
    "        X_candele = np.zeros((tot_elementi, timesteps, tot_col_candele_x))\n",
    "    if len(targets) > 0:\n",
    "        #tot_col_targets_y = len(targets.columns)\n",
    "        #Y = np.zeros((tot_elementi, giorni_previsione, tot_col_targets_y)) # togliere se classificazione binaria\n",
    "        Y = np.zeros(tot_elementi) #solo per classificazione binaria\n",
    "    \n",
    "    for i in range(timesteps - 1, i_tot):\n",
    "        if len(features_scala_prezzo) > 0:\n",
    "            arr_x = np.array(ft_prezzo.iloc[i - (timesteps - 1):i + 1])\n",
    "            arr_res = arr_x.reshape(-1, 1)\n",
    "            scaler_prezzo = MinMaxScaler()\n",
    "            scaler_prezzo.fit(arr_res)\n",
    "            arr_sc = scaler_prezzo.transform(arr_res).reshape(timesteps, tot_col_prezzo_x)\n",
    "            X_prezzo[i - (timesteps - 1)] = arr_sc\n",
    "            scalers_prezzo.append(scaler_prezzo)\n",
    "\n",
    "        if len(features_da_scalare_singolarmente) > 0:\n",
    "            arr_x = np.array(ft_standard.iloc[i - (timesteps - 1):i + 1])\n",
    "            arr_sc = scaler_standard.fit_transform(arr_x)   \n",
    "            X_standard[i - (timesteps - 1)] = arr_sc\n",
    "\n",
    "        if len(features_oscillatori) > 0:\n",
    "            arr_x = np.array(ft_meno_piu.iloc[i - (timesteps - 1):i + 1])\n",
    "            arr_sc = scaler_meno_piu.fit_transform(arr_x)   \n",
    "            X_meno_piu[i - (timesteps - 1)] = arr_sc\n",
    "\n",
    "        if len(features_no_scala) > 0:\n",
    "            arr_x = np.array(ft_no_scala.iloc[i - (timesteps - 1):i + 1])\n",
    "            X_no_scala[i - (timesteps - 1)] = arr_x\n",
    "\n",
    "        if len(features_candele) > 0:\n",
    "            arr_x = np.array(ft_candele.iloc[i - (timesteps - 1):i + 1])\n",
    "            arr_sc = scaler_meno_piu.fit_transform(arr_x) \n",
    "            X_candele[i - (timesteps - 1)] = arr_sc\n",
    "\n",
    "        if len(targets) > 0:\n",
    "            # arr_y = np.array(targets.iloc[i + 1:i + 1 + giorni_previsione]) # togliere in caso di classificazione binaria\n",
    "            # arr_res = arr_y.reshape(-1, 1) # togliere in caso di classificazione binaria\n",
    "            # arr_sc = scaler_prezzo.transform(arr_res).reshape(giorni_previsione, tot_col_targets_y) # togliere in caso di classificazione binaria\n",
    "            # Y[i - (timesteps - 1)] = arr_sc  # togliere in caso di classificazione binaria\n",
    "            Y[i - (timesteps - 1)] = np.array(_targets.iloc[i]) #solo per classificazione binaria\n",
    "\n",
    "    X_list = [x for x in [X_prezzo, X_standard, X_meno_piu, X_no_scala, X_candele] if x is not None and x.size > 0]\n",
    "    X = np.concatenate(X_list, axis=2) if X_list else np.array([])\n",
    "    idx = dati_ticker.index[timesteps - 1:i_tot]\n",
    "\n",
    "    if bilanciamento > 0:\n",
    "        #rus = RandomUnderSampler(sampling_strategy=bilanciamento)\n",
    "        smote = SMOTE(sampling_strategy=bilanciamento)\n",
    "        dim1 = X.shape[1]\n",
    "        dim2 = X.shape[2]\n",
    "        X_flat = X.reshape(-1, dim1 * dim2)\n",
    "        # Applica l'undersampling\n",
    "        X_flat_resampled, Y = smote.fit_resample(X_flat, Y)\n",
    "\n",
    "        # Ridimensiona X tornando alla forma originale\n",
    "        X = X_flat_resampled.reshape(-1, dim1, dim2)\n",
    "\n",
    "        # Ottieni gli indici originali dopo l'undersampling\n",
    "        #idx_resampled = rus.sample_indices_\n",
    "\n",
    "        # Usa idx_resampled per ottenere gli indici originali\n",
    "        #idx = idx[idx_resampled]\n",
    "\n",
    "    Y = Y.reshape(-1, 1)\n",
    "    return idx, X, Y, scalers_prezzo\n",
    "\n",
    "def concatena(array_list, hdf5_file, dataset_name):\n",
    "    \"\"\"\n",
    "    Concatena una lista di array NumPy a un dataset in un file HDF5, creando il file se non esiste.\n",
    "    \n",
    "    :param array_list: Lista di array NumPy da aggiungere.\n",
    "    :param hdf5_file: Percorso del file HDF5.\n",
    "    :param dataset_name: Nome del dataset all'interno del file HDF5.\n",
    "    \"\"\"\n",
    "    # Apri o crea il file HDF5\n",
    "    with h5py.File(hdf5_file, 'a') as h5f:  # 'a' apre il file in modalità read/write e lo crea se non esiste\n",
    "        # Controlla se il dataset esiste già\n",
    "        if dataset_name in h5f:\n",
    "            # Il dataset esiste, leggi la sua lunghezza e aggiungi gli array\n",
    "            dset = h5f[dataset_name]\n",
    "        else:\n",
    "            # Il dataset non esiste, quindi dobbiamo crearlo\n",
    "            # Usiamo la forma del primo array per definire la forma del dataset\n",
    "            initial_shape = (0,) + array_list[0].shape[1:]\n",
    "            maxshape = (None,) + array_list[0].shape[1:]\n",
    "            \n",
    "            # Crea il dataset con shape iniziale e maxshape\n",
    "            dset = h5f.create_dataset(dataset_name, shape=initial_shape, maxshape=maxshape, chunks=True)\n",
    "            \n",
    "        # Itera su tutti gli array nella lista\n",
    "        for array in array_list:\n",
    "            # Calcola la nuova lunghezza del dataset\n",
    "            new_len = dset.shape[0] + array.shape[0]\n",
    "            # Ridimensiona il dataset per accogliere i nuovi dati\n",
    "            dset.resize(new_len, axis=0)\n",
    "            # Aggiungi il nuovo array alla fine del dataset\n",
    "            dset[-array.shape[0]:] = array\n",
    "\n",
    "def crea_cartella(percorso_e_nome_cartella):\n",
    "    if not os.path.exists(percorso_e_nome_cartella):\n",
    "        os.makedirs(percorso_e_nome_cartella)\n",
    "\n",
    "class Borsa:\n",
    "    def __init__(self, n_simboli_contemporanei=10, bilancio_iniziale=1000, probabilità_per_acquisto=0.5, giorni_max_posizione=20, stop_loss=None, take_profit=None, data_inizio=pd.Timestamp(year=2005, month=1, day=1), data_fine=pd.Timestamp.now().normalize(), nome_modello='mod_1_in'):\n",
    "        self.N_SIMBOLI = n_simboli_contemporanei\n",
    "        self.DATA_INIZIO = pd.to_datetime(data_inizio)\n",
    "        self.DATA_FINE = pd.to_datetime(data_fine)\n",
    "        self.BILANCIO_INIZIALE = bilancio_iniziale\n",
    "        self.PROBABILITA_PER_ACQUISTO = probabilità_per_acquisto\n",
    "        self.SL = stop_loss\n",
    "        self.TP = take_profit\n",
    "        self.GIORNI_POS = giorni_max_posizione\n",
    "\n",
    "        self.nome_modello = nome_modello\n",
    "        self.modello_ingresso = Modello()\n",
    "        self.modello_ingresso.carica(progetto=self.nome_modello)\n",
    "        self.timesteps = self.modello_ingresso.timesteps\n",
    "        self.giorni_previsione = self.modello_ingresso.giorni_previsione\n",
    "        self.features = self.modello_ingresso.features\n",
    "        self.targets = self.modello_ingresso.targets\n",
    "        \n",
    "        self.lista_tickers = pd.read_parquet(\"lista_ticker.parquet\")\n",
    "        self.tot_tickers = len(self.lista_tickers)\n",
    "        self.screener = pd.DataFrame()\n",
    "\n",
    "    def _verifica_date_aggiornamento(self, nome_file='_indice.json'):\n",
    "        if os.path.exists(nome_file):\n",
    "            file_esistente = True\n",
    "            with open(nome_file, 'r') as jsonfile:\n",
    "                indice = json.load(jsonfile)\n",
    "            prima_data = pd.to_datetime(indice['prima_data'])\n",
    "            ultima_data = pd.to_datetime(indice['ultima_data'])\n",
    "            \n",
    "            if (self.DATA_INIZIO < prima_data):\n",
    "                scarica_prima = True\n",
    "            else:\n",
    "                scarica_prima = False\n",
    "\n",
    "            if (self.DATA_FINE > ultima_data):\n",
    "                scarica_dopo = True\n",
    "            else:\n",
    "                scarica_dopo = False\n",
    "        else:\n",
    "            file_esistente=False\n",
    "            scarica_prima = True\n",
    "            scarica_dopo = True\n",
    "        return file_esistente, scarica_prima, scarica_dopo\n",
    "\n",
    "    def aggiorna_dati(self):\n",
    "        try:\n",
    "            file_esistente, scarica_prima, scarica_dopo = self._verifica_date_aggiornamento('_indice.json')\n",
    "            if file_esistente:\n",
    "                if scarica_prima or scarica_dopo:\n",
    "                    print('Caricamento nuovi dati ticker')\n",
    "                    self.scarica_tickers(scarica_prima, scarica_dopo, append=True)\n",
    "                    print('Aggiornamento lista tickers')  \n",
    "                    self.aggiorna_lista_tickers()      \n",
    "            else:\n",
    "                print('Scarico totale dati ticker')\n",
    "                self.scarica_tickers(scarica_prima=True, scarica_dopo=True, append=False) \n",
    "                print('Aggiornamento lista tickers')  \n",
    "                self.aggiorna_lista_tickers()       \n",
    "                \n",
    "            file_esistente, scarica_prima, scarica_dopo = self._verifica_date_aggiornamento(f'{self.nome_modello}/_indice_screeners.json')\n",
    "            if file_esistente:\n",
    "                if scarica_prima or scarica_dopo:\n",
    "                    print('Aggiornamento screener')\n",
    "                    self.avvia_screener(append=True)    \n",
    "                else:\n",
    "                    print('Caricamento screener esistenti')\n",
    "                    self.screener = pd.read_hdf(f'{self.nome_modello}/screeners/_screener.h5', 'screener')\n",
    "            else:\n",
    "                print('Creazione nuovi screener')\n",
    "                self.avvia_screener(append=False)                 \n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "        \n",
    "    def scarica_tickers(self, scarica_prima=True, scarica_dopo=True, append=False) -> None: \n",
    "        totale_processati = Value('i', 0)\n",
    "        data_inizio = self.DATA_INIZIO\n",
    "        data_fine = self.DATA_FINE\n",
    "        with Pool(cpu_count()) as p:\n",
    "            callback_with_args = partial(_callback_tickers, totale_processati=totale_processati, tot_tickers=self.tot_tickers)\n",
    "            for i in range(0, self.tot_tickers):\n",
    "                nome_simbolo = self.lista_tickers.iloc[i][\"Ticker\"]\n",
    "                param = (nome_simbolo, scarica_prima, scarica_dopo, data_inizio, data_fine, append)\n",
    "                p.apply_async(_scarica, args=param, callback=callback_with_args)\n",
    "            p.close()\n",
    "            p.join()     \n",
    "\n",
    "        indice = {\n",
    "            'prima_data': data_inizio.strftime('%Y-%m-%d'),\n",
    "            'ultima_data': data_fine.strftime('%Y-%m-%d')\n",
    "        }\n",
    "        with open(f'_indice.json', 'w') as jsonfile:\n",
    "            json.dump(indice, jsonfile, indent=4)    \n",
    "\n",
    "    def aggiorna_lista_tickers(self):\n",
    "        cartella_tickers = 'tickers'\n",
    "        cartella_screeners = f'{self.nome_modello}/screeners'\n",
    "        files_tickers = os.listdir(cartella_tickers)\n",
    "\n",
    "        tickers_da_rimuovere = []\n",
    "\n",
    "        for file in files_tickers:\n",
    "            percorso_file = os.path.join(cartella_tickers, file)\n",
    "\n",
    "            # Controlla il numero di righe nel file HDF5\n",
    "            try:\n",
    "                df_temp = pd.read_hdf(percorso_file)\n",
    "                if len(df_temp) < 100:\n",
    "                    # Elimina il file da tickers\n",
    "                    os.remove(percorso_file)\n",
    "\n",
    "                    # Elimina il corrispondente file in screeners\n",
    "                    percorso_file_screener = os.path.join(cartella_screeners, file)\n",
    "                    if os.path.exists(percorso_file_screener):\n",
    "                        os.remove(percorso_file_screener)\n",
    "\n",
    "                    # Aggiungi il nome del ticker alla lista dei tickers da rimuovere\n",
    "                    nome_ticker = os.path.splitext(file)[0]\n",
    "                    tickers_da_rimuovere.append(nome_ticker)\n",
    "            except Exception as e:\n",
    "                print(f\"Errore nella lettura del file {file}: {e}\")\n",
    "\n",
    "        # Rimuovi i tickers dalla lista\n",
    "        self.lista_tickers = self.lista_tickers[~self.lista_tickers['Ticker'].isin(tickers_da_rimuovere)]\n",
    "\n",
    "        # Aggiorna la lista dei tickers nel DataFrame\n",
    "        lista_files_aggiornata = os.listdir(cartella_tickers)\n",
    "        lista_files_aggiornata = [os.path.splitext(file)[0] for file in lista_files_aggiornata]\n",
    "        self.lista_tickers = self.lista_tickers[self.lista_tickers['Ticker'].isin(lista_files_aggiornata)]\n",
    "\n",
    "        # Salva il DataFrame aggiornato\n",
    "        self.lista_tickers.to_parquet('lista_ticker.parquet')\n",
    "       \n",
    "    def avvia_screener(self, append=False, inizia_da=0) -> None:\n",
    "        tot_tickers = len(self.lista_tickers)\n",
    "        crea_cartella(f'{self.nome_modello}/screeners')\n",
    "        data_inizio = self.DATA_INIZIO\n",
    "        data_fine = self.DATA_FINE\n",
    "        \n",
    "        for i in range(inizia_da, tot_tickers):\n",
    "            try:\n",
    "                nome_simbolo = self.lista_tickers.iloc[i][\"Ticker\"]\n",
    "                print(\"\\033[42m\" + f'{i+1}/{tot_tickers}) Calcolo screeners per {nome_simbolo}' + \"\\033[0m\")\n",
    "                ticker = pd.read_hdf(f'tickers/{nome_simbolo}.h5', 'ticker')\n",
    "                if append:\n",
    "                    scr = pd.read_hdf(f'{self.nome_modello}/screeners/{nome_simbolo}.h5', 'screener')\n",
    "                    inizio = scr.index.max() - pd.Timedelta(days=365)\n",
    "                    ticker_analisi = ticker.loc[ticker.index >= inizio].copy()\n",
    "                    if scr.index.max() == ticker.index.max():\n",
    "                        scr = scr.drop(scr.index[-1]).copy()\n",
    "                    idx, X, Y, _ = to_XY(dati_ticker=ticker_analisi, timesteps=self.timesteps, giorni_previsione=self.giorni_previsione, features=self.features, targets=self.targets, bilanciamento=0)\n",
    "                    print(f'Aggiornamento previsione {nome_simbolo}')\n",
    "                    pred = self.modello_ingresso.model.predict(X)\n",
    "                    scr_temp = pd.DataFrame({'Previsione': pred.flatten().round(2), 'Reale': Y.flatten()}, index=idx)\n",
    "                    scr_temp = scr_temp.loc[scr_temp.index > scr.index.max()].copy()\n",
    "                    scr = pd.concat([scr, scr_temp], axis=0, ignore_index=False)\n",
    "                    print(f\"Aggiornamento file di screener {nome_simbolo}.h5\")\n",
    "                    scr.to_hdf(f'{self.nome_modello}/screeners/{nome_simbolo}.h5', key='screener', mode='w')\n",
    "                else:\n",
    "                    idx, X, Y, _ = to_XY(dati_ticker=ticker, timesteps=self.timesteps, giorni_previsione=self.giorni_previsione, features=self.features, targets=self.targets, bilanciamento=0)\n",
    "                    print(f'Previsione {nome_simbolo}')\n",
    "                    pred = self.modello_ingresso.model.predict(X)\n",
    "                    scr = pd.DataFrame({'Previsione': pred.flatten().round(2), 'Reale': Y.flatten()}, index=idx)\n",
    "                    scr = scr.loc[scr.index >= self.DATA_INIZIO]\n",
    "                    print(f\"Salvataggio file di screener {nome_simbolo}.h5\")\n",
    "                    scr.to_hdf(f'{self.nome_modello}/screeners/{nome_simbolo}.h5', key='screener', mode='w')\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "        indice = {\n",
    "            'prima_data': data_inizio.strftime('%Y-%m-%d'),\n",
    "            'ultima_data': data_fine.strftime('%Y-%m-%d')\n",
    "        }\n",
    "        with open(f'{self.nome_modello}/_indice_screeners.json', 'w') as jsonfile:\n",
    "            json.dump(indice, jsonfile, indent=4)    \n",
    "        self.carica_screener()\n",
    "        self.screener.to_hdf(f'{self.nome_modello}/screeners/_screener.h5', key='screener', mode='w')\n",
    "\n",
    "    def carica_screener(self):\n",
    "        manager = Manager()\n",
    "        lista_scr = manager.list()\n",
    "        totale_processati = Value('i', 0)\n",
    "        with Pool(cpu_count()) as p:\n",
    "            callback_with_args = partial(_carica_screener_callback, totale_processati=totale_processati, tot_tickers=self.tot_tickers)\n",
    "            for i in range(0, self.tot_tickers):\n",
    "                nome_simbolo = self.lista_tickers.iloc[i][\"Ticker\"]\n",
    "                param = (nome_simbolo, lista_scr, self.PROBABILITA_PER_ACQUISTO, f'{self.nome_modello}/screeners/{nome_simbolo}.h5')\n",
    "                p.apply_async(_carica_screener, args=param, callback=callback_with_args)\n",
    "            p.close()\n",
    "            p.join()  \n",
    "        self.screener = pd.concat(lista_scr, axis=0, ignore_index=False)\n",
    "        self.screener = self.screener.sort_values(by=['Data', 'Previsione'], ascending=[True, False])\n",
    "\n",
    "    def ultimo_screener(self) -> (pd.Timestamp, pd.DataFrame):\n",
    "        # Ottieni l'ultimo valore dell'indice di livello 0\n",
    "        ultimo_indice = self.screener.index.get_level_values(0)[-1]\n",
    "        # Usa .loc per selezionare tutte le righe con quell'indice di livello 0\n",
    "        return ultimo_indice.date(), self.screener.loc[ultimo_indice]\n",
    "\n",
    "    def calcola_n_azioni(self, prezzo_unitario_acquisto, budget_per_simbolo):\n",
    "        commissione_massima = self.applica_commissione(budget_per_simbolo)\n",
    "        n_azioni_acquisto = (budget_per_simbolo - commissione_massima) // prezzo_unitario_acquisto\n",
    "        return n_azioni_acquisto\n",
    "\n",
    "    def compra(self, data, simbolo, prezzo_unitario_acquisto, n_azioni_acquisto):\n",
    "        prezzo_azioni = prezzo_unitario_acquisto * n_azioni_acquisto\n",
    "        commissione = self.applica_commissione(prezzo_azioni)\n",
    "        totale_transazione = prezzo_azioni + commissione \n",
    "        SL = prezzo_unitario_acquisto * (1 - self.SL) if self.SL is not None else -1\n",
    "        TP = prezzo_unitario_acquisto * (1 + self.TP) if self.TP is not None else np.inf\n",
    "        posizione = {\n",
    "            'data': data.date(),\n",
    "            'simbolo': simbolo,\n",
    "            'prezzo_unitario': prezzo_unitario_acquisto,\n",
    "            'n_azioni': n_azioni_acquisto,\n",
    "            'commissione': -commissione, \n",
    "            'totale_transazione': -totale_transazione,\n",
    "            'SL': SL, \n",
    "            'TP': TP,\n",
    "            'giorni_apertura': 1,\n",
    "            'movimento': 'ACQUISTO'\n",
    "        }\n",
    "        return posizione\n",
    "\n",
    "    def vendi(self, data, simbolo, prezzo_unitario_vendita, n_azioni_vendita):\n",
    "        prezzo_azioni = prezzo_unitario_vendita * n_azioni_vendita\n",
    "        commissione = self.applica_commissione(prezzo_azioni)\n",
    "        totale_transazione = prezzo_azioni - commissione \n",
    "        SL = None\n",
    "        TP = None\n",
    "        posizione = {\n",
    "            'data': data.date(),\n",
    "            'simbolo': simbolo,\n",
    "            'prezzo_unitario': prezzo_unitario_vendita,\n",
    "            'n_azioni': n_azioni_vendita,\n",
    "            'commissione': -commissione, \n",
    "            'totale_transazione': totale_transazione,\n",
    "            'SL': SL, \n",
    "            'TP': TP,\n",
    "            'movimento': 'VENDITA'\n",
    "        }\n",
    "        return posizione\n",
    "    \n",
    "    def simulazione_trading(self):\n",
    "        print('Inizio simulazione trading')\n",
    "        screener = self.screener.loc[(self.screener.index.get_level_values(0) >= self.DATA_INIZIO, slice(None)), :]\n",
    "        self.posizioni_aperte = pd.DataFrame(columns=['data', 'simbolo', 'prezzo_apertura', 'valore_apertura', 'prezzo_chiusura', 'valore_chiusura', 'prezzo_attuale', 'valore_attuale', 'P_L_perc', 'P_L_valore', 'n_azioni', 'commissione', 'totale_transazione', 'SL', 'TP', 'giorni_apertura', 'movimento', 'open', 'high', 'low', 'close'])    \n",
    "        self.storico = pd.DataFrame(columns=['data', 'simbolo', 'prezzo_apertura', 'valore_apertura', 'prezzo_chiusura', 'valore_chiusura', 'prezzo_attuale', 'valore_attuale', 'P_L_perc', 'P_L_valore', 'n_azioni', 'commissione', 'totale_transazione', 'SL', 'TP', 'giorni_apertura', 'movimento', 'open', 'high', 'low', 'close'])\n",
    "        self.stato = pd.DataFrame(columns=['data', 'bilancio', 'n_pos_aperte', 'valore_pos_aperte', 'budget_per_simbolo'])\n",
    "        self.previsioni = pd.DataFrame(columns=['simbolo', 'previsione'])\n",
    "        bilancio = self.BILANCIO_INIZIALE\n",
    "        n_posizioni_libere = self.N_SIMBOLI - len(self.posizioni_aperte)\n",
    "        budget_per_simbolo = bilancio / n_posizioni_libere if n_posizioni_libere != 0 else 0      \n",
    "        data_corrente = self.DATA_INIZIO\n",
    "        while data_corrente <= self.DATA_FINE:\n",
    "            \n",
    "            # APERTURA BORSA\n",
    "            \n",
    "            print(f\"\\033[42m {data_corrente.date()} \\033[0m\")\n",
    "\n",
    "            for i, previsione in self.previsioni.iterrows():\n",
    "                simbolo = previsione['simbolo']\n",
    "                ticker = pd.read_hdf(f'tickers/{simbolo}.h5', 'ticker')    \n",
    "                if data_corrente in ticker.index:\n",
    "                    prezzi_del_giorno = ticker.loc[data_corrente]\n",
    "                    prezzo_unitario = prezzi_del_giorno['Open']\n",
    "                    if (previsione['previsione'] == 'VENDI') and (simbolo in self.posizioni_aperte['simbolo']):\n",
    "                        n_azioni = self.posizioni_aperte.loc[self.posizioni_aperte['simbolo'] == simbolo, 'n_azioni']\n",
    "                        prezzo_tot = prezzo_unitario * n_azioni\n",
    "                        posizione = self.vendi(data_corrente, simbolo, prezzo_unitario, n_azioni)\n",
    "                        for simbolo in self.posizioni_aperte:\n",
    "                            # Trova gli indici delle righe dove la colonna 'simbolo' ha il valore specificato\n",
    "                            indici_da_eliminare = self.posizioni_aperte[self.posizioni_aperte['simbolo'] == simbolo].index\n",
    "                            # Elimina queste righe\n",
    "                            self.posizioni_aperte.drop(indici_da_eliminare, inplace=True)\n",
    "\n",
    "                        bilancio += posizione['totale_transazione']\n",
    "                        df_pos = pd.DataFrame([posizione])\n",
    "                        self.storico = pd.concat([self.storico, df_pos], ignore_index=True)\n",
    "                        print(f\"VENDITA {simbolo} n. {n_azioni} azioni a {prezzo_unitario}, Tot.trans. {posizione['totale_transazione']}, nuovo bilancio: {bilancio}\")\n",
    "                    elif previsione['previsione'] == 'COMPRA':\n",
    "                        n_azioni = self.calcola_n_azioni(prezzo_unitario, budget_per_simbolo)\n",
    "                        prezzo_tot = prezzo_unitario * n_azioni\n",
    "                        commissione = self.applica_commissione(prezzo_tot)\n",
    "                        if (prezzo_tot + commissione) <= budget_per_simbolo:\n",
    "                            posizione = self.compra(data_corrente, simbolo, prezzo_unitario, n_azioni) \n",
    "                            df_pos = pd.DataFrame([posizione])\n",
    "                            self.posizioni_aperte = pd.concat([self.posizioni_aperte, df_pos], ignore_index=True)\n",
    "                            bilancio += posizione['totale_transazione']\n",
    "                            self.storico = pd.concat([self.storico, df_pos], ignore_index=True)\n",
    "                            print(f\"ACQUISTO {simbolo} n. {posizione['n_azioni']} azioni a {prezzo_unitario}, Tot.trans. {posizione['totale_transazione']}, nuovo bilancio: {bilancio}\")\n",
    "                                \n",
    "            # CHIUSURA BORSA\n",
    "            \n",
    "            n_posizioni_libere = self.N_SIMBOLI - len(self.posizioni_aperte)\n",
    "            budget_per_simbolo = bilancio / n_posizioni_libere if n_posizioni_libere != 0 else 0\n",
    "            self.previsioni = pd.DataFrame(columns=['simbolo', 'previsione'])\n",
    "            \n",
    "            posizioni_da_eliminare = [] # Conterrà le posizioni che vanno in SL o TP\n",
    "            # Calcolo valore posizioni aperte e posizioni da chiudere\n",
    "            for _, pos in self.posizioni_aperte.iterrows():\n",
    "                simbolo = pos['simbolo']\n",
    "                ticker = pd.read_hdf(f'tickers/{simbolo}.h5', 'ticker') \n",
    "                if data_corrente in ticker.index:\n",
    "                    giorni_apertura = pos['giorni_apertura']\n",
    "                    prezzi_del_giorno = ticker.loc[data_corrente]\n",
    "                    pos['open'] = prezzi_del_giorno['Open']\n",
    "                    pos['close'] = prezzi_del_giorno['Close']\n",
    "                    pos['high'] = prezzi_del_giorno['High']\n",
    "                    pos['low'] = prezzi_del_giorno['Low']\n",
    "                    prezzo_unitario = prezzi_del_giorno['Close']\n",
    "                    n_azioni = pos['n_azioni']\n",
    "                    importo_totale = prezzo_unitario * n_azioni\n",
    "                    pos['giorni_apertura'] += 1\n",
    "                    pos['prezzo_attuale'] = prezzo_unitario  \n",
    "                    pos['valore_attuale'] = importo_totale\n",
    "                    pos['P_L_perc'] = pct_change(pos['prezzo_apertura'], pos['prezzo_attuale'])   \n",
    "                    pos['P_L_valore'] = pos['valore_attuale'] - pos['valore_apertura'] \n",
    "                    pos['movimento'] = 'TIENI'\n",
    "                                  \n",
    "                    # Verifica condizioni per chiusura posizioni\n",
    "                    \n",
    "                    # 1) Se scatta lo Stop Loss o il Take Profit chiude in automatico la posizione\n",
    "                    if prezzo_unitario < pos['SL']:                       \n",
    "                        posizione = self.vendi(data_corrente, simbolo, prezzo_unitario, n_azioni)\n",
    "                        posizioni_da_eliminare.append(simbolo)\n",
    "                        bilancio += posizione['totale_transazione']\n",
    "                        posizione['movimento'] = 'VENDITA SU STOP LOSS'\n",
    "                        posizione['prezzo_chiusura'] = pos['SL']\n",
    "                        df_pos = pd.DataFrame([posizione])\n",
    "                        self.storico = pd.concat([self.storico, df_pos], ignore_index=True)\n",
    "                        print(f'VENDITA SU STOP LOSS {simbolo}')\n",
    "                    elif prezzo_unitario > pos['TP']:                       \n",
    "                        posizione = self.vendi(data_corrente, simbolo, prezzo_unitario, n_azioni)\n",
    "                        posizioni_da_eliminare.append(simbolo)\n",
    "                        bilancio += posizione['totale_transazione']\n",
    "                        posizione['movimento'] = 'VENDITA SU TAKE PROFIT'\n",
    "                        df_pos = pd.DataFrame([posizione])\n",
    "                        self.storico = pd.concat([self.storico, df_pos], ignore_index=True)\n",
    "                        print(f'VENDITA SU TAKE PROFIT {simbolo}')\n",
    "                    elif giorni_apertura > self.GIORNI_POS:                       \n",
    "                        posizione = self.vendi(data_corrente, simbolo, prezzo_unitario, n_azioni)\n",
    "                        posizioni_da_eliminare.append(simbolo)\n",
    "                        bilancio += posizione['totale_transazione']\n",
    "                        posizione['movimento'] = 'VENDITA SU MAX GIORNI APERTURA'\n",
    "                        df_pos = pd.DataFrame([posizione])\n",
    "                        self.storico = pd.concat([self.storico, df_pos], ignore_index=True)\n",
    "                        print(f'VENDITA SU MAX GIORNI APERTURA {simbolo}')                      \n",
    "                                             \n",
    "                    # 2) Verifica le condizioni per la chiusura manuale il giorno successivo\n",
    "                    \n",
    "                    # CONDIZIONI BASATE SU SCREENER OUT\n",
    "                    # if data_corrente in screener_out.index:\n",
    "                    #     screener_out_corrente = screener_out.loc[data_corrente]  \n",
    "                    #     if simbolo in screener_out_corrente:\n",
    "                    #         prev = pd.DataFrame([{\n",
    "                    #             'simbolo': simbolo,\n",
    "                    #             'previsione': 'VENDI'\n",
    "                    #         }])\n",
    "                    #         self.previsioni = pd.concat([self.previsioni, prev])                   \n",
    "         \n",
    "            for simbolo in posizioni_da_eliminare:\n",
    "                # Trova gli indici delle righe dove la colonna 'simbolo' ha il valore specificato\n",
    "                indici_da_eliminare = self.posizioni_aperte[self.posizioni_aperte['simbolo'] == simbolo].index\n",
    "                # Elimina queste righe\n",
    "                self.posizioni_aperte.drop(indici_da_eliminare, inplace=True)\n",
    "\n",
    "            n_posizioni_libere = self.N_SIMBOLI - len(self.posizioni_aperte) \n",
    "            budget_per_simbolo = bilancio / n_posizioni_libere if n_posizioni_libere != 0 else 0                     \n",
    "\n",
    "            # Verifica condizioni per apertura nuove posizioni\n",
    "            if data_corrente in screener.index:\n",
    "                screener_corrente = screener.loc[data_corrente]           \n",
    "                i_scr = 0\n",
    "                while (n_posizioni_libere > 0) and (i_scr < len(screener_corrente)) and (budget_per_simbolo > 0):\n",
    "                    # Condizioni per apertura posizione\n",
    "                    simbolo = screener_corrente.index[i_scr]  \n",
    "                    if simbolo not in self.posizioni_aperte:                  \n",
    "                        ticker = pd.read_hdf(f'tickers/{simbolo}.h5', 'ticker')    \n",
    "                        prezzi_del_giorno = ticker.loc[data_corrente]\n",
    "                        prezzo_unitario_acquisto = prezzi_del_giorno['Close']\n",
    "                        n_azioni = self.calcola_n_azioni(prezzo_unitario_acquisto, budget_per_simbolo)\n",
    "                        prezzo_tot = prezzo_unitario_acquisto * n_azioni\n",
    "                        commissione = self.applica_commissione(prezzo_tot)\n",
    "                        if (prezzo_tot + commissione) <= budget_per_simbolo:\n",
    "                            posizione = self.compra(data_corrente, simbolo, prezzo_unitario_acquisto, n_azioni) \n",
    "                            prev = pd.DataFrame([{\n",
    "                                'simbolo': simbolo, \n",
    "                                'previsione': 'COMPRA'\n",
    "                            }])\n",
    "                            self.previsioni = pd.concat([self.previsioni, prev], ignore_index=True)\n",
    "                            n_posizioni_libere -= 1\n",
    "                    i_scr += 1\n",
    "            \n",
    "            # Calcolo situazione a fine giornata\n",
    "            stato_attuale = {\n",
    "                'data': data_corrente.date(),\n",
    "                'bilancio': bilancio,\n",
    "                'n_pos_aperte': len(self.posizioni_aperte),\n",
    "                'valore_pos_aperte': valore_pos_aperte, \n",
    "                'budget_per_simbolo': budget_per_simbolo\n",
    "            }\n",
    "            print(f\"Data: {stato_attuale['data']}, Bilancio: {stato_attuale['bilancio']}, N. pos aperte: {stato_attuale['n_pos_aperte']}, Valore pos aperte:{stato_attuale['valore_pos_aperte']}, Budget per simbolo: {stato_attuale['budget_per_simbolo']}, BILANCIO TOT.:{stato_attuale['bilancio'] + stato_attuale['valore_pos_aperte']}\")\n",
    "            stato_attuale_df = pd.DataFrame([stato_attuale])\n",
    "            self.stato = pd.concat([self.stato, stato_attuale_df])\n",
    "            \n",
    "            # Passa al giorno successivo\n",
    "            data_corrente += pd.Timedelta(days=1)   \n",
    "         \n",
    "    def applica_commissione(self, importo_transazione, broker='FINECO'):\n",
    "        if broker == 'FINECO':\n",
    "            tot = importo_transazione * 0.0019\n",
    "            if tot < 2.95:\n",
    "                return 2.95\n",
    "            elif tot > 19:\n",
    "                return 19\n",
    "            else:\n",
    "                return tot \n",
    "        else:\n",
    "            return 0.\n",
    "\n",
    "    # Funzione obiettivo per l'ottimizzazione\n",
    "    def funzione_obiettivo(self, N_SIMBOLI, GIORNI_POS, SL, TP):\n",
    "        # Imposta i parametri\n",
    "        self.N_SIMBOLI = N_SIMBOLI\n",
    "        self.GIORNI_POS = GIORNI_POS\n",
    "        self.SL = SL\n",
    "        self.TP = TP\n",
    "        print('PARAMETRI:')\n",
    "        print(f'N.simboli = {N_SIMBOLI}')\n",
    "        print(f'Giorni pos. = {GIORNI_POS}')\n",
    "        print(f'SL = {SL}')\n",
    "        print(f'TP = {TP}')\n",
    "        # Esegui il trading\n",
    "        self.avvia_trading()\n",
    "\n",
    "        # Restituisce il bilancio finale in modo negativo per la minimizzazione\n",
    "        return -self._bilancio\n",
    "\n",
    "class Modello:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def _crea_modello(self):      \n",
    "        # Input layer\n",
    "        input_layer = Input(shape=(self.timesteps, self.n_features))\n",
    "\n",
    "        # Convolutional layer\n",
    "        conv1 = Conv1D(filters=128, kernel_size=5, activation='relu')(input_layer)\n",
    "        conv1 = BatchNormalization()(conv1)\n",
    "\n",
    "        # Continuation of the model\n",
    "        lstm2 = GRU(50)(conv1)\n",
    "        lstm2 = Dropout(0.5)(lstm2)\n",
    "\n",
    "        dense2 = Dense(80, activation='relu', kernel_regularizer=regularizers.l2(0.02))(lstm2)\n",
    "        dense2 = Dropout(0.5)(dense2)\n",
    "\n",
    "        batch_norm1 = BatchNormalization()(dense2)\n",
    "\n",
    "        dense3 = Dense(40, activation='relu', kernel_regularizer=regularizers.l2(0.02))(batch_norm1)\n",
    "        dense3 = Dropout(0.5)(dense3)\n",
    "\n",
    "        batch_norm2 = BatchNormalization()(dense3)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(1, activation='sigmoid')(batch_norm2)\n",
    "\n",
    "        adam = Adam(learning_rate=self.learning_rate)\n",
    "        model = Model(inputs=input_layer, outputs=output_layer)\n",
    "        model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall(), AUC(curve='PR')])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def crea(self, \n",
    "             progetto='default', \n",
    "             timesteps=120, \n",
    "             giorni_previsione=1, \n",
    "             features=[\"EMA_20\", \"EMA_50\", \"EMA_100\", \"Volume\", \"MACDh\", \"AROONOSC\", \"TRIX\", \"DM_OSC\", \"TSI\", \"KVO\"], \n",
    "             targets=[\"Target_ingresso\"], \n",
    "             n_ticker_batch=400, \n",
    "             bilanciamento=1, \n",
    "             epochs=100,\n",
    "             batch_size=2052, \n",
    "             soglia=0.5, \n",
    "             class_weights={0: 3, 1: 1},\n",
    "             learning_rate=0.001, \n",
    "             train_test_split=0.2\n",
    "            ):\n",
    "        self.progetto = progetto\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.timesteps = timesteps # n. barre del periodo passato per la ricerca di pattern, inclusa ultima data disponibile\n",
    "        self.giorni_previsione = giorni_previsione  # giorni futuri di cui effettuare la previsione\n",
    "        self.features_scala_prezzo = [ft for ft in _features_scala_prezzo_tutte if ft in self.features]\n",
    "        self.features_da_scalare_singolarmente = [ft for ft in _features_da_scalare_singolarmente_tutte if ft in self.features]\n",
    "        self.features_oscillatori = [ft for ft in _features_oscillatori_tutte if ft in self.features]\n",
    "        self.features_no_scala = [ft for ft in _features_no_scala_tutte if ft in self.features]\n",
    "        self.features_candele = [ft for ft in _features_candele_tutte if ft in self.features]\n",
    "        self.targets = targets\n",
    "        self.n_ticker_batch = n_ticker_batch\n",
    "        self.bilanciamento = bilanciamento\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.soglia = soglia\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_test_split = train_test_split\n",
    "        self.class_weights = class_weights\n",
    "        self.n_features = len(self.features) \n",
    "        self.n_targets = len(self.targets) \n",
    "        self.model = self._crea_modello() \n",
    "        self.model_history = None\n",
    "\n",
    "    def carica(self, progetto='default'):\n",
    "        self.progetto = progetto\n",
    "        percorso_file = f'{self.progetto}/impostazioni.json'\n",
    "        try:\n",
    "            with open(percorso_file, \"r\") as file:\n",
    "                impostazioni = json.load(file) if os.path.getsize(percorso_file) > 0 else {}\n",
    "                self.timesteps = impostazioni.get(\"timesteps\", 120) # n. barre del periodo passato per la ricerca di pattern, inclusa ultima data disponibile\n",
    "                self.giorni_previsione = impostazioni.get(\"giorni_previsione\", 1)  # giorni futuri di cui effettuare la previsione\n",
    "                self.features = impostazioni.get(\"features\", [\"EMA_20\", \"EMA_50\", \"EMA_100\", \"Volume\", \"MACDh\", \"AROONOSC\", \"TRIX\", \"DM_OSC\", \"TSI\", \"KVO\"])\n",
    "                self.features_scala_prezzo = [ft for ft in _features_scala_prezzo_tutte if ft in self.features]\n",
    "                self.features_da_scalare_singolarmente = [ft for ft in _features_da_scalare_singolarmente_tutte if ft in self.features]\n",
    "                self.features_oscillatori = [ft for ft in _features_oscillatori_tutte if ft in self.features]\n",
    "                self.features_no_scala = [ft for ft in _features_no_scala_tutte if ft in self.features]\n",
    "                self.features_candele = [ft for ft in _features_candele_tutte if ft in self.features]                \n",
    "                self.targets = impostazioni.get(\"targets\", [\"Target_ingresso\"])\n",
    "                self.n_features = len(self.features)\n",
    "                self.n_targets = len(self.targets) \n",
    "                self.n_ticker_batch = impostazioni.get(\"n_ticker_batch\", 400)\n",
    "                self.bilanciamento = impostazioni.get(\"bilanciamento\", 1)\n",
    "                self.batch_size = impostazioni.get(\"batch_size\", 2052)\n",
    "                self.epochs = impostazioni.get(\"epochs\", 100)\n",
    "                self.soglia = impostazioni.get(\"soglia\", 0.5)\n",
    "                self.learning_rate = impostazioni.get(\"learnig_rate\", 0.001)\n",
    "                self.train_test_split = impostazioni.get(\"train_test_split\", 0.2)\n",
    "                self.class_weights = impostazioni.get(\"class_weights\", {0: 3, 1: 1})\n",
    "                self.n_features = len(self.features) \n",
    "                self.n_targets = len(self.targets) \n",
    "                self.model = load_model(f\"{self.progetto}/model.h5\")  \n",
    "                self.model_history = pd.read_hdf(f'{progetto}/model_history.h5', 'history')      \n",
    "        except Exception as e:\n",
    "            print(f\"Errore durante il caricamento del file: {e}\")\n",
    "\n",
    "    def _salva_impostazioni(self):\n",
    "        impostazioni = {\n",
    "            \"timesteps\": self.timesteps,\n",
    "            \"giorni_previsione\": self.giorni_previsione,\n",
    "            \"features\": self.features,\n",
    "            \"targets\": self.targets,\n",
    "            \"n_ticker_batch\": self.n_ticker_batch,\n",
    "            \"bilanciamento\": self.bilanciamento,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"epochs\": self.epochs, \n",
    "            \"soglia\": self.soglia,\n",
    "            \"class_weights\": self.class_weights\n",
    "        }\n",
    "        with open(f'{self.progetto}/impostazioni.json', \"w\") as file:\n",
    "            json.dump(impostazioni, file, indent=4)\n",
    "            \n",
    "        modello = json.loads(self.model.to_json())\n",
    "        with open(f'{self.progetto}/struttura.json', \"w\") as file:\n",
    "            json.dump(modello, file, indent=4)\n",
    "\n",
    "    def salva(self):\n",
    "        os.makedirs(self.progetto, exist_ok=True)\n",
    "        self._salva_impostazioni()\n",
    "        self.model.save(f'{self.progetto}/model.h5')\n",
    "        self.model_history.to_hdf(f'{self.progetto}/model_history.h5', key='history', mode='w')\n",
    "\n",
    "    def genera_XY(self, lista_files, nome_file=''):\n",
    "        perc_file = f'XY/XY_{nome_file}.h5'\n",
    "        if not os.path.exists(perc_file):\n",
    "            manager = Manager()\n",
    "            listaX = manager.list()\n",
    "            listaY = manager.list()\n",
    "            totale_processati = Value('i', 1)  \n",
    "            tot_files = len(lista_files)\n",
    "            with Pool(cpu_count()) as p:\n",
    "                for file_name in lista_files:\n",
    "                    param = (file_name, self.timesteps, self.giorni_previsione, self.features, self.targets, self.bilanciamento)\n",
    "                    p.apply_async(_process_ticker, args=param, callback=lambda result: _callback_XY(result, listaX, listaY, totale_processati, tot_files, hdf5_file=perc_file))\n",
    "\n",
    "                p.close()\n",
    "                p.join()\n",
    "\n",
    "            if len(listaX) > 0:\n",
    "                print(\"\\033[43m\" + 'Salvataggio finale su file X' + \"\\033[0m\")\n",
    "                concatena(listaX, perc_file, dataset_name='X')\n",
    "                print(\"\\033[43m\" + 'Salvataggio finale su file Y' + \"\\033[0m\")\n",
    "                concatena(listaY, perc_file, dataset_name='Y')\n",
    "                del listaX[:]\n",
    "                del listaY[:]\n",
    "\n",
    "    def addestra(self):\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001, verbose=1)\n",
    "        #model_checkpoint = ModelCheckpoint(f'{self.progetto}/model.h5', monitor='val_precision', save_best_only=True, verbose=1)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "        callbacks = [early_stopping, reduce_lr]\n",
    "        list_of_files = os.listdir('tickers')\n",
    "        random.shuffle(list_of_files)\n",
    "        train_files = list_of_files[:self.n_ticker_batch]\n",
    "        val_files = list_of_files[self.n_ticker_batch:int(self.n_ticker_batch*(1+self.train_test_split))]\n",
    "        \n",
    "        print(\"\\033[41m\" + 'Preparazione dati di train' + \"\\033[0m\")\n",
    "        self.genera_XY(train_files, 'train')\n",
    "        print(\"\\033[41m\" + 'Preparazione dati di validazione' + \"\\033[0m\")\n",
    "        self.genera_XY(val_files, 'val')\n",
    "        train_generator = DataGenerator('XY/XY_train.h5', self.batch_size)\n",
    "        val_generator = DataGenerator('XY/XY_val.h5', self.batch_size)    \n",
    "           \n",
    "        history = self.model.fit(train_generator, epochs=self.epochs, validation_data=val_generator, callbacks=callbacks, class_weight=self.class_weights, steps_per_epoch=len(train_generator), validation_steps=len(val_generator))\n",
    "        self.model_history = pd.DataFrame(history.history)\n",
    "        self.salva()\n",
    "        self.grafico_loss(salva_su_file=True)\n",
    "        self.grafico_precision(salva_su_file=True)\n",
    "        df = self.test()\n",
    "        return df\n",
    "        \n",
    "    def previsione_singola(self, nome_simbolo):\n",
    "        print(f'Caricamento dati ticker {nome_simbolo}')\n",
    "        ticker = pd.read_hdf(f'tickers/{nome_simbolo}.h5', 'ticker')\n",
    "        print('Generazione X e Y')\n",
    "        idx, X, Y, _ = to_XY(dati_ticker=ticker, timesteps=self.timesteps, giorni_previsione=self.giorni_previsione, features=self.features, targets=self.targets, bilanciamento=0)\n",
    "        print(f'Previsione')\n",
    "        pred = self.modello_ingresso.model.predict(X)\n",
    "        scr = pd.DataFrame({'Previsione': pred.flatten().round(2), 'Reale': Y.flatten()}, index=idx)\n",
    "        scr = scr[scr.index >= self.DATA_INIZIO]\n",
    "        print(f\"Salvataggio file {nome_simbolo}.h5\")\n",
    "    \n",
    "    def grafico_loss(self, salva_su_file=False):\n",
    "        num_epochs = self.model_history.shape[0]\n",
    "        plt.plot(np.arange(0, num_epochs), self.model_history['loss'], label=\"Training\")\n",
    "        plt.plot(np.arange(0, num_epochs), self.model_history['val_loss'], label=\"Validation\")\n",
    "        plt.legend()\n",
    "        plt.title('Loss')\n",
    "        plt.tight_layout()\n",
    "        if salva_su_file:\n",
    "            plt.savefig(f'{self.progetto}/grafico_loss.png')\n",
    "        plt.show()        \n",
    "\n",
    "    def grafico_precision(self, salva_su_file=False):\n",
    "        num_epochs = self.model_history.shape[0]\n",
    "        plt.plot(np.arange(0, num_epochs), self.model_history['precision'], label=\"Training\")\n",
    "        plt.plot(np.arange(0, num_epochs), self.model_history['val_precision'], label=\"Validation\")\n",
    "        plt.legend()\n",
    "        plt.title('Precision')\n",
    "        plt.tight_layout()\n",
    "        if salva_su_file:\n",
    "            plt.savefig(f'{self.progetto}/grafico_precision.png')\n",
    "        plt.show()        \n",
    "\n",
    "    def test(self, nome_simbolo='BTG'):\n",
    "        ticker = pd.read_hdf(f'tickers/{nome_simbolo}.h5', 'ticker')\n",
    "        ticker = dropna_iniziali(ticker)\n",
    "        ticker = dropna_finali(ticker)\n",
    "        idx, X, Y, _ = to_XY(ticker, timesteps=self.timesteps, giorni_previsione=self.giorni_previsione, features=self.features, targets=self.targets, bilanciamento=0)\n",
    "        print(f'X.shape: {X.shape}')\n",
    "        print(f'Y.shape: {Y.shape}')\n",
    "        print(f'ticker.shape: {ticker.shape}')\n",
    "        pred = self.model.predict(X, batch_size=self.batch_size, verbose=1, use_multiprocessing=True)\n",
    "        pred_binary = (pred > self.soglia).astype(int)\n",
    "        \n",
    "        result = self.model.evaluate(X, Y, batch_size=self.batch_size, verbose=1, use_multiprocessing=True, return_dict=True)\n",
    "        print(result)\n",
    "        \n",
    "        # Visualizza come heatmap\n",
    "        matrice = confusion_matrix(Y, pred_binary)\n",
    "        sns.heatmap(matrice, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "        plt.xlabel('Previsti')\n",
    "        plt.ylabel('Reali')\n",
    "        plt.savefig(f'{self.progetto}/confusion_matrix.png')\n",
    "        plt.show()\n",
    "        print(f'idx: {idx.shape}')\n",
    "        print(f'pred: {pred.shape}')\n",
    "        print(f'real: {Y.shape}')\n",
    "        df = pd.DataFrame({'Prev': pred.flatten().round(2), 'Real': Y.flatten()}, index=idx)\n",
    "        return df       \n",
    "\n",
    "def _process_ticker(file_name, timesteps, giorni_previsione, features, targets, bilanciamento):\n",
    "    try:\n",
    "        ticker = pd.read_hdf(f'tickers/{file_name}', 'ticker')\n",
    "        ticker = dropna_iniziali(ticker)\n",
    "        ticker = dropna_finali(ticker)\n",
    "        _, X, Y, _ = to_XY(ticker, timesteps, giorni_previsione, features, targets, bilanciamento)\n",
    "        return file_name, X, Y, \"\"\n",
    "    except Exception as e:\n",
    "        return file_name, np.array([]), np.array([]), str(e)\n",
    "\n",
    "def _callback_XY(result, listaX, listaY, totale_processati, tot_files, hdf5_file):\n",
    "    nome_simbolo, X, Y, err = result\n",
    "    if err == \"\":\n",
    "        if X.shape[0] > 0 and Y.shape[0] > 0:  # Verifica se X e Y sono non vuoti\n",
    "            print(f'X.shape:{X.shape}')\n",
    "            print(f'Y.shape:{Y.shape}')\n",
    "            listaX.append(X)\n",
    "            listaY.append(Y)\n",
    "            print(\"\\033[42m\" + f\"{totale_processati.value}/{tot_files}) Completato ticker {nome_simbolo}\" + \"\\033[0m\")\n",
    "        else:\n",
    "            print(\"\\033[43m\" + f\"Ticker {nome_simbolo} ignorato a causa di dati mancanti o errati.\" + \"\\033[0m\")\n",
    "    else:\n",
    "        print(err)\n",
    "\n",
    "    with totale_processati.get_lock(): \n",
    "        totale_processati.value += 1\n",
    "        if len(listaX) >= 100:\n",
    "            print(\"\\033[43m\" + 'Salvataggio su file X' + \"\\033[0m\")\n",
    "            concatena(listaX, hdf5_file, dataset_name='X')\n",
    "            print(\"\\033[43m\" + 'Salvataggio su file Y' + \"\\033[0m\")\n",
    "            concatena(listaY, hdf5_file, dataset_name='Y')\n",
    "            del listaX[:]\n",
    "            del listaY[:]\n",
    "     \n",
    "def modifica_target():\n",
    "    totale_processati = Value('i', 1)\n",
    "    list_of_files = os.listdir('tickers')\n",
    "    tot_tickers = len(list_of_files)\n",
    "    with Pool(cpu_count()) as p:\n",
    "        callback_with_args = partial(_callback_modifica_target, totale_processati=totale_processati, tot_tickers=tot_tickers)\n",
    "        for i in range(0, tot_tickers):\n",
    "            nome_file = list_of_files[i]\n",
    "            param = (nome_file,)\n",
    "            p.apply_async(_modifica_target, args=param, callback=callback_with_args)\n",
    "        p.close()\n",
    "        p.join()          \n",
    "   \n",
    "def _modifica_target(nome_file):\n",
    "    try:\n",
    "        ticker = pd.read_hdf(f'tickers/{nome_file}', 'ticker')\n",
    "        # if 'Target_ingresso' in ticker.columns:\n",
    "        #     ticker.drop(['Target_ingresso'], axis=1, inplace=True)\n",
    "        # if 'Target_uscita' in ticker.columns:\n",
    "        #     ticker.drop(['Target_uscita'], axis=1, inplace=True)\n",
    "        ticker = imposta_target(ticker)\n",
    "        return nome_file, ticker, \"\"\n",
    "    except Exception as e:\n",
    "        return nome_file, ticker, str(e)\n",
    "\n",
    "def _callback_modifica_target(result, totale_processati, tot_tickers):\n",
    "    nome_file, ticker, err = result\n",
    "    if err == \"\":\n",
    "        print(f\"{totale_processati.value}/{tot_tickers}) Modificato target {nome_file}\")\n",
    "        ticker.to_hdf(f'tickers/{nome_file}', key='ticker', mode='w')\n",
    "    else:\n",
    "        print(err)\n",
    "\n",
    "    with totale_processati.get_lock(): \n",
    "        totale_processati.value += 1\n",
    "        \n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, file_path, batch_size):\n",
    "        self.file_path = file_path\n",
    "        self.batch_size = batch_size\n",
    "        # Apriamo il file in modalità lettura e salviamo i riferimenti ai dataset\n",
    "        self.file = h5py.File(file_path, 'r')\n",
    "        self.X = self.file['X']\n",
    "        self.Y = self.file['Y']\n",
    "        self.num_samples = self.X.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.num_samples / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calcola gli indici per il batch corrente\n",
    "        start = idx * self.batch_size\n",
    "        end = (idx + 1) * self.batch_size\n",
    "\n",
    "        # Legge solo i dati necessari per il batch corrente\n",
    "        batch_x = self.X[start:end]\n",
    "        batch_y = self.Y[start:end]\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Eventuali azioni alla fine di ogni epoca, se necessario\n",
    "        pass\n",
    "\n",
    "    def __del__(self):\n",
    "        # Assicurati di chiudere il file quando il generatore viene distrutto\n",
    "        self.file.close()\n",
    "\n",
    "def ottimizzazione_parametri():\n",
    "    PROBABILITA_PER_ACQUISTO = 0.5\n",
    "    BILANCIO_INIZIALE = 1000\n",
    "    GIORNI_MAX_POSIZIONE = 40\n",
    "    N_SIMBOLI = 10\n",
    "    DATA_INIZIO = pd.Timestamp(2013, 1, 1)\n",
    "    \n",
    "    inizializza_gpu()\n",
    "\n",
    "    borsa = Borsa(N_SIMBOLI, BILANCIO_INIZIALE, PROBABILITA_PER_ACQUISTO, GIORNI_MAX_POSIZIONE, data_inizio=DATA_INIZIO)\n",
    "    borsa.aggiorna_dati()\n",
    "    \n",
    "    valori_N_SIMBOLI = list(range(1, 11))  # Valori da 1 a 10\n",
    "    valori_GIORNI_POS = list(range(5, 61, 5))  # Valori da 5 a 60 con step di 5\n",
    "    valori_SL = list(np.arange(0.01, 0.1, 0.01))\n",
    "    valori_TP = list(np.arange(0.1, 1, 0.05))\n",
    "\n",
    "    space  = [\n",
    "        Categorical(valori_N_SIMBOLI, name='N_SIMBOLI'),  \n",
    "        Categorical(valori_GIORNI_POS, name='GIORNI_POS'),  \n",
    "        Categorical(valori_SL, name='SL'),  \n",
    "        Categorical(valori_TP, name='TP')\n",
    "    ]\n",
    "\n",
    "    @use_named_args(space)\n",
    "    def objective(**params):\n",
    "        return borsa.funzione_obiettivo(**params)\n",
    "\n",
    "    risultato = gp_minimize(objective, space, n_calls=50, random_state=0)\n",
    "\n",
    "    print(f\"Migliori parametri: {risultato.x}\")\n",
    "\n",
    "    x_iters = risultato.x_iters  # Lista di parametri testati\n",
    "    fun_values = risultato.func_vals  # Lista di valori della funzione obiettivo\n",
    "\n",
    "    df_results = pd.DataFrame(x_iters, columns=['N_SIMBOLI', 'GIORNI_POS', 'SL', 'TP'])\n",
    "    df_results['Valore_Funzione'] = fun_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e1218b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Caricamento screener esistenti\n",
      "Caricamento screener esistenti\n"
     ]
    }
   ],
   "source": [
    "PROBABILITA_PER_ACQUISTO = 0.5\n",
    "BILANCIO_INIZIALE = 1000\n",
    "GIORNI_MAX_POSIZIONE = 40\n",
    "N_SIMBOLI = 10\n",
    "DATA_INIZIO = pd.Timestamp(2013, 1, 1)\n",
    "\n",
    "inizializza_gpu()\n",
    "\n",
    "nome_modello = 'mod_2_in'\n",
    "borsa5d = Borsa(N_SIMBOLI, BILANCIO_INIZIALE, PROBABILITA_PER_ACQUISTO, GIORNI_MAX_POSIZIONE, data_inizio=DATA_INIZIO, nome_modello=nome_modello)\n",
    "borsa5d.aggiorna_dati()\n",
    "data5d, scr5d = borsa5d.ultimo_screener()\n",
    "\n",
    "nome_modello2 = 'mod_1_in'\n",
    "borsa20d = Borsa(N_SIMBOLI, BILANCIO_INIZIALE, PROBABILITA_PER_ACQUISTO, GIORNI_MAX_POSIZIONE, data_inizio=DATA_INIZIO, nome_modello=nome_modello2)\n",
    "borsa20d.aggiorna_dati()\n",
    "data20d, scr20d = borsa20d.ultimo_screener()\n",
    "\n",
    "scr_unione = pd.merge(scr5d, scr20d, on='Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d772bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-08\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Previsione_x</th>\n",
       "      <th>Reale_x</th>\n",
       "      <th>Previsione_y</th>\n",
       "      <th>Reale_y</th>\n",
       "      <th>Media_Previsione</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EMA_5</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>EMA_50</th>\n",
       "      <th>EMA_100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EWCZ</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955</td>\n",
       "      <td>13.480000</td>\n",
       "      <td>15.960000</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>15.490000</td>\n",
       "      <td>15.490000</td>\n",
       "      <td>1933900</td>\n",
       "      <td>13.884865</td>\n",
       "      <td>13.828493</td>\n",
       "      <td>14.257327</td>\n",
       "      <td>15.096171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGIO</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.845</td>\n",
       "      <td>23.040001</td>\n",
       "      <td>24.459999</td>\n",
       "      <td>22.650000</td>\n",
       "      <td>24.450001</td>\n",
       "      <td>24.450001</td>\n",
       "      <td>636500</td>\n",
       "      <td>23.641796</td>\n",
       "      <td>23.120963</td>\n",
       "      <td>22.962384</td>\n",
       "      <td>23.511131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIM</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>13.720000</td>\n",
       "      <td>12.350000</td>\n",
       "      <td>13.670000</td>\n",
       "      <td>13.670000</td>\n",
       "      <td>17962800</td>\n",
       "      <td>13.082489</td>\n",
       "      <td>10.751690</td>\n",
       "      <td>9.619906</td>\n",
       "      <td>10.236551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEXI</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>6.340000</td>\n",
       "      <td>9.440000</td>\n",
       "      <td>6.308000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>6237200</td>\n",
       "      <td>5.833216</td>\n",
       "      <td>3.890272</td>\n",
       "      <td>3.628049</td>\n",
       "      <td>4.322233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGL</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.725</td>\n",
       "      <td>8.380000</td>\n",
       "      <td>9.260000</td>\n",
       "      <td>8.260000</td>\n",
       "      <td>9.180000</td>\n",
       "      <td>9.180000</td>\n",
       "      <td>13471800</td>\n",
       "      <td>10.467496</td>\n",
       "      <td>11.789336</td>\n",
       "      <td>12.989697</td>\n",
       "      <td>14.787077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSTG</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710</td>\n",
       "      <td>36.060001</td>\n",
       "      <td>37.445000</td>\n",
       "      <td>35.900002</td>\n",
       "      <td>37.439999</td>\n",
       "      <td>37.439999</td>\n",
       "      <td>7012000</td>\n",
       "      <td>36.519824</td>\n",
       "      <td>35.820026</td>\n",
       "      <td>35.496671</td>\n",
       "      <td>35.155293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VCEL</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>32.439999</td>\n",
       "      <td>34.820000</td>\n",
       "      <td>32.310001</td>\n",
       "      <td>34.790001</td>\n",
       "      <td>34.790001</td>\n",
       "      <td>817900</td>\n",
       "      <td>34.190937</td>\n",
       "      <td>34.793665</td>\n",
       "      <td>34.863619</td>\n",
       "      <td>34.552120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDT</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>84.800003</td>\n",
       "      <td>86.720001</td>\n",
       "      <td>84.309998</td>\n",
       "      <td>86.570000</td>\n",
       "      <td>86.570000</td>\n",
       "      <td>7867100</td>\n",
       "      <td>84.599399</td>\n",
       "      <td>82.323088</td>\n",
       "      <td>79.925496</td>\n",
       "      <td>79.576362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNF</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>162.880005</td>\n",
       "      <td>166.419998</td>\n",
       "      <td>161.600006</td>\n",
       "      <td>165.619995</td>\n",
       "      <td>165.619995</td>\n",
       "      <td>124300</td>\n",
       "      <td>167.925500</td>\n",
       "      <td>175.110173</td>\n",
       "      <td>173.863810</td>\n",
       "      <td>172.100215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>233.850006</td>\n",
       "      <td>225.789993</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>40633200</td>\n",
       "      <td>242.982996</td>\n",
       "      <td>247.675973</td>\n",
       "      <td>233.919177</td>\n",
       "      <td>223.369308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Previsione_x  Reale_x  Previsione_y  Reale_y  Media_Previsione  \\\n",
       "Ticker                                                                   \n",
       "EWCZ            0.98      0.0          0.93      0.0             0.955   \n",
       "AGIO            0.92      0.0          0.77      0.0             0.845   \n",
       "ZIM             0.83      0.0          0.77      0.0             0.800   \n",
       "NEXI            0.80      0.0          0.77      0.0             0.785   \n",
       "AGL             0.65      0.0          0.80      0.0             0.725   \n",
       "PSTG            0.64      0.0          0.78      0.0             0.710   \n",
       "VCEL            0.64      0.0          0.75      0.0             0.695   \n",
       "MDT             0.70      0.0          0.67      0.0             0.685   \n",
       "UNF             0.52      0.0          0.82      0.0             0.670   \n",
       "BA              0.59      0.0          0.73      0.0             0.660   \n",
       "\n",
       "              Open        High         Low       Close   Adj Close    Volume  \\\n",
       "Ticker                                                                         \n",
       "EWCZ     13.480000   15.960000   13.300000   15.490000   15.490000   1933900   \n",
       "AGIO     23.040001   24.459999   22.650000   24.450001   24.450001    636500   \n",
       "ZIM      12.950000   13.720000   12.350000   13.670000   13.670000  17962800   \n",
       "NEXI      6.340000    9.440000    6.308000    7.570000    7.570000   6237200   \n",
       "AGL       8.380000    9.260000    8.260000    9.180000    9.180000  13471800   \n",
       "PSTG     36.060001   37.445000   35.900002   37.439999   37.439999   7012000   \n",
       "VCEL     32.439999   34.820000   32.310001   34.790001   34.790001    817900   \n",
       "MDT      84.800003   86.720001   84.309998   86.570000   86.570000   7867100   \n",
       "UNF     162.880005  166.419998  161.600006  165.619995  165.619995    124300   \n",
       "BA      228.000000  233.850006  225.789993  229.000000  229.000000  40633200   \n",
       "\n",
       "             EMA_5      EMA_20      EMA_50     EMA_100  \n",
       "Ticker                                                  \n",
       "EWCZ     13.884865   13.828493   14.257327   15.096171  \n",
       "AGIO     23.641796   23.120963   22.962384   23.511131  \n",
       "ZIM      13.082489   10.751690    9.619906   10.236551  \n",
       "NEXI      5.833216    3.890272    3.628049    4.322233  \n",
       "AGL      10.467496   11.789336   12.989697   14.787077  \n",
       "PSTG     36.519824   35.820026   35.496671   35.155293  \n",
       "VCEL     34.190937   34.793665   34.863619   34.552120  \n",
       "MDT      84.599399   82.323088   79.925496   79.576362  \n",
       "UNF     167.925500  175.110173  173.863810  172.100215  \n",
       "BA      242.982996  247.675973  233.919177  223.369308  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(data5d)\n",
    "scr_unione['Media_Previsione'] = (scr_unione['Previsione_x'] + scr_unione['Previsione_y']) / 2\n",
    "\n",
    "lista = []\n",
    "for t, dati in scr_unione.iterrows():\n",
    "    dati = pd.read_hdf(f'tickers/{t}.h5', 'ticker')\n",
    "    dati = dati.iloc[[-1]]\n",
    "    dati['Ticker'] = t\n",
    "    dati.set_index('Ticker', inplace=True)\n",
    "    lista.append(dati.copy())\n",
    "df_dati = pd.concat(lista, axis=0)\n",
    "df_dati = df_dati[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'EMA_5', 'EMA_20', 'EMA_50', 'EMA_100']]\n",
    "scr_unione = pd.merge(scr_unione, df_dati, on='Ticker')\n",
    "scr_unione.sort_values(by=['Media_Previsione'], ascending=False, inplace=True)\n",
    "scr_unione.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6bb6d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Previsione_x</th>\n",
       "      <th>Reale_x</th>\n",
       "      <th>Previsione_y</th>\n",
       "      <th>Reale_y</th>\n",
       "      <th>Media_Previsione</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>EMA_5</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>EMA_50</th>\n",
       "      <th>EMA_100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EWCZ</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955</td>\n",
       "      <td>13.480000</td>\n",
       "      <td>15.960000</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>15.490000</td>\n",
       "      <td>15.490000</td>\n",
       "      <td>1933900</td>\n",
       "      <td>13.884865</td>\n",
       "      <td>13.828493</td>\n",
       "      <td>14.257327</td>\n",
       "      <td>15.096171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNF</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.670</td>\n",
       "      <td>162.880005</td>\n",
       "      <td>166.419998</td>\n",
       "      <td>161.600006</td>\n",
       "      <td>165.619995</td>\n",
       "      <td>165.619995</td>\n",
       "      <td>124300</td>\n",
       "      <td>167.925500</td>\n",
       "      <td>175.110173</td>\n",
       "      <td>173.863810</td>\n",
       "      <td>172.100215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGL</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.725</td>\n",
       "      <td>8.380000</td>\n",
       "      <td>9.260000</td>\n",
       "      <td>8.260000</td>\n",
       "      <td>9.180000</td>\n",
       "      <td>9.180000</td>\n",
       "      <td>13471800</td>\n",
       "      <td>10.467496</td>\n",
       "      <td>11.789336</td>\n",
       "      <td>12.989697</td>\n",
       "      <td>14.787077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSTG</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710</td>\n",
       "      <td>36.060001</td>\n",
       "      <td>37.445000</td>\n",
       "      <td>35.900002</td>\n",
       "      <td>37.439999</td>\n",
       "      <td>37.439999</td>\n",
       "      <td>7012000</td>\n",
       "      <td>36.519824</td>\n",
       "      <td>35.820026</td>\n",
       "      <td>35.496671</td>\n",
       "      <td>35.155293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGIO</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.845</td>\n",
       "      <td>23.040001</td>\n",
       "      <td>24.459999</td>\n",
       "      <td>22.650000</td>\n",
       "      <td>24.450001</td>\n",
       "      <td>24.450001</td>\n",
       "      <td>636500</td>\n",
       "      <td>23.641796</td>\n",
       "      <td>23.120963</td>\n",
       "      <td>22.962384</td>\n",
       "      <td>23.511131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIM</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800</td>\n",
       "      <td>12.950000</td>\n",
       "      <td>13.720000</td>\n",
       "      <td>12.350000</td>\n",
       "      <td>13.670000</td>\n",
       "      <td>13.670000</td>\n",
       "      <td>17962800</td>\n",
       "      <td>13.082489</td>\n",
       "      <td>10.751690</td>\n",
       "      <td>9.619906</td>\n",
       "      <td>10.236551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEXI</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>6.340000</td>\n",
       "      <td>9.440000</td>\n",
       "      <td>6.308000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>7.570000</td>\n",
       "      <td>6237200</td>\n",
       "      <td>5.833216</td>\n",
       "      <td>3.890272</td>\n",
       "      <td>3.628049</td>\n",
       "      <td>4.322233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VCEL</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>32.439999</td>\n",
       "      <td>34.820000</td>\n",
       "      <td>32.310001</td>\n",
       "      <td>34.790001</td>\n",
       "      <td>34.790001</td>\n",
       "      <td>817900</td>\n",
       "      <td>34.190937</td>\n",
       "      <td>34.793665</td>\n",
       "      <td>34.863619</td>\n",
       "      <td>34.552120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRFS</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645</td>\n",
       "      <td>11.060000</td>\n",
       "      <td>11.170000</td>\n",
       "      <td>10.970000</td>\n",
       "      <td>11.130000</td>\n",
       "      <td>11.130000</td>\n",
       "      <td>3930600</td>\n",
       "      <td>11.119250</td>\n",
       "      <td>10.657328</td>\n",
       "      <td>10.072245</td>\n",
       "      <td>9.689908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>233.850006</td>\n",
       "      <td>225.789993</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>40633200</td>\n",
       "      <td>242.982996</td>\n",
       "      <td>247.675973</td>\n",
       "      <td>233.919177</td>\n",
       "      <td>223.369308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Previsione_x  Reale_x  Previsione_y  Reale_y  Media_Previsione  \\\n",
       "Ticker                                                                   \n",
       "EWCZ            0.98      0.0          0.93      0.0             0.955   \n",
       "UNF             0.52      0.0          0.82      0.0             0.670   \n",
       "AGL             0.65      0.0          0.80      0.0             0.725   \n",
       "PSTG            0.64      0.0          0.78      0.0             0.710   \n",
       "AGIO            0.92      0.0          0.77      0.0             0.845   \n",
       "ZIM             0.83      0.0          0.77      0.0             0.800   \n",
       "NEXI            0.80      0.0          0.77      0.0             0.785   \n",
       "VCEL            0.64      0.0          0.75      0.0             0.695   \n",
       "GRFS            0.54      0.0          0.75      0.0             0.645   \n",
       "BA              0.59      0.0          0.73      0.0             0.660   \n",
       "\n",
       "              Open        High         Low       Close   Adj Close    Volume  \\\n",
       "Ticker                                                                         \n",
       "EWCZ     13.480000   15.960000   13.300000   15.490000   15.490000   1933900   \n",
       "UNF     162.880005  166.419998  161.600006  165.619995  165.619995    124300   \n",
       "AGL       8.380000    9.260000    8.260000    9.180000    9.180000  13471800   \n",
       "PSTG     36.060001   37.445000   35.900002   37.439999   37.439999   7012000   \n",
       "AGIO     23.040001   24.459999   22.650000   24.450001   24.450001    636500   \n",
       "ZIM      12.950000   13.720000   12.350000   13.670000   13.670000  17962800   \n",
       "NEXI      6.340000    9.440000    6.308000    7.570000    7.570000   6237200   \n",
       "VCEL     32.439999   34.820000   32.310001   34.790001   34.790001    817900   \n",
       "GRFS     11.060000   11.170000   10.970000   11.130000   11.130000   3930600   \n",
       "BA      228.000000  233.850006  225.789993  229.000000  229.000000  40633200   \n",
       "\n",
       "             EMA_5      EMA_20      EMA_50     EMA_100  \n",
       "Ticker                                                  \n",
       "EWCZ     13.884865   13.828493   14.257327   15.096171  \n",
       "UNF     167.925500  175.110173  173.863810  172.100215  \n",
       "AGL      10.467496   11.789336   12.989697   14.787077  \n",
       "PSTG     36.519824   35.820026   35.496671   35.155293  \n",
       "AGIO     23.641796   23.120963   22.962384   23.511131  \n",
       "ZIM      13.082489   10.751690    9.619906   10.236551  \n",
       "NEXI      5.833216    3.890272    3.628049    4.322233  \n",
       "VCEL     34.190937   34.793665   34.863619   34.552120  \n",
       "GRFS     11.119250   10.657328   10.072245    9.689908  \n",
       "BA      242.982996  247.675973  233.919177  223.369308  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scr_unione.sort_values(by=['Previsione_y', 'Previsione_x'], ascending=False, inplace=True)\n",
    "scr_unione.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd30936",
   "metadata": {},
   "source": [
    "TP = 0.10\n",
    "SL = 0.01\n",
    "BILANCIO_INIZIALE = 1000\n",
    "N_SIMBOLI = 5\n",
    "DATA_INIZIO = pd.Timestamp(2013, 1, 1)\n",
    "\n",
    "inizializza_gpu()\n",
    "\n",
    "borsa = Borsa(N_SIMBOLI, BILANCIO_INIZIALE, data_inizio=DATA_INIZIO, stop_loss=SL, take_profit=TP)\n",
    "borsa.aggiorna_dati()\n",
    "pos = borsa.simulazione_trading()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892bd212",
   "metadata": {},
   "source": [
    "mod = Modello()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mod.carica(progetto='mod_1_in')\n",
    "mod.class_weights = {0: 1, 1: 1}\n",
    "df = mod.addestra()\n",
    "mod.salva()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3120ae03",
   "metadata": {},
   "source": [
    "\n",
    "mod.crea(\n",
    "    'mod_1_in', \n",
    "    class_weights={0: 1, 1: 1}, \n",
    "    bilanciamento=1, \n",
    "    timesteps=240, \n",
    "    batch_size=8000, \n",
    "    learning_rate=0.01, \n",
    "    n_ticker_batch=300, \n",
    "    train_test_split=0.2,\n",
    "    features=[\"EMA_20\", \"EMA_50\", \"EMA_100\", \"Volume\"]#, \"MACDh\", \"AROONOSC\", \"TRIX\", \"DM_OSC\", \"TSI\", \"KVO\"]\n",
    ")\n",
    "df = mod.addestra()\n",
    "df\n",
    "mod.salva()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "mod.crea(\n",
    "    'mod_1_out', \n",
    "    class_weights={0: 1, 1: 1}, \n",
    "    bilanciamento=1, \n",
    "    timesteps=240, \n",
    "    batch_size=4000, \n",
    "    learning_rate=0.01, \n",
    "    n_ticker_batch=300, \n",
    "    train_test_split=0.2,\n",
    "    features=[\"EMA_20\", \"EMA_50\", \"EMA_100\", \"Volume\"],#, \"MACDh\", \"AROONOSC\", \"TRIX\", \"DM_OSC\", \"TSI\", \"KVO\"]\n",
    "    targets=['Target_uscita']\n",
    ")\n",
    "df = mod.addestra()\n",
    "df\n",
    "mod.salva()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93261fb5",
   "metadata": {},
   "source": [
    "mod.crea(\n",
    "    'mod_2_in', \n",
    "    class_weights={0: 1, 1: 1}, \n",
    "    bilanciamento=1, \n",
    "    timesteps=240, \n",
    "    batch_size=8000, \n",
    "    learning_rate=0.01, \n",
    "    n_ticker_batch=300, \n",
    "    train_test_split=0.2,\n",
    "    features=[\"Open\", \"Close\", \"High\", \"Low\", \"Volume\"],#, \"MACDh\", \"AROONOSC\", \"TRIX\", \"DM_OSC\", \"TSI\", \"KVO\"]\n",
    "    targets=['Target_mod_2_in']\n",
    ")\n",
    "df = mod.addestra()\n",
    "df\n",
    "mod.salva()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4272395e",
   "metadata": {},
   "source": [
    "df = mod.test()\n",
    "df.to_excel('test_mod_2.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
