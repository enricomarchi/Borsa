{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85a9176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from multiprocessing import Pool, cpu_count, Manager, Value\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Sequential, Model\n",
    "from tensorflow.keras.layers import Bidirectional, BatchNormalization, LSTM, Dropout, Dense, Conv1D, Flatten, GRU, Attention, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import os\n",
    "from functools import partial\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas_ta as ta\n",
    "import random\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "import plotly.subplots as sp\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "_features_scala_prezzo_tutte = [\n",
    "    \"Close\",\n",
    "    \"EMA_5\", \n",
    "    \"EMA_20\", \n",
    "    \"EMA_50\",\n",
    "    \"EMA_100\",\n",
    "    \"Open\",  \n",
    "    \"High\",\n",
    "    \"Low\",\n",
    "    \"PSAR\",\n",
    "    \"SUPERT\", \n",
    "]\n",
    "\n",
    "_features_da_scalare_singolarmente_tutte = [\n",
    "    \"Volume\",\n",
    "    \"ATR\",\n",
    "    \"PSARaf\",\n",
    "    \"ADX\",\n",
    "    \"OBV\"\n",
    "]\n",
    "\n",
    "_features_oscillatori_tutte = [\n",
    "    \"MACDh\",    \n",
    "    \"MACD\",\n",
    "    \"MACDs\",\n",
    "    \"AROONOSC\",\n",
    "    \"TRIX\",\n",
    "    \"TRIXs\",\n",
    "    \"DM_OSC\",\n",
    "    \"TSI\",\n",
    "    \"TSIs\",\n",
    "    \"ROC_10\",\n",
    "    \"KVO\",\n",
    "    \"KVOs\",\n",
    "    \"VI_OSC\"\n",
    "]\n",
    "\n",
    "_features_no_scala_tutte = [\n",
    "    \"SUPERTd\",  \n",
    "    \"PSARr\",\n",
    "    \"CMF\",\n",
    "    \"VHF\",\n",
    "    \"VTX_OSC\"\n",
    "]\n",
    "\n",
    "_features_candele_tutte = [\n",
    "    \"CDL_2CROWS\", \"CDL_3BLACKCROWS\", \"CDL_3INSIDE\", \"CDL_3LINESTRIKE\", \"CDL_3OUTSIDE\", \"CDL_3STARSINSOUTH\", \"CDL_3WHITESOLDIERS\", \"CDL_ABANDONEDBABY\", \"CDL_ADVANCEBLOCK\", \"CDL_BELTHOLD\", \"CDL_BREAKAWAY\", \"CDL_CLOSINGMARUBOZU\", \"CDL_CONCEALBABYSWALL\", \"CDL_COUNTERATTACK\", \"CDL_DARKCLOUDCOVER\", \"CDL_DOJI_10_0.1\", \"CDL_DOJISTAR\", \"CDL_DRAGONFLYDOJI\", \"CDL_ENGULFING\", \"CDL_EVENINGDOJISTAR\", \"CDL_EVENINGSTAR\", \"CDL_GAPSIDESIDEWHITE\", \"CDL_GRAVESTONEDOJI\", \"CDL_HAMMER\", \"CDL_HANGINGMAN\", \"CDL_HARAMI\", \"CDL_HARAMICROSS\", \"CDL_HIGHWAVE\", \"CDL_HIKKAKE\", \"CDL_HIKKAKEMOD\", \"CDL_HOMINGPIGEON\", \"CDL_IDENTICAL3CROWS\", \"CDL_INNECK\", \"CDL_INSIDE\", \"CDL_INVERTEDHAMMER\", \"CDL_KICKING\", \"CDL_KICKINGBYLENGTH\", \"CDL_LADDERBOTTOM\", \"CDL_LONGLEGGEDDOJI\", \"CDL_LONGLINE\", \"CDL_MARUBOZU\", \"CDL_MATCHINGLOW\", \"CDL_MATHOLD\", \"CDL_MORNINGDOJISTAR\", \"CDL_MORNINGSTAR\", \"CDL_ONNECK\", \"CDL_PIERCING\", \"CDL_RICKSHAWMAN\", \"CDL_RISEFALL3METHODS\", \"CDL_SEPARATINGLINES\", \"CDL_SHOOTINGSTAR\", \"CDL_SHORTLINE\", \"CDL_SPINNINGTOP\", \"CDL_STALLEDPATTERN\", \"CDL_STICKSANDWICH\", \"CDL_TAKURI\", \"CDL_TASUKIGAP\", \"CDL_THRUSTING\", \"CDL_TRISTAR\", \"CDL_UNIQUE3RIVER\", \"CDL_UPSIDEGAP2CROWS\", \"CDL_XSIDEGAP3METHODS\",\n",
    "]\n",
    "\n",
    "def inizializza_gpu():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "                tf.config.experimental.set_visible_devices(gpu, 'GPU')\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    else:\n",
    "        print(\"nessuna GPU\")\n",
    "    \n",
    "def pct_change(valore_iniziale, valore_finale):\n",
    "    try:\n",
    "        return ((valore_finale - valore_iniziale) / valore_iniziale) * 100\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "def analizza_ticker(nome_simbolo, start, end, progress=True, dropna_iniziali=False, dropna_finali=False):\n",
    "    start_str = start.strftime('%Y-%m-%d')\n",
    "    end_str = end.strftime('%Y-%m-%d')\n",
    "    df = yf.download(nome_simbolo, start=start_str, end=end_str, progress=progress)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = crea_indicatori(df)\n",
    "    if dropna_iniziali:\n",
    "        idx = df[df.notna().all(axis=1) == True].index[0]\n",
    "        df = df[idx:]\n",
    "    if dropna_finali:\n",
    "        idx = df[df.notna().all(axis=1) == True].index[-1]\n",
    "        df = df[:idx]\n",
    "    df = imposta_target(df)\n",
    "    return df\n",
    "\n",
    "def dropna_iniziali(df):\n",
    "    idx = df[df.notna().all(axis=1) == True].index[0]\n",
    "    df = df[idx:]\n",
    "    return df\n",
    "\n",
    "def dropna_finali(df):\n",
    "    idx = df[df.notna().all(axis=1) == True].index[-1]\n",
    "    df = df[:idx]\n",
    "    return df\n",
    "\n",
    "def imposta_target(df):\n",
    "    df['Max_Close_20d'] = df['Close'].shift(-20).rolling(window=20, min_periods=1).max()\n",
    "    df['pct_change_20d'] = df.apply(lambda row: pct_change(row['Close'], row['Max_Close_20d']), axis=1)\n",
    "    df['diff_EMA5_EMA20'] = df['EMA_5'] - df['EMA_20']\n",
    "    df['Min_diff_EMA5_EMA20_5d'] = df['diff_EMA5_EMA20'].shift(-5).rolling(window=5, min_periods=1).apply(lambda x: (x < 0).any())\n",
    "    \n",
    "    df['Target_ingresso'] = (\n",
    "        (df['pct_change_20d'] > 20)\n",
    "    )\n",
    "    df['Target_uscita'] = (\n",
    "        (df['Min_diff_EMA5_EMA20_5d'] == 1) & (df['EMA_5'] > df['EMA_20'])\n",
    "    )    \n",
    "    return df\n",
    "    \n",
    "def grafico(df):\n",
    "    close = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = df['Close'],\n",
    "        mode = 'lines',\n",
    "        line = dict(color='rgba(0, 0, 0, .9)'),\n",
    "        name = 'Close'\n",
    "    )\n",
    "\n",
    "    close2 = go.Scatter( # serve solo per il fill del supertrend\n",
    "        x = df.index,\n",
    "        y = df['Close'],\n",
    "        mode = 'lines',\n",
    "        line = dict(color='rgba(0, 0, 0, 0)'),\n",
    "        showlegend=False,\n",
    "        name = 'Close2'\n",
    "    )\n",
    "\n",
    "    # min5 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == -5].index,\n",
    "    #     y = df[df['MaxMinRel'] == -5]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 5,\n",
    "    #         color = 'rgba(255, 0, 0, .9)'\n",
    "    #     ),\n",
    "    #     name = 'MinRel5'\n",
    "    # )\n",
    "  \n",
    "    # max5 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == 5].index,\n",
    "    #     y = df[df['MaxMinRel'] == 5]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 5,\n",
    "    #         color = 'rgba(50, 205, 50, .9)'\n",
    "    #     ),\n",
    "    #     name = 'MaxRel5'\n",
    "    # )\n",
    "\n",
    "    # min10 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == -10].index,\n",
    "    #     y = df[df['MaxMinRel'] == -10]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 15,\n",
    "    #         color = 'rgba(255, 0, 0, .4)'\n",
    "    #     ),\n",
    "    #     name = 'MinRel10'\n",
    "    # )\n",
    "  \n",
    "    # max10 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == 10].index,\n",
    "    #     y = df[df['MaxMinRel'] == 10]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 15,\n",
    "    #         color = 'rgba(50, 205, 50, .4)'\n",
    "    #     ),\n",
    "    #     name = 'MaxRel10'\n",
    "    # )\n",
    "\n",
    "    # min20 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == -20].index,\n",
    "    #     y = df[df['MaxMinRel'] == -20]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 25,\n",
    "    #         color = 'rgba(255, 0, 0, .2)'\n",
    "    #     ),\n",
    "    #     name = 'MinRel20'\n",
    "    # )\n",
    "  \n",
    "    # max20 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == 20].index,\n",
    "    #     y = df[df['MaxMinRel'] == 20]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 25,\n",
    "    #         color = 'rgba(50, 205, 50, .2)'\n",
    "    #     ),\n",
    "    #     name = 'MaxRel20'\n",
    "    # )\n",
    "\n",
    "    # min60 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == -60].index,\n",
    "    #     y = df[df['MaxMinRel'] == -60]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 35,\n",
    "    #         color = 'rgba(255, 0, 0, .1)'\n",
    "    #     ),\n",
    "    #     name = 'MinRel60'\n",
    "    # )\n",
    "  \n",
    "    # max60 = go.Scatter(\n",
    "    #     x = df[df['MaxMinRel'] == 60].index,\n",
    "    #     y = df[df['MaxMinRel'] == 60]['Close'],\n",
    "    #     mode = 'markers',\n",
    "    #     marker = dict(\n",
    "    #         size = 35,\n",
    "    #         color = 'rgba(50, 205, 50, .1)'\n",
    "    #     ),\n",
    "    #     name = 'MaxRel60'\n",
    "    # )\n",
    "\n",
    "    ema5 = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = df['EMA_5'],\n",
    "        mode = 'lines',\n",
    "        line = dict(color='blue'),\n",
    "        name = 'EMA5'\n",
    "    )\n",
    "\n",
    "    ema20 = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = df['EMA_20'],\n",
    "        mode = 'lines',\n",
    "        line = dict(color='limegreen'),\n",
    "        name = 'EMA20'\n",
    "    )\n",
    "\n",
    "    ema50 = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = df['EMA_50'],\n",
    "        mode = 'lines',\n",
    "        line = dict(color='orange'),\n",
    "        name = 'EMA50'\n",
    "    )\n",
    "    \n",
    "    ema100 = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = df['EMA_100'],\n",
    "        mode = 'lines',\n",
    "        line = dict(color='red'),\n",
    "        name = 'EMA100'\n",
    "    )\n",
    "    \n",
    "    psar = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = df['PSAR'], \n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = 2, \n",
    "            color = 'rgba(0, 0, 0, .8)',  \n",
    "        ),\n",
    "        visible = False,\n",
    "        showlegend=True,\n",
    "        name = 'SAR Parabolico'\n",
    "    )\n",
    "    \n",
    "    stup = np.where(df['SUPERTd'] == 1, df['SUPERT'], np.nan)\n",
    "    stdown = np.where(df['SUPERTd'] == -1, df['SUPERT'], np.nan)\n",
    "    stupfill = np.where(df['SUPERTd'] == 1, df['SUPERT'], df['Close'])\n",
    "    stdownfill = np.where(df['SUPERTd'] == -1, df['SUPERT'], df['Close'])\n",
    "    \n",
    "    strendup = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = stup, \n",
    "        mode = 'lines',\n",
    "        line = dict(\n",
    "            color='limegreen',\n",
    "            width=1\n",
    "        ),\n",
    "        visible = False,\n",
    "        showlegend=True,\n",
    "        connectgaps = False,\n",
    "        name = 'SuperTrend'\n",
    "    )\n",
    "        \n",
    "    strendupfill = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = stupfill, \n",
    "        mode = 'lines',\n",
    "        line = dict(\n",
    "            color='rgba(0,0,0,0)',\n",
    "            width=1\n",
    "        ),\n",
    "        connectgaps = False,\n",
    "        visible = False,\n",
    "        showlegend=True,\n",
    "        fill='tonexty',   \n",
    "        fillcolor='rgba(50, 205, 50, 0.1)', \n",
    "        name = 'SuperTrend'\n",
    "    )\n",
    "        \n",
    "    strenddown = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = stdown, \n",
    "        mode = 'lines',\n",
    "        line = dict(\n",
    "            color='red',\n",
    "            width=1\n",
    "        ),\n",
    "        connectgaps = False,\n",
    "        visible = False,\n",
    "        showlegend=True,\n",
    "        name = 'SuperTrend'\n",
    "    )\n",
    "    \n",
    "    strenddownfill = go.Scatter(\n",
    "        x = df.index,\n",
    "        y = stdownfill, \n",
    "        mode = 'lines',\n",
    "        line = dict(\n",
    "            color='rgba(0,0,0,0)',\n",
    "            width=1\n",
    "        ),\n",
    "        fill='tonexty',   \n",
    "        fillcolor='rgba(255, 0, 0, 0.1)', \n",
    "        connectgaps = False,\n",
    "        visible = False,\n",
    "        showlegend=True,\n",
    "        name = 'SuperTrend'\n",
    "    )\n",
    "    \n",
    "    target_in = go.Scatter(\n",
    "        x = df[df['Target_ingresso'] == 1].index,\n",
    "        y = df[df['Target_ingresso'] == 1]['Close'],\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgba(0, 200, 0, .9)'\n",
    "        ),\n",
    "        name = 'target_in'\n",
    "    )\n",
    "    \n",
    "    target_out = go.Scatter(\n",
    "        x = df[df['Target_uscita'] == 1].index,\n",
    "        y = df[df['Target_uscita'] == 1]['Close'],\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgba(220, 0, 0, .9)'\n",
    "        ),\n",
    "        name = 'target_out'\n",
    "    )\n",
    "        \n",
    "    layout = dict(xaxis = dict(autorange=True),\n",
    "                  yaxis = dict(title = 'Close', autorange=True),\n",
    "                  autosize = True,\n",
    "                  margin = go.layout.Margin(\n",
    "                      l=0,  # Sinistra\n",
    "                      r=0,  # Destra\n",
    "                      b=0,  # Basso\n",
    "                      t=50,  # Alto\n",
    "                      pad=0  # Padding\n",
    "                  ),\n",
    "                  legend = dict(traceorder = 'normal', bordercolor = 'black')\n",
    "    )\n",
    "        \n",
    "    fig = sp.make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "    fig.update_layout(layout)\n",
    "    \n",
    "    # RIGA 1\n",
    "\n",
    "    fig.add_trace(close, row=1, col=1)\n",
    "    fig.add_trace(strendupfill, row=1, col=1)\n",
    "    fig.add_trace(strendup, row=1, col=1)\n",
    "    fig.add_trace(close2, row=1, col=1)\n",
    "    fig.add_trace(strenddownfill, row=1, col=1)\n",
    "    fig.add_trace(strenddown, row=1, col=1)\n",
    "    #fig.add_trace(min5, row=1, col=1); fig.add_trace(max5, row=1, col=1)\n",
    "    #fig.add_trace(min10, row=1, col=1); fig.add_trace(max10, row=1, col=1)\n",
    "    #fig.add_trace(min20, row=1, col=1); fig.add_trace(max20, row=1, col=1)\n",
    "    #fig.add_trace(min60, row=1, col=1); fig.add_trace(max60, row=1, col=1)\n",
    "    fig.add_trace(target_in, row=1, col=1); fig.add_trace(target_out, row=1, col=1)\n",
    "    fig.add_trace(ema5, row=1, col=1); fig.add_trace(ema20, row=1, col=1); fig.add_trace(ema50, row=1, col=1); fig.add_trace(ema100, row=1, col=1)\n",
    "    fig.add_trace(psar, row=1, col=1)\n",
    "    \n",
    "    pyo.plot(fig, filename=\"grafico_target.html\", auto_open=True)\n",
    "    \n",
    "    return fig\n",
    "    \n",
    "def crea_indicatori(df):\n",
    "    def __trova_massimi_minimi(df, periodo):\n",
    "        mezzo_periodo = periodo // 2\n",
    "\n",
    "        massimi_passati = df['Close'].shift(1).rolling(mezzo_periodo).max()\n",
    "        massimi_futuri = df['Close'][::-1].shift(1).rolling(mezzo_periodo).max()[::-1]\n",
    "        idx_massimi = (df[\"Close\"] >= massimi_passati) & (df[\"Close\"] >= massimi_futuri)\n",
    "        df.loc[idx_massimi, \"MaxMinRel\"] = periodo\n",
    "\n",
    "        minimi_passati = df['Close'].shift(1).rolling(mezzo_periodo).min()\n",
    "        minimi_futuri = df['Close'][::-1].shift(1).rolling(mezzo_periodo).min()[::-1]\n",
    "        idx_minimi = (df[\"Close\"] <= minimi_passati) & (df[\"Close\"] <= minimi_futuri)\n",
    "        df.loc[idx_minimi, \"MaxMinRel\"] = -periodo\n",
    "            \n",
    "        return df\n",
    "\n",
    "    def __rinomina_colonne(df):\n",
    "        df = df.rename(columns={\n",
    "            'PSARaf_0.02_0.2': 'PSARaf',\n",
    "            'PSARr_0.02_0.2': 'PSARr',\n",
    "            'MACD_20_50_9': 'MACD',\n",
    "            'MACDh_20_50_9': 'MACDh',\n",
    "            'MACDs_20_50_9': 'MACDs',\n",
    "            'TSI_13_25_13': 'TSI',\n",
    "            'TSIs_13_25_13': 'TSIs',\n",
    "            'SUPERT_20_3.0': 'SUPERT',\n",
    "            'SUPERTd_20_3.0': 'SUPERTd',\n",
    "            'ADX_20': 'ADX',\n",
    "            'DMP_20': 'DMP',\n",
    "            'DMN_20': 'DMN',\n",
    "            'CMF_10': 'CMF',\n",
    "            'TRIX_18_9': 'TRIX',\n",
    "            'TRIXs_18_9': 'TRIXs',\n",
    "            'KVO_34_55_13': 'KVO',\n",
    "            'KVOs_34_55_13': 'KVOs',\n",
    "            'DCL_20_20': 'DCL',\n",
    "            'DCM_20_20': 'DCM',\n",
    "            'DCU_20_20': 'DCU',\n",
    "            'VTXP_20': 'VTXP',\n",
    "            'VTXM_20': 'VTXM',\n",
    "            'AROOND_20': 'AROOND',\n",
    "            'AROONU_20': 'AROONU',\n",
    "            'AROONOSC_20': 'AROONOSC',\n",
    "            'NVI_1': 'NVI',\n",
    "            'PVI_1': 'PVI',\n",
    "            'VHF_20': 'VHF',\n",
    "            'ATRr_14': 'ATR'\n",
    "        })\n",
    "        return df\n",
    "\n",
    "    def __calcolo_drawdown_gain(df, periodo):\n",
    "        df[f\"Max_High_Futuro_{periodo}d\"] = df[\"High\"].shift(-periodo).rolling(periodo).max()\n",
    "        df[f\"Min_Low_Futuro_{periodo}d\"] = df[\"Low\"].shift(-periodo).rolling(periodo).min()\n",
    "        df[f\"Drawdown_{periodo}d\"] = df[\"Open\"] - df[f\"Min_Low_Futuro_{periodo}d\"]\n",
    "        df[f\"Drawdown_{periodo}d\"] = df[f\"Drawdown_{periodo}d\"].where(df[f\"Drawdown_{periodo}d\"] > 0, 0)\n",
    "        df[f\"Perc_Max_High_Futuro_{periodo}d\"] = ((df[f\"Max_High_Futuro_{periodo}d\"] - df[\"Open\"]) / df[\"Open\"]) * 100\n",
    "        df[f\"Perc_Drawdown_{periodo}d\"] = ((df[f\"Drawdown_{periodo}d\"]) / df[\"Open\"]) * 100 \n",
    "        df[f\"Perc_Drawdown_{periodo}d\"] = df[f\"Perc_Drawdown_{periodo}d\"].where(df[f\"Perc_Drawdown_{periodo}d\"] > 0, 0)\n",
    "        df.drop(columns=[f\"Max_High_Futuro_{periodo}d\", f\"Min_Low_Futuro_{periodo}d\", f\"Drawdown_{periodo}d\"], axis=1, inplace=True)\n",
    "        return df\n",
    "    \n",
    "    psar = ta.psar(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"], af0=0.02, af=0.02, max_af=0.2)\n",
    "    psar[\"PSAR\"] = psar[\"PSARl_0.02_0.2\"].combine_first(psar[\"PSARs_0.02_0.2\"])\n",
    "    psar.drop([\"PSARl_0.02_0.2\", \"PSARs_0.02_0.2\"], axis=1, inplace=True)\n",
    "    macd = ta.macd(close=df[\"Close\"], fast=20, slow=50, signal=9)\n",
    "    tsi = ta.tsi(close=df[\"Close\"], fast=13, slow=25)\n",
    "    supertrend = ta.supertrend(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"], length=20, multiplier=3)\n",
    "    supertrend.drop([\"SUPERTl_20_3.0\", \"SUPERTs_20_3.0\"], axis=1, inplace=True)\n",
    "    ema5 = ta.ema(close=df[\"Close\"], length=5)\n",
    "    ema20 = ta.ema(close=df[\"Close\"], length=20)\n",
    "    ema50 = ta.ema(close=df[\"Close\"], length=50)\n",
    "    ema100 = ta.ema(close=df[\"Close\"], length=100)\n",
    "    adx = ta.adx(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"], length=20)\n",
    "    roc = ta.roc(close=df[\"Close\"], length=10)\n",
    "    cmf = ta.cmf(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"], volume=df['Volume'], length=10)\n",
    "    trix = ta.trix(close=df['Close'], length=18)\n",
    "    klinger = ta.kvo(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"], volume=df['Volume'], short=34, long=55)\n",
    "    vi = ta.vortex(high=df['High'], low=df['Low'], close=df['Close'], length=20)\n",
    "    aroon = ta.aroon(high=df['High'], low=df['Low'], close=df['Close'], length=20)\n",
    "    nvi = ta.nvi(close=df['Close'], volume=df['Volume'])\n",
    "    pvi = ta.pvi(close=df['Close'], volume=df['Volume'])\n",
    "    vhf = ta.vhf(close=df['Close'], length=20)\n",
    "    atr = ta.atr(high=df['High'], low=df['Low'], close=df['Close'])\n",
    "    obv = ta.obv(close=df[\"Close\"], volume=df[\"Volume\"])\n",
    "    #candele = ta.cdl_pattern(open_=df[\"Open\"], high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"])\n",
    "\n",
    "    df = pd.concat([df, ema5, ema20, ema50, ema100, psar, macd, tsi, supertrend, adx, trix, vi, aroon, nvi, pvi, atr, cmf, roc, klinger, vhf, obv], axis=1)\n",
    "\n",
    "    df = __rinomina_colonne(df)\n",
    "\n",
    "    df = __calcolo_drawdown_gain(df, 20)\n",
    "    df = __calcolo_drawdown_gain(df, 50)\n",
    "    df = __calcolo_drawdown_gain(df, 100)\n",
    "    df[\"max_gain\"] = df[[\"Perc_Max_High_Futuro_20d\", \"Perc_Max_High_Futuro_50d\", \"Perc_Max_High_Futuro_100d\"]].max(axis=1)\n",
    "    df[\"max_drawdown\"] = df[[\"Perc_Drawdown_20d\", \"Perc_Drawdown_50d\", \"Perc_Drawdown_100d\"]].min(axis=1)\n",
    "\n",
    "    df['EMA_20_5d'] = df['EMA_20'].shift(-5)\n",
    "    df['EMA_20_10d'] = df['EMA_20'].shift(-10)\n",
    "    df['EMA_20_15d'] = df['EMA_20'].shift(-15)\n",
    "    df['EMA_20_20d'] = df['EMA_20'].shift(-20)\n",
    "    df['EMA_50_5d'] = df['EMA_50'].shift(-5)\n",
    "    df['EMA_50_10d'] = df['EMA_50'].shift(-10)\n",
    "    df['EMA_50_15d'] = df['EMA_50'].shift(-15)\n",
    "    df['EMA_50_20d'] = df['EMA_50'].shift(-20)\n",
    "    df['Close_5d'] = df['Close'].shift(-5)\n",
    "    df['Close_10d'] = df['Close'].shift(-10)\n",
    "    df['Close_15d'] = df['Close'].shift(-15)\n",
    "    df['Close_20d'] = df['Close'].shift(-20)\n",
    "    df['EMA_5_5d'] = df['EMA_5'].shift(-5)\n",
    "    df['EMA_5_10d'] = df['EMA_5'].shift(-10)\n",
    "    df['EMA_5_15d'] = df['EMA_5'].shift(-15)\n",
    "    df['EMA_5_20d'] = df['EMA_5'].shift(-20)\n",
    "    #df['Close_1d'] = df['Close'].shift(-1)\n",
    "    #df['perc_EMA_5_20d'] = ((df['EMA_5_20d'] - df['EMA_5']) / df['EMA_5']) * 100\n",
    "    #df['perc_Close_20d'] = ((df['Close_20d'] - df['Close']) / df['Close']) * 100\n",
    "    #df['incrocio_verde_gialla'] = (ta.cross(df['EMA_20'], df['EMA_50'], above=True)).astype(\"int8\")\n",
    "    #df[\"incrocio_passato_verde_gialla_10d\"] = df[\"incrocio_verde_gialla\"].rolling(10).sum()\n",
    "    \n",
    "    #df['HLC3'] = ((df['High'] + df['Low'] + df['Close']) / 3)\n",
    "    df[\"DM_OSC\"] = (df[\"DMP\"] - df[\"DMN\"])\n",
    "    df[\"VTX_OSC\"] = (df[\"VTXP\"] - df[\"VTXM\"])\n",
    "    df[\"VI_OSC\"] = (df[\"PVI\"] - df[\"NVI\"])\n",
    "    \n",
    "    df.drop(columns=[\"DMP\", \"DMN\", \"VTXP\", \"VTXM\", \"PVI\", \"NVI\", \"AROOND\", \"AROONU\"], inplace=True, axis=1)\n",
    "    \n",
    "    df[\"MaxMinRel\"] = 0\n",
    "    df = __trova_massimi_minimi(df, 20)   \n",
    "    df = __trova_massimi_minimi(df, 50)   \n",
    "    df = __trova_massimi_minimi(df, 100)         \n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    return df\n",
    "\n",
    "def _scarica(nome_simbolo, scarica_prima, scarica_dopo, data_inizio, data_fine, append):\n",
    "    try:\n",
    "        if append == True:\n",
    "            ticker = pd.read_hdf(f'tickers/{nome_simbolo}.h5', \"ticker\")\n",
    "            ti_min = ticker.index.min()\n",
    "            ti_max = ticker.index.max()\n",
    "            if scarica_prima:\n",
    "                inizio = data_inizio - pd.Timedelta(days=365)\n",
    "                fine = ti_min - pd.Timedelta(days=1)\n",
    "                df_inizio = analizza_ticker(nome_simbolo, start=inizio, end=fine, progress=False, dropna_iniziali=True, dropna_finali=False)\n",
    "                ticker = pd.concat([df_inizio, ticker], axis=0, ignore_index=False)\n",
    "            if scarica_dopo:\n",
    "                inizio = ti_max - pd.Timedelta(days=365) \n",
    "                fine = data_fine\n",
    "                df_fine = analizza_ticker(nome_simbolo, start=inizio, end=fine, progress=False, dropna_iniziali=True, dropna_finali=False)\n",
    "                ticker = ticker[ticker.index < df_fine.index.min()]\n",
    "                ticker = pd.concat([ticker, df_fine], axis=0, ignore_index=False)\n",
    "        else:\n",
    "            ticker = analizza_ticker(nome_simbolo, start=data_inizio, end=data_fine, progress=False, dropna_iniziali=True, dropna_finali=False)\n",
    "        return nome_simbolo, ticker, \"\"\n",
    "    except Exception as e:\n",
    "        return nome_simbolo, None, str(e)\n",
    "\n",
    "def _callback_tickers(result, totale_processati, tot_tickers):\n",
    "    nome_simbolo, ticker, error = result\n",
    "    if error == \"\":\n",
    "        ticker.to_hdf(f'tickers/{nome_simbolo}.h5', key='ticker', mode='w')\n",
    "    else:\n",
    "        print(f\"Errore su funzione di callback per {nome_simbolo}: {error}\")\n",
    "\n",
    "    with totale_processati.get_lock(): \n",
    "        totale_processati.value += 1\n",
    "    print(f\"{totale_processati.value}/{tot_tickers}) Scaricato ticker {nome_simbolo}\")   \n",
    "    \n",
    "def _carica_screener(nome_simbolo, lista_scr, lista_scr_out, prob, nome_dataset):\n",
    "    try:\n",
    "        df = pd.read_hdf(f'screeners/{nome_simbolo}.h5', nome_dataset)\n",
    "        df.index.set_names(['Data'], inplace=True)\n",
    "        df['Ticker'] = nome_simbolo\n",
    "        df.set_index('Ticker', append=True, inplace=True)\n",
    "        df = df[df['Previsione'] > prob]\n",
    "        if nome_dataset == 'screener':\n",
    "            lista_scr.append(df)\n",
    "        else:\n",
    "            lista_scr_out.append(df)\n",
    "        return nome_simbolo, \"\"\n",
    "    except Exception as e:\n",
    "        return nome_simbolo, str(e)\n",
    "\n",
    "def _carica_screener_callback(result, totale_processati, tot_tickers):\n",
    "    nome_simbolo, error = result\n",
    "    if error != \"\":\n",
    "        print(f\"Errore su funzione di callback per {nome_simbolo}: {error}\")\n",
    "\n",
    "    with totale_processati.get_lock(): \n",
    "        totale_processati.value += 1\n",
    "    print(f\"{totale_processati.value}/{tot_tickers}) Caricato su screener ticker {nome_simbolo}\")   \n",
    "\n",
    "def to_XY(dati_ticker, timesteps, giorni_previsione, features, targets, bilanciamento=0):\n",
    "    features_scala_prezzo = [ft for ft in _features_scala_prezzo_tutte if ft in features]\n",
    "    features_da_scalare_singolarmente = [ft for ft in _features_da_scalare_singolarmente_tutte if ft in features]\n",
    "    features_oscillatori = [ft for ft in _features_oscillatori_tutte if ft in features]\n",
    "    features_no_scala = [ft for ft in _features_no_scala_tutte if ft in features]\n",
    "    features_candele = [ft for ft in _features_candele_tutte if ft in features]\n",
    "\n",
    "    scalers_prezzo = []\n",
    "    scaler_meno_piu = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler_standard = MinMaxScaler()\n",
    "\n",
    "    new_dates = pd.bdate_range(start=dati_ticker.index[-1] + pd.Timedelta(days=1), periods=giorni_previsione)\n",
    "    df_new = pd.DataFrame(index=new_dates)\n",
    "    dati_ticker = pd.concat([dati_ticker, df_new])\n",
    "\n",
    "    ft_prezzo = dati_ticker[features_scala_prezzo]\n",
    "    ft_standard = dati_ticker[features_da_scalare_singolarmente]\n",
    "    ft_meno_piu = dati_ticker[features_oscillatori]\n",
    "    ft_no_scala = dati_ticker[features_no_scala]\n",
    "    ft_candele = dati_ticker[features_candele] \n",
    "\n",
    "    _targets = dati_ticker[targets]\n",
    "\n",
    "    i_tot = len(dati_ticker) - giorni_previsione\n",
    "\n",
    "    tot_elementi = i_tot - (timesteps-1)    \n",
    "    \n",
    "    X_prezzo = X_standard = X_meno_piu = X_no_scala = X_candele = None\n",
    "    if len(features_scala_prezzo) > 0:\n",
    "        tot_col_prezzo_x = len(ft_prezzo.columns)\n",
    "        X_prezzo = np.zeros((tot_elementi, timesteps, tot_col_prezzo_x))\n",
    "    if len(features_da_scalare_singolarmente) > 0:\n",
    "        tot_col_standard_x = len(ft_standard.columns)\n",
    "        X_standard = np.zeros((tot_elementi, timesteps, tot_col_standard_x))\n",
    "    if len(features_oscillatori) > 0:\n",
    "        tot_col_meno_piu_x = len(ft_meno_piu.columns)\n",
    "        X_meno_piu = np.zeros((tot_elementi, timesteps, tot_col_meno_piu_x))\n",
    "    if len(features_no_scala) > 0:\n",
    "        tot_col_no_scala_x = len(ft_no_scala.columns)\n",
    "        X_no_scala = np.zeros((tot_elementi, timesteps, tot_col_no_scala_x))\n",
    "    if len(features_candele) > 0:\n",
    "        tot_col_candele_x = len(ft_candele.columns)\n",
    "        X_candele = np.zeros((tot_elementi, timesteps, tot_col_candele_x))\n",
    "    if len(targets) > 0:\n",
    "        #tot_col_targets_y = len(targets.columns)\n",
    "        #Y = np.zeros((tot_elementi, giorni_previsione, tot_col_targets_y)) # togliere se classificazione binaria\n",
    "        Y = np.zeros(tot_elementi) #solo per classificazione binaria\n",
    "    \n",
    "    for i in range(timesteps - 1, i_tot):\n",
    "        if len(features_scala_prezzo) > 0:\n",
    "            arr_x = np.array(ft_prezzo.iloc[i - (timesteps - 1):i + 1])\n",
    "            arr_res = arr_x.reshape(-1, 1)\n",
    "            scaler_prezzo = MinMaxScaler()\n",
    "            scaler_prezzo.fit(arr_res)\n",
    "            arr_sc = scaler_prezzo.transform(arr_res).reshape(timesteps, tot_col_prezzo_x)\n",
    "            X_prezzo[i - (timesteps - 1)] = arr_sc\n",
    "            scalers_prezzo.append(scaler_prezzo)\n",
    "\n",
    "        if len(features_da_scalare_singolarmente) > 0:\n",
    "            arr_x = np.array(ft_standard.iloc[i - (timesteps - 1):i + 1])\n",
    "            arr_sc = scaler_standard.fit_transform(arr_x)   \n",
    "            X_standard[i - (timesteps - 1)] = arr_sc\n",
    "\n",
    "        if len(features_oscillatori) > 0:\n",
    "            arr_x = np.array(ft_meno_piu.iloc[i - (timesteps - 1):i + 1])\n",
    "            arr_sc = scaler_meno_piu.fit_transform(arr_x)   \n",
    "            X_meno_piu[i - (timesteps - 1)] = arr_sc\n",
    "\n",
    "        if len(features_no_scala) > 0:\n",
    "            arr_x = np.array(ft_no_scala.iloc[i - (timesteps - 1):i + 1])\n",
    "            X_no_scala[i - (timesteps - 1)] = arr_x\n",
    "\n",
    "        if len(features_candele) > 0:\n",
    "            arr_x = np.array(ft_candele.iloc[i - (timesteps - 1):i + 1])\n",
    "            arr_sc = scaler_meno_piu.fit_transform(arr_x) \n",
    "            X_candele[i - (timesteps - 1)] = arr_sc\n",
    "\n",
    "        if len(targets) > 0:\n",
    "            # arr_y = np.array(targets.iloc[i + 1:i + 1 + giorni_previsione]) # togliere in caso di classificazione binaria\n",
    "            # arr_res = arr_y.reshape(-1, 1) # togliere in caso di classificazione binaria\n",
    "            # arr_sc = scaler_prezzo.transform(arr_res).reshape(giorni_previsione, tot_col_targets_y) # togliere in caso di classificazione binaria\n",
    "            # Y[i - (timesteps - 1)] = arr_sc  # togliere in caso di classificazione binaria\n",
    "            Y[i - (timesteps - 1)] = np.array(_targets.iloc[i]) #solo per classificazione binaria\n",
    "\n",
    "    X_list = [x for x in [X_prezzo, X_standard, X_meno_piu, X_no_scala, X_candele] if x is not None and x.size > 0]\n",
    "    X = np.concatenate(X_list, axis=2) if X_list else np.array([])\n",
    "    idx = dati_ticker.index[timesteps - 1:i_tot]\n",
    "\n",
    "    if bilanciamento > 0:\n",
    "        #rus = RandomUnderSampler(sampling_strategy=bilanciamento)\n",
    "        smote = SMOTE(sampling_strategy=bilanciamento)\n",
    "        dim1 = X.shape[1]\n",
    "        dim2 = X.shape[2]\n",
    "        X_flat = X.reshape(-1, dim1 * dim2)\n",
    "        # Applica l'undersampling\n",
    "        X_flat_resampled, Y = smote.fit_resample(X_flat, Y)\n",
    "\n",
    "        # Ridimensiona X tornando alla forma originale\n",
    "        X = X_flat_resampled.reshape(-1, dim1, dim2)\n",
    "\n",
    "        # Ottieni gli indici originali dopo l'undersampling\n",
    "        #idx_resampled = rus.sample_indices_\n",
    "\n",
    "        # Usa idx_resampled per ottenere gli indici originali\n",
    "        #idx = idx[idx_resampled]\n",
    "\n",
    "    Y = Y.reshape(-1, 1)\n",
    "    return idx, X, Y, scalers_prezzo\n",
    "\n",
    "def concatena(array_list, hdf5_file, dataset_name):\n",
    "    \"\"\"\n",
    "    Concatena una lista di array NumPy a un dataset in un file HDF5, creando il file se non esiste.\n",
    "    \n",
    "    :param array_list: Lista di array NumPy da aggiungere.\n",
    "    :param hdf5_file: Percorso del file HDF5.\n",
    "    :param dataset_name: Nome del dataset all'interno del file HDF5.\n",
    "    \"\"\"\n",
    "    # Apri o crea il file HDF5\n",
    "    with h5py.File(hdf5_file, 'a') as h5f:  # 'a' apre il file in modalità read/write e lo crea se non esiste\n",
    "        # Controlla se il dataset esiste già\n",
    "        if dataset_name in h5f:\n",
    "            # Il dataset esiste, leggi la sua lunghezza e aggiungi gli array\n",
    "            dset = h5f[dataset_name]\n",
    "        else:\n",
    "            # Il dataset non esiste, quindi dobbiamo crearlo\n",
    "            # Usiamo la forma del primo array per definire la forma del dataset\n",
    "            initial_shape = (0,) + array_list[0].shape[1:]\n",
    "            maxshape = (None,) + array_list[0].shape[1:]\n",
    "            \n",
    "            # Crea il dataset con shape iniziale e maxshape\n",
    "            dset = h5f.create_dataset(dataset_name, shape=initial_shape, maxshape=maxshape, chunks=True)\n",
    "            \n",
    "        # Itera su tutti gli array nella lista\n",
    "        for array in array_list:\n",
    "            # Calcola la nuova lunghezza del dataset\n",
    "            new_len = dset.shape[0] + array.shape[0]\n",
    "            # Ridimensiona il dataset per accogliere i nuovi dati\n",
    "            dset.resize(new_len, axis=0)\n",
    "            # Aggiungi il nuovo array alla fine del dataset\n",
    "            dset[-array.shape[0]:] = array\n",
    "\n",
    "class Posizione:\n",
    "    def __init__(self, simbolo, ticker, screener_out, data, n_azioni, bilancio, max_giorni_apertura, stop_loss, take_profit) -> None:\n",
    "        self.simbolo = simbolo\n",
    "        self.ticker = ticker\n",
    "        self.screener_out = screener_out\n",
    "        self.data = data\n",
    "        self.prezzo_unitario = ticker['Open'].iloc[0]\n",
    "        self.n_azioni = n_azioni\n",
    "        self.stop_loss = self.prezzo_unitario * (1 - stop_loss)\n",
    "        self.take_profit = self.prezzo_unitario * (1 + take_profit)\n",
    "        self.prezzo_tot = self.n_azioni * self.prezzo_unitario\n",
    "        self.bilancio = bilancio - self.prezzo_tot \n",
    "        self.giorni_apertura = 1\n",
    "        self.max_giorni_apertura = max_giorni_apertura\n",
    "        self._valore = self.prezzo_tot\n",
    "        self._colonne = ['Simbolo', 'Data', 'Tipo', 'Prezzo_unitario', 'n_azioni', 'Prezzo_tot', 'SL', 'TP', 'Bilancio', 'Valore_posizione', 'Giorni_apertura', 'Esito', 'Vincita', 'Perc']\n",
    "    \n",
    "    def valore(self, data):\n",
    "        dati_attuali = self.ticker[self.ticker.index == data]\n",
    "        prezzo_attuale = dati_attuali['Open'].iloc[0]\n",
    "        return prezzo_attuale * self.n_azioni\n",
    "    \n",
    "    def to_df(self, data) -> pd.DataFrame:\n",
    "        return pd.DataFrame([\n",
    "            [self.simbolo, self.data.normalize(), 'COMPRA', self.prezzo_unitario.round(2), int(self.n_azioni), self.prezzo_tot.round(2), self.stop_loss.round(2), self.take_profit.round(2), self.bilancio.round(2), round(self.valore(data), 2), int(self.giorni_apertura), '', 0, 0]\n",
    "        ], columns=self._colonne)\n",
    "\n",
    "    def chiudi(self, data, bilancio, forza_chiusura=False):\n",
    "        if ((data in self.ticker.index) and (data in self.screener_out.index)) or (forza_chiusura):\n",
    "            if forza_chiusura:\n",
    "                dati_attuali = self.ticker.iloc[-1:]\n",
    "                _screener_out = self.screener_out.loc[data].loc[self.screener_out['Previsione'] > 0.5]\n",
    "            else:\n",
    "                dati_attuali = self.ticker[self.ticker.index == data]\n",
    "                _screener_out = pd.DataFrame()\n",
    "            self.giorni_apertura += 1\n",
    "            prezzo_attuale = dati_attuali['Open'].iloc[0]\n",
    "            prezzo_tot = prezzo_attuale * self.n_azioni\n",
    "            #if (self.giorni_apertura > self.max_giorni_apertura) or (prezzo_attuale < self.stop_loss) or (prezzo_attuale > self.take_profit) or (forza_chiusura):\n",
    "            if (self.giorni_apertura > self.max_giorni_apertura) or (self.simbolo in _screener_out.index) or (forza_chiusura):\n",
    "                bilancio += prezzo_tot\n",
    "                if prezzo_attuale > self.prezzo_unitario:\n",
    "                    esito = 'VINCITA'\n",
    "                else:\n",
    "                    esito = 'PERDITA'\n",
    "                esito_tot = prezzo_tot - self.prezzo_tot\n",
    "                esito_pct = pct_change(self.prezzo_unitario, prezzo_attuale)\n",
    "                return pd.DataFrame([\n",
    "                    [self.simbolo, data.normalize(), 'VENDI', prezzo_attuale.round(2), int(self.n_azioni), prezzo_tot.round(2), self.stop_loss.round(2), self.take_profit.round(2), bilancio.round(2), self.valore(data).round(2), int(self.giorni_apertura), esito, esito_tot.round(2), int(esito_pct)]\n",
    "                ], columns=self._colonne)\n",
    "        return None\n",
    "\n",
    "class Borsa:\n",
    "    def __init__(self, n_simboli_contemporanei, bilancio_iniziale, probabilità_per_acquisto, giorni_max_posizione,stop_loss=0, take_profit=0, data_inizio=pd.Timestamp(year=2005, month=1, day=1), data_fine=pd.Timestamp.now().normalize()):\n",
    "        self.N_SIMBOLI = n_simboli_contemporanei\n",
    "        self.DATA_INIZIO = pd.to_datetime(data_inizio)\n",
    "        self.DATA_FINE = pd.to_datetime(data_fine)\n",
    "        self.BILANCIO_INIZIALE = bilancio_iniziale\n",
    "        self.PROBABILITA_PER_ACQUISTO = probabilità_per_acquisto\n",
    "        self.SL = stop_loss\n",
    "        self.TP = take_profit\n",
    "        self.GIORNI_POS = giorni_max_posizione\n",
    "        self._posizioni = []\n",
    "        self._valore_posizioni = 0\n",
    "        self._bilancio = None\n",
    "        self._data_corrente = None\n",
    "        self._bilancio_per_simbolo = None\n",
    "        self.esito_trading = None\n",
    "\n",
    "        self.modello_ingresso = Modello()\n",
    "        self.modello_ingresso.carica(progetto='mod_1_in')\n",
    "        self.timesteps = self.modello_ingresso.timesteps\n",
    "        self.giorni_previsione = self.modello_ingresso.giorni_previsione\n",
    "        self.features = self.modello_ingresso.features\n",
    "        self.targets = self.modello_ingresso.targets\n",
    "        \n",
    "        self.modello_uscita = Modello()\n",
    "        self.modello_uscita.carica(progetto='mod_1_out')\n",
    "        self.features_out = self.modello_uscita.features\n",
    "        self.targets_out = self.modello_uscita.targets        \n",
    "\n",
    "        self.lista_tickers = pd.read_parquet(\"lista_ticker.parquet\")\n",
    "        self.tot_tickers = len(self.lista_tickers)\n",
    "        self.screener = pd.DataFrame()\n",
    "        self.screener_out = pd.DataFrame()\n",
    "\n",
    "    def aggiorna_dati(self):\n",
    "        try:\n",
    "            if os.path.exists(f'_indice.json'):\n",
    "                with open(f'_indice.json', 'r') as jsonfile:\n",
    "                    indice = json.load(jsonfile)\n",
    "                prima_data = pd.to_datetime(indice['prima_data'])\n",
    "                ultima_data = pd.to_datetime(indice['ultima_data'])\n",
    "                \n",
    "                if (self.DATA_INIZIO < prima_data):\n",
    "                    scarica_prima = True\n",
    "                else:\n",
    "                    scarica_prima = False\n",
    "\n",
    "                if (self.DATA_FINE > ultima_data):\n",
    "                    scarica_dopo = True\n",
    "                else:\n",
    "                    scarica_dopo = False\n",
    "\n",
    "                if scarica_prima or scarica_dopo:\n",
    "                    self.scarica_tickers(scarica_prima, scarica_dopo, self.DATA_INIZIO, self.DATA_FINE, append=True)\n",
    "                    self.avvia_screener(append=True)    \n",
    "                else:\n",
    "                    self.screener = pd.read_hdf('screeners/_screener.h5', 'screener')\n",
    "                    self.screener_out = pd.read_hdf('screeners/_screener.h5', 'screener_out')\n",
    "            else:\n",
    "                self.scarica_tickers(scarica_prima=True, scarica_dopo=True, data_inizio=self.DATA_INIZIO, data_fine=self.DATA_FINE, append=False)\n",
    "                self.avvia_screener(append=False)    \n",
    "            self.aggiorna_lista_tickers()              \n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "        \n",
    "    def carica_screener(self, nome_dataset):\n",
    "        manager = Manager()\n",
    "        lista_scr = manager.list()\n",
    "        lista_scr_out = manager.list()\n",
    "        totale_processati = Value('i', 0)\n",
    "        with Pool(cpu_count()) as p:\n",
    "            callback_with_args = partial(_carica_screener_callback, totale_processati=totale_processati, tot_tickers=self.tot_tickers)\n",
    "            for i in range(0, self.tot_tickers):\n",
    "                nome_simbolo = self.lista_tickers.iloc[i][\"Ticker\"]\n",
    "                param = (nome_simbolo, lista_scr, lista_scr_out, self.PROBABILITA_PER_ACQUISTO, nome_dataset)\n",
    "                p.apply_async(_carica_screener, args=param, callback=callback_with_args)\n",
    "            p.close()\n",
    "            p.join()  \n",
    "        if nome_dataset == 'screener':\n",
    "            self.screener = pd.concat(lista_scr, axis=0, ignore_index=False)\n",
    "            self.screener = self.screener.sort_values(by=['Data', 'Previsione'], ascending=[True, False])\n",
    "        else:\n",
    "            self.screener_out = pd.concat(lista_scr_out, axis=0, ignore_index=False)\n",
    "            self.screener_out = self.screener_out.sort_values(by=['Data', 'Previsione'], ascending=[True, False])\n",
    "\n",
    "    def scarica_tickers(self, scarica_prima=True, scarica_dopo=True, data_inizio=pd.Timestamp(year=2005, month=1, day=1), data_fine=pd.Timestamp.now().normalize(), append=False) -> None: \n",
    "        totale_processati = Value('i', 0)\n",
    "        with Pool(cpu_count()) as p:\n",
    "            callback_with_args = partial(_callback_tickers, totale_processati=totale_processati, tot_tickers=self.tot_tickers)\n",
    "            for i in range(0, self.tot_tickers):\n",
    "                nome_simbolo = self.lista_tickers.iloc[i][\"Ticker\"]\n",
    "                param = (nome_simbolo, scarica_prima, scarica_dopo, data_inizio, data_fine, append)\n",
    "                p.apply_async(_scarica, args=param, callback=callback_with_args)\n",
    "            p.close()\n",
    "            p.join()     \n",
    "\n",
    "        indice = {\n",
    "            'prima_data': data_inizio.strftime('%Y-%m-%d'),\n",
    "            'ultima_data': data_fine.strftime('%Y-%m-%d')\n",
    "        }\n",
    "        with open(f'_indice.json', 'w') as jsonfile:\n",
    "            json.dump(indice, jsonfile, indent=4)    \n",
    "\n",
    "    def aggiorna_lista_tickers(self):\n",
    "        lista_files = os.listdir('tickers')\n",
    "        lista_files = [os.path.splitext(file)[0] for file in lista_files]\n",
    "        self.lista_tickers = self.lista_tickers[self.lista_tickers['Ticker'].isin(lista_files)]\n",
    "        self.lista_tickers.to_parquet('lista_ticker.parquet')\n",
    "\n",
    "    def avvia_screener(self, append=False, inizia_da=0) -> None:\n",
    "        tot_tickers = len(self.lista_tickers)\n",
    "\n",
    "        for i in range(inizia_da, tot_tickers):\n",
    "            try:\n",
    "                nome_simbolo = self.lista_tickers.iloc[i][\"Ticker\"]\n",
    "                print(\"\\033[42m\" + f'{i+1}/{tot_tickers}) Caricamento ticker {nome_simbolo}' + \"\\033[0m\")\n",
    "                ticker = pd.read_hdf(f'tickers/{nome_simbolo}.h5', 'ticker')\n",
    "                if append:\n",
    "                    scr = pd.read_hdf(f'screeners/{nome_simbolo}.h5', 'screener')\n",
    "                    scr_out = pd.read_hdf(f'screeners/{nome_simbolo}.h5', 'screener_out')\n",
    "                    inizio = scr.index.max() - pd.Timedelta(days=365)\n",
    "                    ticker_analisi = ticker[ticker.index >= inizio]\n",
    "                    if scr.index.max() == ticker.index.max():\n",
    "                        scr = scr.drop(scr.index[-1])\n",
    "                        scr_out = scr_out.drop(scr_out.index[-1])\n",
    "                    idx, X, Y, _ = to_XY(dati_ticker=ticker_analisi, timesteps=self.timesteps, giorni_previsione=self.giorni_previsione, features=self.features, targets=self.targets, bilanciamento=0)\n",
    "                    idx_out, X_out, Y_out, _ = to_XY(dati_ticker=ticker_analisi, timesteps=self.timesteps, giorni_previsione=self.giorni_previsione, features=self.features_out, targets=self.targets_out, bilanciamento=0)\n",
    "                    print(f'Aggiornamento previsione {nome_simbolo}')\n",
    "                    pred = self.modello_ingresso.model.predict(X)\n",
    "                    pred_out = self.modello_uscita.model.predict(X_out)\n",
    "                    scr_temp = pd.DataFrame({'Previsione': pred.flatten().round(2), 'Reale': Y.flatten()}, index=idx)\n",
    "                    scr_temp = scr_temp[scr_temp.index > scr.index.max()]\n",
    "                    scr = pd.concat([scr, scr_temp], axis=0, ignore_index=False)\n",
    "                    scr_temp = pd.DataFrame({'Previsione': pred_out.flatten().round(2), 'Reale': Y_out.flatten()}, index=idx_out)\n",
    "                    scr_temp = scr_temp[scr_temp.index > scr_out.index.max()]\n",
    "                    scr_out = pd.concat([scr_out, scr_temp], axis=0, ignore_index=False)\n",
    "                    print(f\"Aggiornamento file {nome_simbolo}.h5\")\n",
    "                    scr.to_hdf(f'screeners/{nome_simbolo}.h5', key='screener', mode='w')\n",
    "                    scr_out.to_hdf(f'screeners/{nome_simbolo}.h5', key='screener_out', mode='a')\n",
    "                else:\n",
    "                    idx, X, Y, _ = to_XY(dati_ticker=ticker, timesteps=self.timesteps, giorni_previsione=self.giorni_previsione, features=self.features, targets=self.targets, bilanciamento=0)\n",
    "                    idx_out, X_out, Y_out, _ = to_XY(dati_ticker=ticker, timesteps=self.timesteps, giorni_previsione=self.giorni_previsione, features=self.features_out, targets=self.targets_out, bilanciamento=0)\n",
    "                    print(f'Previsione {nome_simbolo}')\n",
    "                    pred = self.modello_ingresso.model.predict(X)\n",
    "                    scr = pd.DataFrame({'Previsione': pred.flatten().round(2), 'Reale': Y.flatten()}, index=idx)\n",
    "                    scr = scr[scr.index >= self.DATA_INIZIO]\n",
    "                    pred_out = self.modello_uscita.model.predict(X_out)\n",
    "                    scr_out = pd.DataFrame({'Previsione': pred_out.flatten().round(2), 'Reale': Y_out.flatten()}, index=idx_out)\n",
    "                    scr_out = scr_out[scr_out.index >= self.DATA_INIZIO]\n",
    "                    print(f\"Salvataggio file {nome_simbolo}.h5\")\n",
    "                    scr.to_hdf(f'screeners/{nome_simbolo}.h5', key='screener', mode='w')\n",
    "                    scr_out.to_hdf(f'screeners/{nome_simbolo}.h5', key='screener_out', mode='a')\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "        self.carica_screener('screener')\n",
    "        self.carica_screener('screener_out')\n",
    "        self.screener.to_hdf('screeners/_screener.h5', key='screener', mode='w')\n",
    "        self.screener_out.to_hdf('screeners/_screener.h5', key='screener_out', mode='a')\n",
    "\n",
    "    def ultimo_screener(self) -> (pd.Timestamp, pd.DataFrame):\n",
    "        # Ottieni l'ultimo valore dell'indice di livello 0\n",
    "        ultimo_indice = self.screener.index.get_level_values(0)[-1]\n",
    "        ultimo_indice_out = self.screener_out.index.get_level_values(0)[-1]\n",
    "        # Usa .loc per selezionare tutte le righe con quell'indice di livello 0\n",
    "        return ultimo_indice.date(), self.screener.loc[ultimo_indice], ultimo_indice_out.date(), self.screener_out.loc[ultimo_indice_out]\n",
    "\n",
    "    def valore_posizioni(self, data):\n",
    "        tot = 0\n",
    "        for pos in self._posizioni:\n",
    "            tot += pos.valore(data)\n",
    "        return tot\n",
    "\n",
    "    def reset_trading(self) -> None:\n",
    "        self._data_corrente = self.DATA_INIZIO\n",
    "        self._posizioni = []\n",
    "        self._bilancio = self.BILANCIO_INIZIALE\n",
    "        self.esito_trading = pd.DataFrame()\n",
    "        self._bilancio_per_simbolo = self.BILANCIO_INIZIALE / self.N_SIMBOLI\n",
    "        self._valore_posizioni = 0\n",
    "\n",
    "    def avvia_trading(self) -> None:\n",
    "        self.reset_trading()\n",
    "        while self._data_corrente <= self.DATA_FINE:\n",
    "            print(\"\\r\\033[31m\" + f'Data: {self._data_corrente.date()}, Pos. aperte: {len(self._posizioni)}' + \"\\033[0m\", end=' ')\n",
    "            self._chiudi_posizioni()\n",
    "            if self._data_corrente in self.screener.index.get_level_values(0):\n",
    "                scr = self.screener.loc[(self._data_corrente, slice(None)), :]\n",
    "                i = 0\n",
    "                esito = True\n",
    "                while (len(self._posizioni) < self.N_SIMBOLI) and (i < len(scr)):\n",
    "                    simbolo = scr.index[i][1]\n",
    "                    esito = self._apri_posizione(simbolo)\n",
    "                    i += 1\n",
    "            self._data_corrente += timedelta(days=1)\n",
    "        \n",
    "        self._chiudi_posizioni(forza_chiusura=True)\n",
    "\n",
    "    def _chiudi_posizioni(self, forza_chiusura=False):\n",
    "        posizioni_da_mantenere = []\n",
    "        for pos in self._posizioni:\n",
    "            df = pos.chiudi(self._data_corrente, self._bilancio, forza_chiusura=forza_chiusura)\n",
    "            if df is not None or forza_chiusura:\n",
    "                self.esito_trading = pd.concat([self.esito_trading, df], axis=0, ignore_index=True)\n",
    "                df = df.iloc[0]\n",
    "                self._bilancio = df['Bilancio']\n",
    "                val = self.valore_posizioni(self._data_corrente)\n",
    "                pos_da_aprire = (self.N_SIMBOLI - len(self._posizioni) + 1)\n",
    "                if pos_da_aprire == 0:\n",
    "                    self._bilancio_per_simbolo = 0.\n",
    "                else:\n",
    "                    self._bilancio_per_simbolo = self._bilancio / pos_da_aprire\n",
    "                print(f\"VENDI {df['Simbolo']} n.{df['n_azioni']} azioni a {df['Prezzo_unitario']} € = {df['Prezzo_tot']} €, Esito: {df['Esito']}, Perc: {df['Perc']}, Bilancio: {round(self._bilancio, 2)} € + valore pos. aperte: {round(val, 2)} € = {round(self._bilancio + self._valore_posizioni, 2)} €, Bilancio per simbolo: {round(self._bilancio_per_simbolo, 2)}\")\n",
    "            else:\n",
    "                posizioni_da_mantenere.append(pos)\n",
    "        self._posizioni = posizioni_da_mantenere\n",
    "\n",
    "    def _apri_posizione(self, simbolo):\n",
    "        try:\n",
    "            ticker = pd.read_hdf(f'tickers/{simbolo}.h5', 'ticker')\n",
    "            ticker = ticker[ticker.index >= self._data_corrente]\n",
    "            prezzo = ticker[\"Open\"].iloc[0]\n",
    "            n_azioni = self._bilancio_per_simbolo // prezzo\n",
    "            if (prezzo < self._bilancio_per_simbolo) and (simbolo not in [x.simbolo for x in self._posizioni]):\n",
    "                pos = Posizione(simbolo, ticker, self.screener_out, self._data_corrente, n_azioni, self._bilancio, self.GIORNI_POS, self.SL, self.TP)\n",
    "                self._valore_posizioni += pos.valore(self._data_corrente)\n",
    "                self._posizioni.append(pos)\n",
    "                self.esito_trading = pd.concat([self.esito_trading, pos.to_df(self._data_corrente)], axis=0, ignore_index=True)\n",
    "                self._bilancio = pos.bilancio\n",
    "                pos_da_aprire = (self.N_SIMBOLI - len(self._posizioni))\n",
    "                if pos_da_aprire == 0:\n",
    "                    self._bilancio_per_simbolo = 0.\n",
    "                else:\n",
    "                    self._bilancio_per_simbolo = self._bilancio / pos_da_aprire\n",
    "                print(f'COMPRA {simbolo} n.{int(pos.n_azioni)} azioni a {round(pos.prezzo_unitario, 2)} € = {round(pos.prezzo_tot, 2)} €,  Bilancio: {round(self._bilancio, 2)} € + valore pos. aperte: {round(self._valore_posizioni, 2)} € = {round(self._bilancio + self._valore_posizioni, 2)} €, Bilancio per simbolo: {round(self._bilancio_per_simbolo, 2)}')\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f'Errore in apertura posizione: {str(e)}')\n",
    "            return False\n",
    "\n",
    "    # Funzione obiettivo per l'ottimizzazione\n",
    "    def funzione_obiettivo(self, N_SIMBOLI, GIORNI_POS, SL, TP):\n",
    "        # Imposta i parametri\n",
    "        self.N_SIMBOLI = N_SIMBOLI\n",
    "        self.GIORNI_POS = GIORNI_POS\n",
    "        self.SL = SL\n",
    "        self.TP = TP\n",
    "        print('PARAMETRI:')\n",
    "        print(f'N.simboli = {N_SIMBOLI}')\n",
    "        print(f'Giorni pos. = {GIORNI_POS}')\n",
    "        print(f'SL = {SL}')\n",
    "        print(f'TP = {TP}')\n",
    "        # Esegui il trading\n",
    "        self.avvia_trading()\n",
    "\n",
    "        # Restituisce il bilancio finale in modo negativo per la minimizzazione\n",
    "        return -self._bilancio\n",
    "\n",
    "class Modello:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def _crea_modello(self):      \n",
    "        # Input layer\n",
    "        input_layer = Input(shape=(self.timesteps, self.n_features))\n",
    "\n",
    "        # Convolutional layer\n",
    "        conv1 = Conv1D(filters=128, kernel_size=5, activation='relu')(input_layer)\n",
    "        conv1 = BatchNormalization()(conv1)\n",
    "\n",
    "        # Continuation of the model\n",
    "        lstm2 = GRU(50)(conv1)\n",
    "        lstm2 = Dropout(0.5)(lstm2)\n",
    "\n",
    "        dense2 = Dense(80, activation='relu', kernel_regularizer=regularizers.l2(0.02))(lstm2)\n",
    "        dense2 = Dropout(0.5)(dense2)\n",
    "\n",
    "        batch_norm1 = BatchNormalization()(dense2)\n",
    "\n",
    "        dense3 = Dense(40, activation='relu', kernel_regularizer=regularizers.l2(0.02))(batch_norm1)\n",
    "        dense3 = Dropout(0.5)(dense3)\n",
    "\n",
    "        batch_norm2 = BatchNormalization()(dense3)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = Dense(1, activation='sigmoid')(batch_norm2)\n",
    "\n",
    "        adam = Adam(learning_rate=self.learning_rate)\n",
    "        model = Model(inputs=input_layer, outputs=output_layer)\n",
    "        model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall(), AUC(curve='PR')])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def crea(self, \n",
    "             progetto='default', \n",
    "             timesteps=120, \n",
    "             giorni_previsione=1, \n",
    "             features=[\"EMA_20\", \"EMA_50\", \"EMA_100\", \"Volume\", \"MACDh\", \"AROONOSC\", \"TRIX\", \"DM_OSC\", \"TSI\", \"KVO\"], \n",
    "             targets=[\"Target_ingresso\"], \n",
    "             n_ticker_batch=400, \n",
    "             bilanciamento=1, \n",
    "             epochs=100,\n",
    "             batch_size=2052, \n",
    "             soglia=0.5, \n",
    "             class_weights={0: 3, 1: 1},\n",
    "             learning_rate=0.001, \n",
    "             train_test_split=0.2\n",
    "            ):\n",
    "        self.progetto = progetto\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.timesteps = timesteps # n. barre del periodo passato per la ricerca di pattern, inclusa ultima data disponibile\n",
    "        self.giorni_previsione = giorni_previsione  # giorni futuri di cui effettuare la previsione\n",
    "        self.features_scala_prezzo = [ft for ft in _features_scala_prezzo_tutte if ft in self.features]\n",
    "        self.features_da_scalare_singolarmente = [ft for ft in _features_da_scalare_singolarmente_tutte if ft in self.features]\n",
    "        self.features_oscillatori = [ft for ft in _features_oscillatori_tutte if ft in self.features]\n",
    "        self.features_no_scala = [ft for ft in _features_no_scala_tutte if ft in self.features]\n",
    "        self.features_candele = [ft for ft in _features_candele_tutte if ft in self.features]\n",
    "        self.targets = targets\n",
    "        self.n_ticker_batch = n_ticker_batch\n",
    "        self.bilanciamento = bilanciamento\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.soglia = soglia\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_test_split = train_test_split\n",
    "        self.class_weights = class_weights\n",
    "        self.n_features = len(self.features) \n",
    "        self.n_targets = len(self.targets) \n",
    "        self.model = self._crea_modello() \n",
    "        self.model_history = None\n",
    "\n",
    "    def carica(self, progetto='default'):\n",
    "        self.progetto = progetto\n",
    "        percorso_file = f'{self.progetto}/impostazioni.json'\n",
    "        try:\n",
    "            with open(percorso_file, \"r\") as file:\n",
    "                impostazioni = json.load(file) if os.path.getsize(percorso_file) > 0 else {}\n",
    "                self.timesteps = impostazioni.get(\"timesteps\", 120) # n. barre del periodo passato per la ricerca di pattern, inclusa ultima data disponibile\n",
    "                self.giorni_previsione = impostazioni.get(\"giorni_previsione\", 1)  # giorni futuri di cui effettuare la previsione\n",
    "                self.features = impostazioni.get(\"features\", [\"EMA_20\", \"EMA_50\", \"EMA_100\", \"Volume\", \"MACDh\", \"AROONOSC\", \"TRIX\", \"DM_OSC\", \"TSI\", \"KVO\"])\n",
    "                self.features_scala_prezzo = [ft for ft in _features_scala_prezzo_tutte if ft in self.features]\n",
    "                self.features_da_scalare_singolarmente = [ft for ft in _features_da_scalare_singolarmente_tutte if ft in self.features]\n",
    "                self.features_oscillatori = [ft for ft in _features_oscillatori_tutte if ft in self.features]\n",
    "                self.features_no_scala = [ft for ft in _features_no_scala_tutte if ft in self.features]\n",
    "                self.features_candele = [ft for ft in _features_candele_tutte if ft in self.features]                \n",
    "                self.targets = impostazioni.get(\"targets\", [\"Target_ingresso\"])\n",
    "                self.n_features = len(self.features)\n",
    "                self.n_targets = len(self.targets) \n",
    "                self.n_ticker_batch = impostazioni.get(\"n_ticker_batch\", 400)\n",
    "                self.bilanciamento = impostazioni.get(\"bilanciamento\", 1)\n",
    "                self.batch_size = impostazioni.get(\"batch_size\", 2052)\n",
    "                self.epochs = impostazioni.get(\"epochs\", 100)\n",
    "                self.soglia = impostazioni.get(\"soglia\", 0.5)\n",
    "                self.learning_rate = impostazioni.get(\"learnig_rate\", 0.001)\n",
    "                self.train_test_split = impostazioni.get(\"train_test_split\", 0.2)\n",
    "                self.class_weights = impostazioni.get(\"class_weights\", {0: 3, 1: 1})\n",
    "                self.n_features = len(self.features) \n",
    "                self.n_targets = len(self.targets) \n",
    "                self.model = load_model(f\"{self.progetto}/model.h5\")  \n",
    "                self.model_history = pd.read_hdf(f'{progetto}/model_history.h5', 'history')      \n",
    "        except Exception as e:\n",
    "            print(f\"Errore durante il caricamento del file: {e}\")\n",
    "\n",
    "    def _salva_impostazioni(self):\n",
    "        impostazioni = {\n",
    "            \"timesteps\": self.timesteps,\n",
    "            \"giorni_previsione\": self.giorni_previsione,\n",
    "            \"features\": self.features,\n",
    "            \"targets\": self.targets,\n",
    "            \"n_ticker_batch\": self.n_ticker_batch,\n",
    "            \"bilanciamento\": self.bilanciamento,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"epochs\": self.epochs, \n",
    "            \"soglia\": self.soglia,\n",
    "            \"class_weights\": self.class_weights\n",
    "        }\n",
    "        with open(f'{self.progetto}/impostazioni.json', \"w\") as file:\n",
    "            json.dump(impostazioni, file, indent=4)\n",
    "            \n",
    "        modello = json.loads(self.model.to_json())\n",
    "        with open(f'{self.progetto}/struttura.json', \"w\") as file:\n",
    "            json.dump(modello, file, indent=4)\n",
    "\n",
    "    def salva(self):\n",
    "        os.makedirs(self.progetto, exist_ok=True)\n",
    "        self._salva_impostazioni()\n",
    "        self.model.save(f'{self.progetto}/model.h5')\n",
    "        self.model_history.to_hdf(f'{self.progetto}/model_history.h5', key='history', mode='w')\n",
    "\n",
    "    def genera_XY(self, lista_files, nome_file=''):\n",
    "        perc_file = f'XY/XY_{nome_file}.h5'\n",
    "        if not os.path.exists(perc_file):\n",
    "            manager = Manager()\n",
    "            listaX = manager.list()\n",
    "            listaY = manager.list()\n",
    "            totale_processati = Value('i', 1)  \n",
    "            tot_files = len(lista_files)\n",
    "            with Pool(cpu_count()) as p:\n",
    "                for file_name in lista_files:\n",
    "                    param = (file_name, self.timesteps, self.giorni_previsione, self.features, self.targets, self.bilanciamento)\n",
    "                    p.apply_async(_process_ticker, args=param, callback=lambda result: _callback_XY(result, listaX, listaY, totale_processati, tot_files, hdf5_file=perc_file))\n",
    "\n",
    "                p.close()\n",
    "                p.join()\n",
    "\n",
    "            if len(listaX) > 0:\n",
    "                print(\"\\033[43m\" + 'Salvataggio finale su file X' + \"\\033[0m\")\n",
    "                concatena(listaX, perc_file, dataset_name='X')\n",
    "                print(\"\\033[43m\" + 'Salvataggio finale su file Y' + \"\\033[0m\")\n",
    "                concatena(listaY, perc_file, dataset_name='Y')\n",
    "                del listaX[:]\n",
    "                del listaY[:]\n",
    "                \n",
    "        # print('Caricamento file X e Y')\n",
    "        # with h5py.File(f'XY/XY_{salva_carica_file}.h5', 'r') as hdf:\n",
    "        #     Xtot = hdf['X'][:]\n",
    "        #     Ytot = hdf['Y'][:]\n",
    "        # return Xtot, Ytot \n",
    "\n",
    "    def addestra(self):\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001, verbose=1)\n",
    "        #model_checkpoint = ModelCheckpoint(f'{self.progetto}/model.h5', monitor='val_precision', save_best_only=True, verbose=1)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "        callbacks = [early_stopping, reduce_lr]\n",
    "        list_of_files = os.listdir('tickers')\n",
    "        random.shuffle(list_of_files)\n",
    "        train_files = list_of_files[:self.n_ticker_batch]\n",
    "        val_files = list_of_files[self.n_ticker_batch:int(self.n_ticker_batch*(1+self.train_test_split))]\n",
    "        \n",
    "        print(\"\\033[41m\" + 'Preparazione dati di train' + \"\\033[0m\")\n",
    "        self.genera_XY(train_files, 'train')\n",
    "        print(\"\\033[41m\" + 'Preparazione dati di validazione' + \"\\033[0m\")\n",
    "        self.genera_XY(val_files, 'val')\n",
    "        train_generator = DataGenerator('XY/XY_train.h5', self.batch_size)\n",
    "        val_generator = DataGenerator('XY/XY_val.h5', self.batch_size)    \n",
    "           \n",
    "        history = self.model.fit(train_generator, epochs=self.epochs, validation_data=val_generator, callbacks=callbacks, class_weight=self.class_weights, steps_per_epoch=len(train_generator), validation_steps=len(val_generator))\n",
    "        self.model_history = pd.DataFrame(history.history)\n",
    "        self.salva()\n",
    "        self.grafico_loss(salva_su_file=True)\n",
    "        self.grafico_precision(salva_su_file=True)\n",
    "        df = self.test()\n",
    "        return df\n",
    "        \n",
    "    def previsione_singola(self, nome_simbolo):\n",
    "        print(f'Caricamento dati ticker {nome_simbolo}')\n",
    "        ticker = pd.read_hdf(f'tickers/{nome_simbolo}.h5', 'ticker')\n",
    "        print('Generazione X e Y')\n",
    "        idx, X, Y, _ = to_XY(dati_ticker=ticker, timesteps=self.timesteps, giorni_previsione=self.giorni_previsione, features=self.features, targets=self.targets, bilanciamento=0)\n",
    "        print(f'Previsione')\n",
    "        pred = self.modello_ingresso.model.predict(X)\n",
    "        scr = pd.DataFrame({'Previsione': pred.flatten().round(2), 'Reale': Y.flatten()}, index=idx)\n",
    "        scr = scr[scr.index >= self.DATA_INIZIO]\n",
    "        print(f\"Salvataggio file {nome_simbolo}.h5\")\n",
    "    \n",
    "    def grafico_loss(self, salva_su_file=False):\n",
    "        num_epochs = self.model_history.shape[0]\n",
    "        plt.plot(np.arange(0, num_epochs), self.model_history['loss'], label=\"Training\")\n",
    "        plt.plot(np.arange(0, num_epochs), self.model_history['val_loss'], label=\"Validation\")\n",
    "        plt.legend()\n",
    "        plt.title('Loss')\n",
    "        plt.tight_layout()\n",
    "        if salva_su_file:\n",
    "            plt.savefig(f'{self.progetto}/grafico_loss.png')\n",
    "        plt.show()        \n",
    "\n",
    "    def grafico_precision(self, salva_su_file=False):\n",
    "        num_epochs = self.model_history.shape[0]\n",
    "        plt.plot(np.arange(0, num_epochs), self.model_history['precision'], label=\"Training\")\n",
    "        plt.plot(np.arange(0, num_epochs), self.model_history['val_precision'], label=\"Validation\")\n",
    "        plt.legend()\n",
    "        plt.title('Precision')\n",
    "        plt.tight_layout()\n",
    "        if salva_su_file:\n",
    "            plt.savefig(f'{self.progetto}/grafico_precision.png')\n",
    "        plt.show()        \n",
    "\n",
    "    def test(self, nome_simbolo='BTG'):\n",
    "        ticker = pd.read_hdf(f'tickers/{nome_simbolo}.h5', 'ticker')\n",
    "        ticker = dropna_iniziali(ticker)\n",
    "        ticker = dropna_finali(ticker)\n",
    "        idx, X, Y, _ = to_XY(ticker, timesteps=self.timesteps, giorni_previsione=self.giorni_previsione, features=self.features, targets=self.targets, bilanciamento=0)\n",
    "        print(f'X.shape: {X.shape}')\n",
    "        print(f'Y.shape: {Y.shape}')\n",
    "        print(f'ticker.shape: {ticker.shape}')\n",
    "        pred = self.model.predict(X, batch_size=self.batch_size, verbose=1, use_multiprocessing=True)\n",
    "        pred_binary = (pred > self.soglia).astype(int)\n",
    "        \n",
    "        result = self.model.evaluate(X, Y, batch_size=self.batch_size, verbose=1, use_multiprocessing=True, return_dict=True)\n",
    "        print(result)\n",
    "        \n",
    "        # Visualizza come heatmap\n",
    "        matrice = confusion_matrix(Y, pred_binary)\n",
    "        sns.heatmap(matrice, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "        plt.xlabel('Previsti')\n",
    "        plt.ylabel('Reali')\n",
    "        plt.savefig(f'{self.progetto}/confusion_matrix.png')\n",
    "        plt.show()\n",
    "        print(f'idx: {idx.shape}')\n",
    "        print(f'pred: {pred.shape}')\n",
    "        print(f'real: {Y.shape}')\n",
    "        df = pd.DataFrame({'Prev': pred.flatten().round(2), 'Real': Y.flatten()}, index=idx)\n",
    "        return df       \n",
    "        \n",
    "def _process_ticker(file_name, timesteps, giorni_previsione, features, targets, bilanciamento):\n",
    "    try:\n",
    "        ticker = pd.read_hdf(f'tickers/{file_name}', 'ticker')\n",
    "        ticker = dropna_iniziali(ticker)\n",
    "        ticker = dropna_finali(ticker)\n",
    "        _, X, Y, _ = to_XY(ticker, timesteps, giorni_previsione, features, targets, bilanciamento)\n",
    "        return file_name, X, Y, \"\"\n",
    "    except Exception as e:\n",
    "        return file_name, np.array([]), np.array([]), str(e)\n",
    "\n",
    "def _callback_XY(result, listaX, listaY, totale_processati, tot_files, hdf5_file):\n",
    "    nome_simbolo, X, Y, err = result\n",
    "    if err == \"\":\n",
    "        if X.shape[0] > 0 and Y.shape[0] > 0:  # Verifica se X e Y sono non vuoti\n",
    "            print(f'X.shape:{X.shape}')\n",
    "            print(f'Y.shape:{Y.shape}')\n",
    "            listaX.append(X)\n",
    "            listaY.append(Y)\n",
    "            print(\"\\033[42m\" + f\"{totale_processati.value}/{tot_files}) Completato ticker {nome_simbolo}\" + \"\\033[0m\")\n",
    "        else:\n",
    "            print(\"\\033[43m\" + f\"Ticker {nome_simbolo} ignorato a causa di dati mancanti o errati.\" + \"\\033[0m\")\n",
    "    else:\n",
    "        print(err)\n",
    "\n",
    "    with totale_processati.get_lock(): \n",
    "        totale_processati.value += 1\n",
    "        if len(listaX) >= 100:\n",
    "            print(\"\\033[43m\" + 'Salvataggio su file X' + \"\\033[0m\")\n",
    "            concatena(listaX, hdf5_file, dataset_name='X')\n",
    "            print(\"\\033[43m\" + 'Salvataggio su file Y' + \"\\033[0m\")\n",
    "            concatena(listaY, hdf5_file, dataset_name='Y')\n",
    "            del listaX[:]\n",
    "            del listaY[:]\n",
    "     \n",
    "def modifica_target():\n",
    "    totale_processati = Value('i', 1)\n",
    "    list_of_files = os.listdir('tickers')\n",
    "    tot_tickers = len(list_of_files)\n",
    "    with Pool(cpu_count()) as p:\n",
    "        callback_with_args = partial(_callback_modifica_target, totale_processati=totale_processati, tot_tickers=tot_tickers)\n",
    "        for i in range(0, tot_tickers):\n",
    "            nome_file = list_of_files[i]\n",
    "            param = (nome_file,)\n",
    "            p.apply_async(_modifica_target, args=param, callback=callback_with_args)\n",
    "        p.close()\n",
    "        p.join()          \n",
    "   \n",
    "def _modifica_target(nome_file):\n",
    "    try:\n",
    "        ticker = pd.read_hdf(f'tickers/{nome_file}', 'ticker')\n",
    "        if 'Target_ingresso' in ticker.columns:\n",
    "            ticker.drop(['Target_ingresso'], axis=1, inplace=True)\n",
    "        if 'Target_uscita' in ticker.columns:\n",
    "            ticker.drop(['Target_uscita'], axis=1, inplace=True)\n",
    "        ticker = imposta_target(ticker)\n",
    "        return nome_file, ticker, \"\"\n",
    "    except Exception as e:\n",
    "        return nome_file, ticker, str(e)\n",
    "\n",
    "def _callback_modifica_target(result, totale_processati, tot_tickers):\n",
    "    nome_file, ticker, err = result\n",
    "    if err == \"\":\n",
    "        print(f\"{totale_processati.value}/{tot_tickers}) Modificato target {nome_file}\")\n",
    "        ticker.to_hdf(f'tickers/{nome_file}', key='ticker', mode='w')\n",
    "    else:\n",
    "        print(err)\n",
    "\n",
    "    with totale_processati.get_lock(): \n",
    "        totale_processati.value += 1\n",
    "        \n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, file_path, batch_size):\n",
    "        self.file_path = file_path\n",
    "        self.batch_size = batch_size\n",
    "        # Apriamo il file in modalità lettura e salviamo i riferimenti ai dataset\n",
    "        self.file = h5py.File(file_path, 'r')\n",
    "        self.X = self.file['X']\n",
    "        self.Y = self.file['Y']\n",
    "        self.num_samples = self.X.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.num_samples / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Calcola gli indici per il batch corrente\n",
    "        start = idx * self.batch_size\n",
    "        end = (idx + 1) * self.batch_size\n",
    "\n",
    "        # Legge solo i dati necessari per il batch corrente\n",
    "        batch_x = self.X[start:end]\n",
    "        batch_y = self.Y[start:end]\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Eventuali azioni alla fine di ogni epoca, se necessario\n",
    "        pass\n",
    "\n",
    "    def __del__(self):\n",
    "        # Assicurati di chiudere il file quando il generatore viene distrutto\n",
    "        self.file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e1218b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TP = 0.15\n",
    "#SL = 0.07\n",
    "PROBABILITA_PER_ACQUISTO = 0.5\n",
    "BILANCIO_INIZIALE = 1000\n",
    "GIORNI_MAX_POSIZIONE = 40\n",
    "N_SIMBOLI = 10\n",
    "DATA_INIZIO = pd.Timestamp(2013, 1, 1)\n",
    "\n",
    "inizializza_gpu()\n",
    "#modifica_target()\n",
    "\n",
    "borsa = Borsa(N_SIMBOLI, BILANCIO_INIZIALE, PROBABILITA_PER_ACQUISTO, GIORNI_MAX_POSIZIONE, data_inizio=DATA_INIZIO)\n",
    "borsa.aggiorna_dati()\n",
    "data, scr, data_out, scr_out = borsa.ultimo_screener()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Previsione</th>\n",
       "      <th>Reale</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EVRG</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPI</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WIT</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LBRDK</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Previsione  Reale\n",
       "Ticker                   \n",
       "EVRG          0.99    0.0\n",
       "GL            0.99    0.0\n",
       "FPI           0.99    0.0\n",
       "WIT           0.99    0.0\n",
       "LBRDK         0.98    0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data)\n",
    "scr.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Previsione</th>\n",
       "      <th>Reale</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARWR</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WB</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AROW</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOHU</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Previsione  Reale\n",
       "Ticker                   \n",
       "ARWR          0.87    0.0\n",
       "WB            0.86    0.0\n",
       "AROW          0.85    0.0\n",
       "GM            0.85    0.0\n",
       "SOHU          0.85    0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_out)\n",
    "scr_out.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mData: 2013-01-02, Pos. aperte: 0\u001b[0m COMPRA DHT n.23 azioni a 4.18 € = 96.14 €,  Bilancio: 903.86 € + valore pos. aperte: 96.14 € = 1000.0 €, Bilancio per simbolo: 100.43\n",
      "COMPRA CSIQ n.28 azioni a 3.5 € = 98.0 €,  Bilancio: 805.86 € + valore pos. aperte: 194.14 € = 1000.0 €, Bilancio per simbolo: 100.73\n",
      "COMPRA TIT n.6 azioni a 16.61 € = 99.66 €,  Bilancio: 706.2 € + valore pos. aperte: 293.8 € = 1000.0 €, Bilancio per simbolo: 100.89\n",
      "COMPRA PHN n.4 azioni a 24.49 € = 97.96 €,  Bilancio: 608.24 € + valore pos. aperte: 391.76 € = 1000.0 €, Bilancio per simbolo: 101.37\n",
      "COMPRA BRE n.10 azioni a 9.3 € = 93.01 €,  Bilancio: 515.23 € + valore pos. aperte: 484.77 € = 1000.0 €, Bilancio per simbolo: 103.05\n",
      "COMPRA TLK n.5 azioni a 18.5 € = 92.52 €,  Bilancio: 422.71 € + valore pos. aperte: 577.29 € = 1000.0 €, Bilancio per simbolo: 105.68\n",
      "COMPRA WFG n.2 azioni a 36.88 € = 73.77 €,  Bilancio: 348.94 € + valore pos. aperte: 651.06 € = 1000.0 €, Bilancio per simbolo: 116.31\n",
      "COMPRA HIMX n.48 azioni a 2.42 € = 116.16 €,  Bilancio: 232.78 € + valore pos. aperte: 767.22 € = 1000.0 €, Bilancio per simbolo: 116.39\n",
      "COMPRA CZNC n.5 azioni a 19.49 € = 97.45 €,  Bilancio: 135.33 € + valore pos. aperte: 864.67 € = 1000.0 €, Bilancio per simbolo: 135.33\n",
      "COMPRA PFC n.14 azioni a 9.21 € = 128.94 €,  Bilancio: 6.39 € + valore pos. aperte: 993.61 € = 1000.0 €, Bilancio per simbolo: 0.0\n",
      "\u001b[31mData: 2013-03-01, Pos. aperte: 10\u001b[0m VENDI DHT n.23 azioni a 4.3 € = 98.9 €, Esito: VINCITA, Perc: 2, Bilancio: 105.29 € + valore pos. aperte: 1096.99 € = 1098.9 €, Bilancio per simbolo: 105.29\n",
      "VENDI CSIQ n.28 azioni a 3.82 € = 106.96 €, Esito: VINCITA, Perc: 9, Bilancio: 212.25 € + valore pos. aperte: 1096.99 € = 1205.86 €, Bilancio per simbolo: 212.25\n",
      "VENDI TIT n.6 azioni a 16.61 € = 99.66 €, Esito: PERDITA, Perc: 0, Bilancio: 311.91 € + valore pos. aperte: 1096.99 € = 1305.52 €, Bilancio per simbolo: 311.91\n",
      "VENDI PHN n.4 azioni a 25.15 € = 100.6 €, Esito: VINCITA, Perc: 2, Bilancio: 412.51 € + valore pos. aperte: 1096.99 € = 1406.12 €, Bilancio per simbolo: 412.51\n",
      "VENDI BRE n.10 azioni a 9.3 € = 93.01 €, Esito: PERDITA, Perc: 0, Bilancio: 505.52 € + valore pos. aperte: 1096.99 € = 1499.13 €, Bilancio per simbolo: 505.52\n",
      "VENDI TLK n.5 azioni a 22.03 € = 110.15 €, Esito: VINCITA, Perc: 19, Bilancio: 615.67 € + valore pos. aperte: 1096.99 € = 1609.28 €, Bilancio per simbolo: 615.67\n",
      "VENDI WFG n.2 azioni a 41.18 € = 82.36 €, Esito: VINCITA, Perc: 11, Bilancio: 698.03 € + valore pos. aperte: 1096.99 € = 1691.64 €, Bilancio per simbolo: 698.03\n",
      "VENDI HIMX n.48 azioni a 3.18 € = 152.64 €, Esito: VINCITA, Perc: 31, Bilancio: 850.67 € + valore pos. aperte: 1096.99 € = 1844.28 €, Bilancio per simbolo: 850.67\n",
      "VENDI CZNC n.5 azioni a 19.49 € = 97.45 €, Esito: PERDITA, Perc: 0, Bilancio: 948.12 € + valore pos. aperte: 1096.99 € = 1941.73 €, Bilancio per simbolo: 948.12\n",
      "VENDI PFC n.14 azioni a 11.09 € = 155.26 €, Esito: VINCITA, Perc: 20, Bilancio: 1103.38 € + valore pos. aperte: 1096.99 € = 2096.99 €, Bilancio per simbolo: 1103.38\n",
      "COMPRA TIT n.66 azioni a 16.61 € = 1096.26 €,  Bilancio: 7.12 € + valore pos. aperte: 2089.87 € = 2096.99 €, Bilancio per simbolo: 0.79\n",
      "\u001b[31mData: 2013-04-29, Pos. aperte: 1\u001b[0m VENDI TIT n.66 azioni a 16.61 € = 1096.26 €, Esito: PERDITA, Perc: 0, Bilancio: 1103.38 € + valore pos. aperte: 1096.26 € = 3193.25 €, Bilancio per simbolo: 110.34\n",
      "COMPRA TIT n.6 azioni a 16.61 € = 99.66 €,  Bilancio: 1003.72 € + valore pos. aperte: 2189.53 € = 3193.25 €, Bilancio per simbolo: 111.52\n",
      "COMPRA TNP n.6 azioni a 18.3 € = 109.8 €,  Bilancio: 893.92 € + valore pos. aperte: 2299.33 € = 3193.25 €, Bilancio per simbolo: 111.74\n",
      "COMPRA PHN n.4 azioni a 24.83 € = 99.32 €,  Bilancio: 794.6 € + valore pos. aperte: 2398.65 € = 3193.25 €, Bilancio per simbolo: 113.51\n",
      "COMPRA BRE n.12 azioni a 9.3 € = 111.61 €,  Bilancio: 682.99 € + valore pos. aperte: 2510.26 € = 3193.25 €, Bilancio per simbolo: 113.83\n",
      "COMPRA EVO n.67 azioni a 1.68 € = 112.56 €,  Bilancio: 570.43 € + valore pos. aperte: 2622.82 € = 3193.25 €, Bilancio per simbolo: 114.09\n",
      "COMPRA DB n.2 azioni a 40.95 € = 81.91 €,  Bilancio: 488.52 € + valore pos. aperte: 2704.73 € = 3193.25 €, Bilancio per simbolo: 122.13\n",
      "COMPRA OTEX n.7 azioni a 15.93 € = 111.51 €,  Bilancio: 377.01 € + valore pos. aperte: 2816.24 € = 3193.25 €, Bilancio per simbolo: 125.67\n",
      "COMPRA AMKR n.29 azioni a 4.29 € = 124.41 €,  Bilancio: 252.6 € + valore pos. aperte: 2940.65 € = 3193.25 €, Bilancio per simbolo: 126.3\n",
      "COMPRA NSIT n.7 azioni a 17.41 € = 121.87 €,  Bilancio: 130.73 € + valore pos. aperte: 3062.52 € = 3193.25 €, Bilancio per simbolo: 130.73\n",
      "COMPRA CTSH n.4 azioni a 31.14 € = 124.54 €,  Bilancio: 6.19 € + valore pos. aperte: 3187.06 € = 3193.25 €, Bilancio per simbolo: 0.0\n",
      "\u001b[31mData: 2013-06-25, Pos. aperte: 10\u001b[0m VENDI TIT n.6 azioni a 16.61 € = 99.66 €, Esito: PERDITA, Perc: 0, Bilancio: 105.85 € + valore pos. aperte: 1109.91 € = 3292.91 €, Bilancio per simbolo: 105.85\n",
      "VENDI TNP n.6 azioni a 20.95 € = 125.7 €, Esito: VINCITA, Perc: 14, Bilancio: 231.55 € + valore pos. aperte: 1109.91 € = 3418.61 €, Bilancio per simbolo: 231.55\n",
      "VENDI PHN n.4 azioni a 24.46 € = 97.84 €, Esito: PERDITA, Perc: -1, Bilancio: 329.39 € + valore pos. aperte: 1109.91 € = 3516.45 €, Bilancio per simbolo: 329.39\n",
      "VENDI BRE n.12 azioni a 9.3 € = 111.61 €, Esito: PERDITA, Perc: 0, Bilancio: 441.0 € + valore pos. aperte: 1109.91 € = 3628.06 €, Bilancio per simbolo: 441.0\n",
      "VENDI EVO n.67 azioni a 1.67 € = 112.06 €, Esito: PERDITA, Perc: 0, Bilancio: 553.06 € + valore pos. aperte: 1109.91 € = 3740.12 €, Bilancio per simbolo: 553.06\n",
      "VENDI DB n.2 azioni a 41.35 € = 82.69 €, Esito: VINCITA, Perc: 0, Bilancio: 635.75 € + valore pos. aperte: 1109.91 € = 3822.81 €, Bilancio per simbolo: 635.75\n",
      "VENDI OTEX n.7 azioni a 16.73 € = 117.13 €, Esito: VINCITA, Perc: 5, Bilancio: 752.88 € + valore pos. aperte: 1109.91 € = 3939.94 €, Bilancio per simbolo: 752.88\n",
      "VENDI AMKR n.29 azioni a 4.07 € = 118.03 €, Esito: PERDITA, Perc: -5, Bilancio: 870.91 € + valore pos. aperte: 1109.91 € = 4057.97 €, Bilancio per simbolo: 870.91\n",
      "VENDI NSIT n.7 azioni a 17.28 € = 120.96 €, Esito: PERDITA, Perc: 0, Bilancio: 991.87 € + valore pos. aperte: 1109.91 € = 4178.93 €, Bilancio per simbolo: 991.87\n",
      "VENDI CTSH n.4 azioni a 31.06 € = 124.24 €, Esito: PERDITA, Perc: 0, Bilancio: 1116.11 € + valore pos. aperte: 1109.91 € = 4303.17 €, Bilancio per simbolo: 1116.11\n",
      "COMPRA TIT n.67 azioni a 16.61 € = 1112.87 €,  Bilancio: 3.24 € + valore pos. aperte: 4299.93 € = 4303.17 €, Bilancio per simbolo: 0.36\n",
      "\u001b[31mData: 2013-06-28, Pos. aperte: 1\u001b[0m COMPRA DANR n.514 azioni a 0.0 € = 0.36 €,  Bilancio: 2.88 € + valore pos. aperte: 4300.29 € = 4303.17 €, Bilancio per simbolo: 0.36\n",
      "\u001b[31mData: 2013-07-01, Pos. aperte: 2\u001b[0m Errore in apertura posizione: File tickers/WWE.h5 does not exist\n",
      "\u001b[31mData: 2013-07-02, Pos. aperte: 2\u001b[0m Errore in apertura posizione: File tickers/WWE.h5 does not exist\n",
      "\u001b[31mData: 2013-07-03, Pos. aperte: 2\u001b[0m Errore in apertura posizione: File tickers/WWE.h5 does not exist\n",
      "\u001b[31mData: 2013-07-05, Pos. aperte: 2\u001b[0m Errore in apertura posizione: File tickers/WWE.h5 does not exist\n",
      "\u001b[31mData: 2013-07-08, Pos. aperte: 2\u001b[0m Errore in apertura posizione: File tickers/WWE.h5 does not exist\n",
      "\u001b[31mData: 2013-07-09, Pos. aperte: 2\u001b[0m Errore in apertura posizione: File tickers/WWE.h5 does not exist\n",
      "\u001b[31mData: 2013-07-10, Pos. aperte: 2\u001b[0m Errore in apertura posizione: File tickers/WWE.h5 does not exist\n",
      "\u001b[31mData: 2013-07-11, Pos. aperte: 2\u001b[0m Errore in apertura posizione: File tickers/WWE.h5 does not exist\n",
      "\u001b[31mData: 2013-07-12, Pos. aperte: 2\u001b[0m Errore in apertura posizione: File tickers/WWE.h5 does not exist\n",
      "\u001b[31mData: 2013-07-15, Pos. aperte: 2\u001b[0m Errore in apertura posizione: File tickers/WWE.h5 does not exist\n",
      "\u001b[31mData: 2013-07-16, Pos. aperte: 2\u001b[0m Errore in apertura posizione: File tickers/WWE.h5 does not exist\n",
      "\u001b[31mData: 2013-07-17, Pos. aperte: 2\u001b[0m Errore in apertura posizione: File tickers/WWE.h5 does not exist\n",
      "\u001b[31mData: 2013-07-18, Pos. aperte: 2\u001b[0m Errore in apertura posizione: File tickers/WWE.h5 does not exist\n",
      "\u001b[31mData: 2013-07-19, Pos. aperte: 2\u001b[0m Errore in apertura posizione: File tickers/WWE.h5 does not exist\n",
      "\u001b[31mData: 2013-07-29, Pos. aperte: 2\u001b[0m "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m borsa\u001b[39m.\u001b[39;49mavvia_trading()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m borsa\u001b[39m.\u001b[39mesito_trading\n",
      "\u001b[1;32m/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb#W4sZmlsZQ%3D%3D?line=988'>989</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m (\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_posizioni) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN_SIMBOLI) \u001b[39mand\u001b[39;00m (i \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(scr)):\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb#W4sZmlsZQ%3D%3D?line=989'>990</a>\u001b[0m         simbolo \u001b[39m=\u001b[39m scr\u001b[39m.\u001b[39mindex[i][\u001b[39m1\u001b[39m]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb#W4sZmlsZQ%3D%3D?line=990'>991</a>\u001b[0m         esito \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apri_posizione(simbolo)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb#W4sZmlsZQ%3D%3D?line=991'>992</a>\u001b[0m         i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb#W4sZmlsZQ%3D%3D?line=992'>993</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_corrente \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m timedelta(days\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m   <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb#W4sZmlsZQ%3D%3D?line=1015'>1016</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apri_posizione\u001b[39m(\u001b[39mself\u001b[39m, simbolo):\n\u001b[1;32m   <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb#W4sZmlsZQ%3D%3D?line=1016'>1017</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb#W4sZmlsZQ%3D%3D?line=1017'>1018</a>\u001b[0m         ticker \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_hdf(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtickers/\u001b[39;49m\u001b[39m{\u001b[39;49;00msimbolo\u001b[39m}\u001b[39;49;00m\u001b[39m.h5\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mticker\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m   <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb#W4sZmlsZQ%3D%3D?line=1018'>1019</a>\u001b[0m         ticker \u001b[39m=\u001b[39m ticker[ticker\u001b[39m.\u001b[39mindex \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_corrente]\n\u001b[1;32m   <a href='vscode-notebook-cell:/home/enrico/Documenti/Borsa/Test_trading_multiplo.ipynb#W4sZmlsZQ%3D%3D?line=1019'>1020</a>\u001b[0m         prezzo \u001b[39m=\u001b[39m ticker[\u001b[39m\"\u001b[39m\u001b[39mOpen\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/pytables.py:416\u001b[0m, in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exists:\n\u001b[1;32m    414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00mpath_or_buf\u001b[39m}\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 416\u001b[0m store \u001b[39m=\u001b[39m HDFStore(path_or_buf, mode\u001b[39m=\u001b[39;49mmode, errors\u001b[39m=\u001b[39;49merrors, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    417\u001b[0m \u001b[39m# can't auto open/close if we are using an iterator\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39m# so delegate to the iterator\u001b[39;00m\n\u001b[1;32m    419\u001b[0m auto_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/pytables.py:578\u001b[0m, in \u001b[0;36mHDFStore.__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fletcher32 \u001b[39m=\u001b[39m fletcher32\n\u001b[1;32m    577\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filters \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopen(mode\u001b[39m=\u001b[39;49mmode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/pytables.py:737\u001b[0m, in \u001b[0;36mHDFStore.open\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    732\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot open HDF5 file, which is already opened, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    733\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39meven in read-only mode.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    734\u001b[0m     )\n\u001b[1;32m    735\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m--> 737\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m tables\u001b[39m.\u001b[39;49mopen_file(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_path, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tables/file.py:294\u001b[0m, in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    290\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is already opened.  Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mclose it before reopening in write mode.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m filename)\n\u001b[1;32m    293\u001b[0m \u001b[39m# Finally, create the File instance, and return it\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m \u001b[39mreturn\u001b[39;00m File(filename, mode, title, root_uep, filters, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tables/file.py:744\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams \u001b[39m=\u001b[39m params\n\u001b[1;32m    743\u001b[0m \u001b[39m# Now, it is time to initialize the File extension\u001b[39;00m\n\u001b[0;32m--> 744\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_g_new(filename, mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    746\u001b[0m \u001b[39m# Check filters and set PyTables format version for new files.\u001b[39;00m\n\u001b[1;32m    747\u001b[0m new \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_v_new\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "borsa.avvia_trading()\n",
    "borsa.esito_trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=8\n",
    "#borsa._posizioni[1].valore(borsa._data_corrente)\n",
    "print(borsa._posizioni[i].simbolo)\n",
    "print(len(borsa._posizioni[i].ticker))\n",
    "borsa._posizioni[i].ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valori_N_SIMBOLI = list(range(1, 11))  # Valori da 1 a 10\n",
    "valori_GIORNI_POS = list(range(5, 61, 5))  # Valori da 5 a 60 con step di 5\n",
    "valori_SL = list(np.arange(0.01, 0.1, 0.01))\n",
    "valori_TP = list(np.arange(0.1, 1, 0.05))\n",
    "\n",
    "space  = [\n",
    "    Categorical(valori_N_SIMBOLI, name='N_SIMBOLI'),  \n",
    "    Categorical(valori_GIORNI_POS, name='GIORNI_POS'),  \n",
    "    Categorical(valori_SL, name='SL'),  \n",
    "    Categorical(valori_TP, name='TP')\n",
    "]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    return borsa.funzione_obiettivo(**params)\n",
    "\n",
    "risultato = gp_minimize(objective, space, n_calls=50, random_state=0)\n",
    "\n",
    "print(f\"Migliori parametri: {risultato.x}\")\n",
    "\n",
    "x_iters = risultato.x_iters  # Lista di parametri testati\n",
    "fun_values = risultato.func_vals  # Lista di valori della funzione obiettivo\n",
    "\n",
    "df_results = pd.DataFrame(x_iters, columns=['N_SIMBOLI', 'GIORNI_POS', 'SL', 'TP'])\n",
    "df_results['Valore_Funzione'] = fun_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df_results.to_excel('parametri_trading.xlsx')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mod = Modello()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mod.carica(progetto='mod_1_in')\n",
    "mod.class_weights = {0: 1, 1: 1}\n",
    "df = mod.addestra()\n",
    "mod.salva()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "mod.crea(\n",
    "    'mod_1_in', \n",
    "    class_weights={0: 1, 1: 1}, \n",
    "    bilanciamento=1, \n",
    "    timesteps=240, \n",
    "    batch_size=8000, \n",
    "    learning_rate=0.01, \n",
    "    n_ticker_batch=300, \n",
    "    train_test_split=0.2,\n",
    "    features=[\"EMA_20\", \"EMA_50\", \"EMA_100\", \"Volume\"]#, \"MACDh\", \"AROONOSC\", \"TRIX\", \"DM_OSC\", \"TSI\", \"KVO\"]\n",
    ")\n",
    "df = mod.addestra()\n",
    "df\n",
    "mod.salva()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "mod.crea(\n",
    "    'mod_1_out', \n",
    "    class_weights={0: 1, 1: 1}, \n",
    "    bilanciamento=1, \n",
    "    timesteps=240, \n",
    "    batch_size=4000, \n",
    "    learning_rate=0.01, \n",
    "    n_ticker_batch=300, \n",
    "    train_test_split=0.2,\n",
    "    features=[\"EMA_20\", \"EMA_50\", \"EMA_100\", \"Volume\"],#, \"MACDh\", \"AROONOSC\", \"TRIX\", \"DM_OSC\", \"TSI\", \"KVO\"]\n",
    "    targets=['Target_uscita']\n",
    ")\n",
    "df = mod.addestra()\n",
    "df\n",
    "mod.salva()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
