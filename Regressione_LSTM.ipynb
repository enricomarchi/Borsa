{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99bae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "simbolo_test = \"BTG\"\n",
    "simbolo_validazione = \"DHT\"\n",
    "n_simboli_addestramento = 2000\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "optimizer = \"adam\"\n",
    "#learning_rate = 0.001\n",
    "n_timesteps = 60 # n. barre del periodo passato per la ricerca di pattern, inclusa ultima data disponibile\n",
    "giorni_previsione = 10 # n. barre nel futuro di cui si desidera prevedere il prezzo\n",
    "\n",
    "elenco_features = [\n",
    "    \"Close\",\n",
    "    \"EMA_5\", \n",
    "    \"EMA_20\", \n",
    "    \"EMA_50\",\n",
    "    \"Open\",  \n",
    "    \"High\",\n",
    "    \"Low\",\n",
    "    \"Volume\",\n",
    "    \"MACDh\",\n",
    "    \"PSAR\",\n",
    "    \"PSARaf\",\n",
    "    \"SUPERT\", \n",
    "    \"TRIX\",\n",
    "    \"ATR\",\n",
    "    \"DM_OSC\",\n",
    "    \"ADX\"\n",
    "]\n",
    "elenco_targets = [\n",
    "    \"EMA_5\",\n",
    "    \"EMA_20\", \n",
    "    \"EMA_50\"    \n",
    "]\n",
    "\n",
    "col_features = {col: idx for idx, col in enumerate(elenco_features)}\n",
    "col_targets = {col: idx for idx, col in enumerate(elenco_targets)}\n",
    "n_features = len(col_features)\n",
    "n_targets = len(col_targets)\n",
    "\n",
    "def crea_modello(n_timesteps, giorni_previsione, n_targets, n_features):\n",
    "        model = Sequential()\n",
    "\n",
    "        # Layer LSTM iniziale\n",
    "        model.add(LSTM(70, input_shape=(n_timesteps, n_features)))\n",
    "        model.add(RepeatVector(giorni_previsione))\n",
    "\n",
    "        # lstm-2\n",
    "        model.add(LSTM(90, return_sequences=True,\n",
    "                       kernel_regularizer=l2(4.153520011432108e-05)))\n",
    "        model.add(Dropout(0.3))\n",
    "        # lstm-3\n",
    "        model.add(LSTM(130, return_sequences=True,\n",
    "                       kernel_regularizer=l2(4.153520011432108e-05)))\n",
    "        model.add(Dropout(0.3))\n",
    "        # lstm-4\n",
    "        model.add(LSTM(70, return_sequences=True,\n",
    "                       kernel_regularizer=l2(4.153520011432108e-05)))\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "        # Aggiunta di layer Dense\n",
    "        model.add(TimeDistributed(Dense(70, activation='relu')))\n",
    "        model.add(Dropout(0))\n",
    "\n",
    "        model.add(TimeDistributed(Dense(n_targets, activation='linear')))\n",
    "\n",
    "        model.compile(optimizer=\"adam\",\n",
    "                      loss='mean_absolute_percentage_error')\n",
    "\n",
    "        return model\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "#from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import clone\n",
    "scaler = PowerTransformer()\n",
    "#scaler = RobustScaler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25570dc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importa librerie.............=\n",
      "Download lista ticker\n",
      "Caricamento modello esistente\n"
     ]
    }
   ],
   "source": [
    "print(\"Importa librerie\", end=\"\", flush=True)\n",
    "\n",
    "#from keras.losses import Huber\n",
    "#print(\".\", end=\"\", flush=True)\n",
    "import pandas as pd\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import yfinance as yf\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import numpy as np\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import tensorflow as tf\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import funzioni as fx\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.layers import Dropout\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from keras.regularizers import l2\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras import Sequential\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "print(\".\", end=\"\", flush=True)\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "#print(\".\", end=\"\", flush=True)\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.models import load_model\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import os\n",
    "print(\"=\", end=\"\\n\", flush=True)\n",
    "\n",
    "print(\"Download lista ticker\")\n",
    "lista_ticker = pd.read_parquet(\"Tickers_De_Giro.parquet\")\n",
    "lista_ticker = lista_ticker.sample(frac=1).reset_index(drop=True)\n",
    "lista_ticker = lista_ticker.loc[(lista_ticker[\"Ticker\"] != simbolo_test) & (lista_ticker[\"Ticker\"] != simbolo_validazione) & (lista_ticker[\"Categoria\"] != \"D\"), :]\n",
    "\n",
    "if os.path.exists('LSTM.keras'):\n",
    "    print(\"Caricamento modello esistente\")\n",
    "    model = load_model(\"LSTM.keras\")\n",
    "else:\n",
    "    print(\"Creazione modello\")\n",
    "    model = crea_modello(n_timesteps, giorni_previsione, n_targets, n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c6e9b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download dati ticker validazione\n",
      "Calcolo indicatori ticker validazione\n",
      "\u001b[48;5;42m1 di 2000: Ticker INW\u001b[0m\n",
      "Download dati ticker\n",
      "Calcolo indicatori ticker\n",
      "Definizione features e target\n",
      "Scaler\n",
      "Addestramento modello epochs=100, batch_size=16\n",
      "Epoch 1/100\n",
      "93/93 [==============================] - 15s 92ms/step - loss: 53.2594 - val_loss: 65.6977 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 7s 71ms/step - loss: 34.3342 - val_loss: 67.2549 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 7s 71ms/step - loss: 35.4718 - val_loss: 65.2438 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 7s 70ms/step - loss: 29.1789 - val_loss: 64.7627 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 6s 70ms/step - loss: 28.5442 - val_loss: 67.3185 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 6s 70ms/step - loss: 26.1430 - val_loss: 69.6484 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 7s 71ms/step - loss: 25.5905 - val_loss: 74.1366 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 7s 71ms/step - loss: 24.6578 - val_loss: 73.8216 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 7s 70ms/step - loss: 23.7093 - val_loss: 75.7459 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 7s 70ms/step - loss: 22.7356 - val_loss: 78.8796 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 7s 71ms/step - loss: 22.4423 - val_loss: 91.9169 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 7s 72ms/step - loss: 21.3284 - val_loss: 89.3492 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 6s 69ms/step - loss: 20.8226 - val_loss: 82.1163 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 6s 70ms/step - loss: 21.2631 - val_loss: 73.8592 - lr: 0.0010\n",
      "\u001b[48;5;42m2 di 2000: Ticker PGC\u001b[0m\n",
      "Download dati ticker\n",
      "Calcolo indicatori ticker\n",
      "Definizione features e target\n",
      "Scaler\n",
      "Addestramento modello epochs=100, batch_size=16\n",
      "Epoch 1/100\n",
      "206/206 [==============================] - 11s 54ms/step - loss: 16.4741 - val_loss: 60.2477 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "206/206 [==============================] - 11s 54ms/step - loss: 13.6775 - val_loss: 62.9708 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "206/206 [==============================] - 11s 54ms/step - loss: 12.6580 - val_loss: 63.0283 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "206/206 [==============================] - 11s 56ms/step - loss: 11.8541 - val_loss: 67.5734 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "206/206 [==============================] - 11s 54ms/step - loss: 11.5951 - val_loss: 65.2132 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "206/206 [==============================] - 11s 54ms/step - loss: 11.1908 - val_loss: 65.4352 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "206/206 [==============================] - 11s 55ms/step - loss: 10.7851 - val_loss: 68.1877 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "206/206 [==============================] - 11s 54ms/step - loss: 10.5203 - val_loss: 63.2193 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "206/206 [==============================] - 11s 55ms/step - loss: 10.2671 - val_loss: 66.2414 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "206/206 [==============================] - 11s 56ms/step - loss: 9.9093 - val_loss: 64.3125 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "206/206 [==============================] - 11s 54ms/step - loss: 9.8042 - val_loss: 65.1211 - lr: 0.0010\n",
      "\u001b[48;5;42m3 di 2000: Ticker KTOS\u001b[0m\n",
      "Download dati ticker\n",
      "Calcolo indicatori ticker\n",
      "Definizione features e target\n",
      "Scaler\n",
      "Addestramento modello epochs=100, batch_size=16\n",
      "Epoch 1/100\n",
      "206/206 [==============================] - 11s 55ms/step - loss: 17.9545 - val_loss: 66.2765 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "206/206 [==============================] - 11s 55ms/step - loss: 17.1704 - val_loss: 68.7138 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "206/206 [==============================] - 11s 55ms/step - loss: 15.4356 - val_loss: 65.5260 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "206/206 [==============================] - 11s 53ms/step - loss: 14.4745 - val_loss: 76.0939 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "206/206 [==============================] - 11s 54ms/step - loss: 14.0091 - val_loss: 71.0735 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "206/206 [==============================] - 16s 76ms/step - loss: 13.2931 - val_loss: 67.1384 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "206/206 [==============================] - 14s 69ms/step - loss: 13.0141 - val_loss: 73.5749 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "206/206 [==============================] - 15s 71ms/step - loss: 12.8831 - val_loss: 73.6872 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "206/206 [==============================] - 15s 71ms/step - loss: 12.2581 - val_loss: 76.4942 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "206/206 [==============================] - 14s 68ms/step - loss: 12.3423 - val_loss: 78.2155 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "206/206 [==============================] - 15s 71ms/step - loss: 12.0257 - val_loss: 76.7402 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "206/206 [==============================] - 15s 74ms/step - loss: 12.2497 - val_loss: 83.1632 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "206/206 [==============================] - 15s 71ms/step - loss: 11.5518 - val_loss: 75.7743 - lr: 0.0010\n",
      "\u001b[48;5;42m4 di 2000: Ticker NDAQ\u001b[0m\n",
      "Download dati ticker\n",
      "Calcolo indicatori ticker\n",
      "Definizione features e target\n",
      "Scaler\n",
      "Addestramento modello epochs=100, batch_size=16\n",
      "Epoch 1/100\n",
      "206/206 [==============================] - 15s 71ms/step - loss: 53.1908 - val_loss: 65.4633 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "206/206 [==============================] - 14s 69ms/step - loss: 33.4266 - val_loss: 66.6951 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "206/206 [==============================] - 12s 57ms/step - loss: 25.5593 - val_loss: 64.1164 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "206/206 [==============================] - 12s 56ms/step - loss: 120.3937 - val_loss: 68.5500 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "206/206 [==============================] - 12s 57ms/step - loss: 49.9005 - val_loss: 67.7961 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "206/206 [==============================] - 12s 56ms/step - loss: 38.2103 - val_loss: 66.7993 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "206/206 [==============================] - 12s 58ms/step - loss: 92.5126 - val_loss: 68.7717 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "206/206 [==============================] - 11s 56ms/step - loss: 50.1116 - val_loss: 68.3989 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "206/206 [==============================] - 11s 54ms/step - loss: 28.5200 - val_loss: 69.6490 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "206/206 [==============================] - 11s 55ms/step - loss: 82.4139 - val_loss: 68.1371 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "206/206 [==============================] - 11s 54ms/step - loss: 60.8746 - val_loss: 63.9657 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "206/206 [==============================] - 11s 55ms/step - loss: 109.1669 - val_loss: 67.2835 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "206/206 [==============================] - 11s 55ms/step - loss: 72.0012 - val_loss: 64.5213 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "206/206 [==============================] - 11s 55ms/step - loss: 54.4152 - val_loss: 72.1904 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "206/206 [==============================] - 12s 57ms/step - loss: 80.7116 - val_loss: 67.2964 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "206/206 [==============================] - 11s 56ms/step - loss: 231.3978 - val_loss: 66.3641 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "206/206 [==============================] - 11s 55ms/step - loss: 71.7407 - val_loss: 67.1563 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "206/206 [==============================] - 11s 55ms/step - loss: 148.0277 - val_loss: 68.0119 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "206/206 [==============================] - 11s 55ms/step - loss: 72.0338 - val_loss: 71.9290 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "206/206 [==============================] - 11s 55ms/step - loss: 78.3933 - val_loss: 66.9519 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "206/206 [==============================] - 11s 55ms/step - loss: 51.1394 - val_loss: 66.7288 - lr: 0.0010\n",
      "\u001b[48;5;42m5 di 2000: Ticker KEN\u001b[0m\n",
      "Download dati ticker\n",
      "Calcolo indicatori ticker\n",
      "Definizione features e target\n",
      "Scaler\n",
      "Addestramento modello epochs=100, batch_size=16\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 44.0904 - val_loss: 58.2324 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 42.0088 - val_loss: 49.6437 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 40.6285 - val_loss: 55.4210 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 40.4676 - val_loss: 52.2079 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 37.8593 - val_loss: 50.2170 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 39.6140 - val_loss: 50.0171 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 34.4169 - val_loss: 50.4969 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 32.5929 - val_loss: 49.7693 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 34.7903 - val_loss: 49.4652 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 31.7815 - val_loss: 50.7726 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 30.8554 - val_loss: 51.5157 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 30.3929 - val_loss: 51.8547 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 30.5283 - val_loss: 49.7842 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 27.8269 - val_loss: 51.1864 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 27.4828 - val_loss: 50.8147 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 28.7878 - val_loss: 50.5288 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 27.0218 - val_loss: 53.9577 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 30.3592 - val_loss: 53.2254 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 27.2336 - val_loss: 50.6186 - lr: 0.0010\n",
      "\u001b[48;5;42m6 di 2000: Ticker SWI\u001b[0m\n",
      "Download dati ticker\n",
      "Calcolo indicatori ticker\n",
      "Definizione features e target\n",
      "Scaler\n",
      "Addestramento modello epochs=100, batch_size=16\n",
      "Epoch 1/100\n",
      "67/67 [==============================] - 5s 81ms/step - loss: 22.0550 - val_loss: 49.7750 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - 5s 80ms/step - loss: 18.2534 - val_loss: 52.7158 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - 5s 81ms/step - loss: 18.1132 - val_loss: 51.8332 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 5s 81ms/step - loss: 17.4901 - val_loss: 53.8746 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - 5s 80ms/step - loss: 17.2191 - val_loss: 55.0936 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - 5s 80ms/step - loss: 16.6154 - val_loss: 55.9584 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - 5s 80ms/step - loss: 15.5544 - val_loss: 58.7518 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - 5s 80ms/step - loss: 15.9122 - val_loss: 58.3712 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - 6s 83ms/step - loss: 15.0443 - val_loss: 65.0615 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - 5s 78ms/step - loss: 15.0057 - val_loss: 66.9558 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - 5s 78ms/step - loss: 15.3884 - val_loss: 63.8628 - lr: 0.0010\n",
      "\u001b[48;5;42m7 di 2000: Ticker SPNT\u001b[0m\n",
      "Download dati ticker\n",
      "Calcolo indicatori ticker\n",
      "Definizione features e target\n",
      "Scaler\n",
      "Addestramento modello epochs=100, batch_size=16\n",
      "Epoch 1/100\n",
      "149/149 [==============================] - 9s 58ms/step - loss: 29.3942 - val_loss: 84.4134 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "149/149 [==============================] - 9s 58ms/step - loss: 47.1478 - val_loss: 66.0650 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "149/149 [==============================] - 9s 61ms/step - loss: 31.1660 - val_loss: 74.7871 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "149/149 [==============================] - 9s 58ms/step - loss: 50.1936 - val_loss: 67.6940 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "149/149 [==============================] - 9s 58ms/step - loss: 30.1680 - val_loss: 68.1982 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "149/149 [==============================] - 9s 58ms/step - loss: 37.7937 - val_loss: 75.9313 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "149/149 [==============================] - 9s 60ms/step - loss: 23.9233 - val_loss: 71.8803 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "149/149 [==============================] - 9s 60ms/step - loss: 64.4929 - val_loss: 70.3287 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "149/149 [==============================] - 9s 58ms/step - loss: 27.7999 - val_loss: 71.1885 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "149/149 [==============================] - 9s 58ms/step - loss: 35.7513 - val_loss: 73.4827 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "149/149 [==============================] - 9s 58ms/step - loss: 41.0178 - val_loss: 63.7697 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "149/149 [==============================] - 9s 58ms/step - loss: 28.8151 - val_loss: 72.1553 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "149/149 [==============================] - 8s 57ms/step - loss: 22.7803 - val_loss: 68.8809 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "149/149 [==============================] - 9s 58ms/step - loss: 21.4620 - val_loss: 65.6736 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "149/149 [==============================] - 9s 57ms/step - loss: 48.4248 - val_loss: 66.1099 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "149/149 [==============================] - 9s 58ms/step - loss: 21.6985 - val_loss: 66.1857 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "149/149 [==============================] - 9s 57ms/step - loss: 39.7960 - val_loss: 64.9289 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "149/149 [==============================] - 9s 57ms/step - loss: 18.7395 - val_loss: 73.4277 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "149/149 [==============================] - 9s 58ms/step - loss: 37.5224 - val_loss: 72.8827 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "149/149 [==============================] - 9s 58ms/step - loss: 34.3291 - val_loss: 71.4004 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "149/149 [==============================] - 9s 58ms/step - loss: 28.5281 - val_loss: 69.8916 - lr: 0.0010\n",
      "\u001b[48;5;42m8 di 2000: Ticker FL\u001b[0m\n",
      "Download dati ticker\n",
      "Calcolo indicatori ticker\n",
      "Definizione features e target\n",
      "Scaler\n",
      "Addestramento modello epochs=100, batch_size=16\n",
      "Epoch 1/100\n",
      "206/206 [==============================] - 11s 53ms/step - loss: 31.2738 - val_loss: 67.1631 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "206/206 [==============================] - 11s 52ms/step - loss: 30.3161 - val_loss: 52.9714 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "206/206 [==============================] - 11s 53ms/step - loss: 26.6538 - val_loss: 52.5991 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "206/206 [==============================] - 11s 53ms/step - loss: 27.2502 - val_loss: 57.7335 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "206/206 [==============================] - 11s 52ms/step - loss: 25.8610 - val_loss: 55.4021 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "206/206 [==============================] - 11s 53ms/step - loss: 24.1338 - val_loss: 55.3913 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "206/206 [==============================] - 11s 52ms/step - loss: 25.0591 - val_loss: 56.2650 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "206/206 [==============================] - 11s 53ms/step - loss: 23.3013 - val_loss: 57.5031 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "206/206 [==============================] - 11s 54ms/step - loss: 22.9838 - val_loss: 54.2276 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "206/206 [==============================] - 11s 53ms/step - loss: 22.2318 - val_loss: 53.2129 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "206/206 [==============================] - 11s 52ms/step - loss: 21.1624 - val_loss: 55.3681 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "206/206 [==============================] - 11s 53ms/step - loss: 24.2764 - val_loss: 53.3795 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "206/206 [==============================] - 11s 54ms/step - loss: 21.7109 - val_loss: 52.6263 - lr: 0.0010\n",
      "\u001b[48;5;42m9 di 2000: Ticker SYNH\u001b[0m\n",
      "Download dati ticker\n",
      "Calcolo indicatori ticker\n",
      "Definizione features e target\n",
      "Scaler\n",
      "Addestramento modello epochs=100, batch_size=16\n",
      "Epoch 1/100\n",
      "129/129 [==============================] - 8s 62ms/step - loss: 66.3831 - val_loss: 53.2812 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "129/129 [==============================] - 8s 61ms/step - loss: 46.5851 - val_loss: 61.4931 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "129/129 [==============================] - 8s 60ms/step - loss: 40.7129 - val_loss: 49.7546 - lr: 0.0010\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 8s 60ms/step - loss: 38.9110 - val_loss: 50.5677 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "129/129 [==============================] - 8s 61ms/step - loss: 36.7116 - val_loss: 52.9520 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "129/129 [==============================] - 8s 61ms/step - loss: 37.1860 - val_loss: 56.9937 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "129/129 [==============================] - 8s 64ms/step - loss: 35.5856 - val_loss: 49.8448 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "129/129 [==============================] - 8s 64ms/step - loss: 34.0385 - val_loss: 50.1631 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "129/129 [==============================] - 8s 64ms/step - loss: 33.1134 - val_loss: 53.9200 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "129/129 [==============================] - 8s 60ms/step - loss: 33.1486 - val_loss: 52.5454 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "129/129 [==============================] - 8s 60ms/step - loss: 33.6355 - val_loss: 51.5151 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "129/129 [==============================] - 8s 60ms/step - loss: 36.9293 - val_loss: 56.6720 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "129/129 [==============================] - 8s 59ms/step - loss: 33.8415 - val_loss: 52.6532 - lr: 0.0010\n",
      "\u001b[48;5;42m10 di 2000: Ticker COOP\u001b[0m\n",
      "Download dati ticker\n",
      "Calcolo indicatori ticker\n",
      "Definizione features e target\n",
      "Scaler\n",
      "Addestramento modello epochs=100, batch_size=16\n",
      "Epoch 1/100\n",
      "170/170 [==============================] - 9s 55ms/step - loss: 20.5909 - val_loss: 72.1717 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "170/170 [==============================] - 9s 56ms/step - loss: 115.8132 - val_loss: 56.6109 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "170/170 [==============================] - 9s 55ms/step - loss: 26.7107 - val_loss: 59.8344 - lr: 0.0010\n",
      "Epoch 4/100\n",
      " 72/170 [===========>..................] - ETA: 3s - loss: 17.8829"
     ]
    }
   ],
   "source": [
    "print(\"Download dati ticker validazione\")\n",
    "ticker_val = yf.download(simbolo_validazione, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "ticker_val.index = ticker_val.index.date\n",
    "print(\"Calcolo indicatori ticker validazione\")\n",
    "ticker_val = fx.crea_indicatori(ticker_val)\n",
    "ticker_val.dropna(axis=0, inplace=True)\n",
    "\n",
    "idx_val, X_val, Y_val = fx.to_XY(ticker_val, elenco_features, elenco_targets, n_timesteps, giorni_previsione, addestramento=True)\n",
    "X_val = X_val.reshape((-1, n_timesteps * n_features))\n",
    "Y_val = Y_val.reshape((-1, giorni_previsione * n_targets))\n",
    "X_scaler_val = clone(scaler)\n",
    "Y_scaler_val = clone(scaler)\n",
    "X_val = X_scaler_val.fit_transform(X_val)\n",
    "Y_val = Y_scaler_val.fit_transform(Y_val)\n",
    "X_val = X_val.reshape((-1, n_timesteps, n_features))\n",
    "Y_val = Y_val.reshape((-1, giorni_previsione, n_targets))\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "for i_ticker in range (n_simboli_addestramento + 1):\n",
    "    nome_simbolo = lista_ticker[\"Ticker\"].iloc[i_ticker]\n",
    "    print(f\"\\033[48;5;42m{i_ticker+1} di {n_simboli_addestramento}: Ticker {nome_simbolo}\\033[0m\")\n",
    "    print(\"Download dati ticker\")\n",
    "    try:\n",
    "        ticker = yf.download(nome_simbolo, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "        if ticker[\"Close\"].iloc[-1] >= 1:\n",
    "            ticker.index = ticker.index.date\n",
    "            print(\"Calcolo indicatori ticker\")\n",
    "            ticker = fx.crea_indicatori(ticker)\n",
    "            ticker.dropna(axis=0, inplace=True)\n",
    "\n",
    "            print(\"Definizione features e target\")\n",
    "            idx, X, Y = fx.to_XY(ticker, elenco_features, elenco_targets, n_timesteps, giorni_previsione, addestramento=True)\n",
    "\n",
    "            print(\"Scaler\")\n",
    "            X = X.reshape((-1, n_timesteps * n_features))\n",
    "            Y = Y.reshape((-1, giorni_previsione * n_targets))\n",
    "\n",
    "            #X_train, X_test, Y_train, Y_test, idx_train, idx_test = train_test_split(X, Y, idx, test_size=0.2, random_state=seed)\n",
    "            X_train = X\n",
    "            Y_train = Y\n",
    "\n",
    "            X_scaler = clone(scaler)\n",
    "            Y_scaler = clone(scaler)\n",
    "            #X_scaler.fit(X_train)\n",
    "            #Y_scaler.fit(Y_train)\n",
    "            X_train = X_scaler.fit_transform(X_train)\n",
    "            #X_test = X_scaler.fit_transform(X_test)\n",
    "            Y_train = Y_scaler.fit_transform(Y_train)\n",
    "            #Y_test = Y_scaler.fit_transform(Y_test)\n",
    "\n",
    "            X_train = X_train.reshape((-1, n_timesteps, n_features))\n",
    "            #X_test = X_test.reshape((-1, n_timesteps, n_features))\n",
    "            Y_train = Y_train.reshape((-1, giorni_previsione, n_targets))\n",
    "            #Y_test = Y_test.reshape((-1, giorni_previsione, n_targets))\n",
    "\n",
    "            print(f\"Addestramento modello epochs={epochs}, batch_size={batch_size}\")\n",
    "            model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, Y_val), callbacks=[early_stopping, reduce_lr])\n",
    "            model.save(\"LSTM.keras\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df7dc8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Download dati ticker per previsione\")\n",
    "dati_previsione = yf.download(simbolo_test, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "dati_previsione.index = dati_previsione.index.date\n",
    "dati_previsione = fx.crea_indicatori(dati_previsione)\n",
    "dati_previsione.iloc[:100] = dati_previsione.iloc[:100].dropna(axis=0)\n",
    "\n",
    "indice_prev, X_prev, Y_prev = fx.to_XY(dati_previsione, elenco_features, elenco_targets, n_timesteps, giorni_previsione, addestramento=False)\n",
    "\n",
    "X_prev = X_prev.reshape(-1, n_timesteps * n_features)\n",
    "Y_prev = Y_prev.reshape(-1, giorni_previsione * n_targets)\n",
    "X_scaler_prev = clone(scaler)\n",
    "Y_scaler_prev = clone(scaler)\n",
    "X_prev = X_scaler_prev.fit_transform(X_prev)\n",
    "Y_prev = Y_scaler_prev.fit_transform(Y_prev)\n",
    "X_prev = X_prev.reshape(-1, n_timesteps, n_features)\n",
    "Y_prev = Y_prev.reshape(-1, giorni_previsione, n_targets)\n",
    "\n",
    "pred = model.predict(X_prev)\n",
    "#pred_loss, pred_mae = model.evaluate(X_prev, Y_prev)\n",
    "\n",
    "X_prev = X_prev.reshape(-1, n_timesteps * n_features)\n",
    "X_prev = X_scaler_prev.inverse_transform(X_prev)\n",
    "X_prev = X_prev.reshape(-1, n_timesteps, n_features)\n",
    "\n",
    "pred = pred.reshape(-1, giorni_previsione * n_targets)\n",
    "pred = Y_scaler_prev.inverse_transform(pred)\n",
    "pred = pred.reshape(-1, giorni_previsione, n_targets)\n",
    "\n",
    "col_analisi = \"EMA_5\"\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "import plotly.subplots as sp\n",
    "import yfinance as yf\n",
    "\n",
    "def grafico1(dati_previsione, pred):\n",
    "    dati_previsione = dati_previsione.loc[indice_prev]\n",
    "    new_dates = pd.bdate_range(start=dati_previsione.index[-1] + pd.Timedelta(days=1), periods=giorni_previsione)\n",
    "    df_new = pd.DataFrame(index=new_dates.date)\n",
    "    dati_previsione = pd.concat([dati_previsione, df_new])\n",
    "    risultato = pd.DataFrame({\"Previsione\": pred[:, giorni_previsione-1, col_targets[col_analisi]].round(2)}, index=dati_previsione.index[giorni_previsione:])\n",
    "    risultato = pd.concat([dati_previsione[col_analisi], risultato], axis=1)\n",
    "    \n",
    "    target = go.Scatter(\n",
    "        x = risultato.index,\n",
    "        y = risultato[col_analisi],\n",
    "        mode = 'lines',\n",
    "        line = dict(color='rgba(0, 0, 0, .9)'),\n",
    "        name = col_analisi\n",
    "    )\n",
    "\n",
    "    previsione = go.Scatter(\n",
    "        x = risultato.index,\n",
    "        y = risultato['Previsione'],\n",
    "        mode = 'lines',\n",
    "        line = dict(color='rgba(0, 0, 250, .9)'),\n",
    "        name = 'Previsione'\n",
    "    )\n",
    "    '''\n",
    "    err_meno = go.Scatter(\n",
    "        x = risultato.index,\n",
    "        y = risultato['Previsione'] - err, \n",
    "        mode = 'lines',\n",
    "        line = dict(\n",
    "            color='rgba(0, 0, 250, .9)',\n",
    "            width=1\n",
    "        ),\n",
    "        connectgaps = False,\n",
    "        name = 'err-'\n",
    "    )                \n",
    "    err_piu = go.Scatter(\n",
    "        x = risultato.index,\n",
    "        y = risultato['Previsione'] + err, \n",
    "        mode = 'lines',\n",
    "        line = dict(\n",
    "            color='rgba(0, 0, 250, .9)',\n",
    "            width=1\n",
    "        ),\n",
    "        fill='tonexty',\n",
    "        fillcolor='rgba(0, 0, 250, .2)', # Puoi cambiare il valore di alpha per regolare la trasparenza\n",
    "        connectgaps = False,\n",
    "        name = 'err+'\n",
    "    )\n",
    "    '''\n",
    "    layout = dict(xaxis = dict(autorange=True),\n",
    "                  yaxis = dict(title = 'Previsioni', autorange=True),\n",
    "                  autosize = True,\n",
    "                  margin = go.layout.Margin(\n",
    "                      l=0,  # Sinistra\n",
    "                      r=0,  # Destra\n",
    "                      b=0,  # Basso\n",
    "                      t=50,  # Alto\n",
    "                      pad=0  # Padding\n",
    "                  ),\n",
    "                  legend = dict(traceorder = 'normal', bordercolor = 'black')\n",
    "    )\n",
    "    fig = sp.make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "    fig.update_layout(layout)\n",
    "    fig.add_trace(target, row=1, col=1)\n",
    "    fig.add_trace(previsione, row=1, col=1)\n",
    "    #fig.add_trace(err_meno, row=1, col=1)\n",
    "    #fig.add_trace(err_piu, row=1, col=1)\n",
    "    pyo.plot(fig, filename=\"grafico1.html\", auto_open=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3527f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico2(dati_previsione, pred):\n",
    "    dati2 = dati_previsione.dropna(axis=0).iloc[-60:]\n",
    "    new_dates = pd.bdate_range(start=dati2.index[-1] + pd.Timedelta(days=1), periods=giorni_previsione)\n",
    "    df_new = pd.DataFrame(index=new_dates.date)\n",
    "\n",
    "    val_prev2 = (pred[-1, i, col_targets[col_analisi]] for i in range(giorni_previsione))\n",
    "    prev2 = pd.DataFrame(val_prev2, columns=[\"Previsione\"], index=df_new.index)\n",
    "    riga_iniziale = pd.DataFrame({\"Previsione\": [dati2[col_analisi].iloc[-1]]}, index=[dati2.index[-1]])\n",
    "    prev2 = pd.concat([riga_iniziale, prev2], axis=0)\n",
    "    \n",
    "    target = go.Scatter(\n",
    "        x = dati2.index,\n",
    "        y = dati2[col_analisi].round(2),\n",
    "        mode = 'lines',\n",
    "        line = dict(color='rgba(0, 0, 0, .9)'),\n",
    "        name = col_analisi\n",
    "    )\n",
    "\n",
    "    previsione = go.Scatter(\n",
    "        x = prev2.index,\n",
    "        y = prev2['Previsione'].round(2),\n",
    "        mode = 'lines',\n",
    "        line = dict(color='rgba(0, 0, 250, .9)'),\n",
    "        name = 'Previsione'\n",
    "    )\n",
    "    layout = dict(xaxis = dict(autorange=True),\n",
    "                  yaxis = dict(title = 'Previsioni', autorange=True),\n",
    "                  autosize = True,\n",
    "                  margin = go.layout.Margin(\n",
    "                      l=0,  # Sinistra\n",
    "                      r=0,  # Destra\n",
    "                      b=0,  # Basso\n",
    "                      t=50,  # Alto\n",
    "                      pad=0  # Padding\n",
    "                  ),\n",
    "                  legend = dict(traceorder = 'normal', bordercolor = 'black')\n",
    "    )\n",
    "    fig = sp.make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "    fig.update_layout(layout)\n",
    "    fig.add_trace(target, row=1, col=1)\n",
    "    fig.add_trace(previsione, row=1, col=1)\n",
    "    pyo.plot(fig, filename=\"grafico2.html\", auto_open=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b5c1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico1(dati_previsione, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "462ab679",
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico2(dati_previsione, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa11c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
