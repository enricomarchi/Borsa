{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99bae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "simbolo_test = \"BTG\"\n",
    "simbolo_validazione = \"DHT\"\n",
    "n_simboli_addestramento = 10\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "#learning_rate = 0.001\n",
    "n_timesteps = 60 # n. barre del periodo passato per la ricerca di pattern, inclusa ultima data disponibile\n",
    "giorni_previsione = 10 # n. barre nel futuro di cui si desidera prevedere il prezzo\n",
    "seed = 10 \n",
    "elenco_features = [\n",
    "    #\"Close\",\n",
    "    \"EMA_5\", \n",
    "    \"EMA_20\", \n",
    "    \"EMA_50\",\n",
    "    #\"Open\",  \n",
    "    #\"High\",\n",
    "    #\"Low\",\n",
    "    \"Volume\",\n",
    "    \"MACDh\",\n",
    "    \"PSAR\",\n",
    "    \"PSARaf\",\n",
    "    \"SUPERT\", \n",
    "    \"TRIX\",\n",
    "    \"ATR\"\n",
    "]\n",
    "elenco_target = [\n",
    "    #\"Close\"\n",
    "    \"EMA_5\",\n",
    "    \"EMA_20\", \n",
    "    \"EMA_50\"    \n",
    "]\n",
    "\n",
    "col_features = {col: idx for idx, col in enumerate(elenco_features)}\n",
    "col_targets = {col: idx for idx, col in enumerate(elenco_target)}\n",
    "n_features = len(col_features)\n",
    "n_targets = len(col_targets)\n",
    "\n",
    "def crea_modello(giorni_previsione=giorni_previsione, n_targets=n_targets, n_features=n_features, neuroni=50, l2_rate=0, dropout_rate=0, optimizer='adam'):\n",
    "    model = Sequential([\n",
    "        LSTM(neuroni, input_shape=(n_timesteps, n_features)),\n",
    "        RepeatVector(giorni_previsione),\n",
    "        LSTM(neuroni, return_sequences=True, kernel_regularizer=l2(l2_rate)),\n",
    "        Dropout(dropout_rate),\n",
    "        #LSTM(100, return_sequences=True, kernel_regularizer=l2(0.01)),\n",
    "        #Dropout(0.2),\n",
    "        #LSTM(50, kernel_regularizer=l2(0.01)),\n",
    "        #Dropout(0.2),\n",
    "        #Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        #Dropout(0.2),\n",
    "        TimeDistributed(Dense(n_targets, activation='linear'))\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss='mean_absolute_percentage_error', metrics=['mse', 'mae', 'msle', 'huber_loss'])\n",
    "    return model\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "#from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import clone\n",
    "scaler = PowerTransformer()\n",
    "#scaler = RobustScaler()\n",
    "\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "param_space = {\n",
    "    'neuroni': Integer(10, 150),\n",
    "    'dropout_rate': Real(0.0, 0.5),\n",
    "    'optimizer': Categorical(['adam', 'rmsprop']),\n",
    "    'batch_size': Integer(10, 50),\n",
    "    'epochs': Integer(10, 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25570dc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importa librerie"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImporta librerie\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasRegressor\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers'"
     ]
    }
   ],
   "source": [
    "print(\"Importa librerie\", end=\"\", flush=True)\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import pandas as pd\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import yfinance as yf\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import numpy as np\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import tensorflow as tf\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import fx_com\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import funzioni as fx\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.layers import Dropout\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from keras.regularizers import l2\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras import Sequential\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\".\", end=\"\", flush=True)\n",
    "from tensorflow.keras.models import load_model\n",
    "print(\".\", end=\"\", flush=True)\n",
    "import os\n",
    "print(\".\", end=\"\\n\", flush=True)\n",
    "\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "def ottimizzazione(X_train, Y_train, n_iter=50, cv=3, n_jobs=-1, seed=42):\n",
    "    from skopt import BayesSearchCV\n",
    "    model = KerasRegressor(build_fn=crea_modello, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    opt = BayesSearchCV(\n",
    "        model,\n",
    "        param_space,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        random_state=seed\n",
    "    )\n",
    "    opt.fit(X_train, Y_train)\n",
    "    print(\"Migliori iperparametri:\", opt.best_params_)\n",
    "\n",
    "print(\"Download lista ticker\")\n",
    "lista_ticker = pd.read_parquet(\"Tickers_De_Giro.parquet\")\n",
    "lista_ticker = lista_ticker.sample(frac=1).reset_index(drop=True)\n",
    "lista_ticker = lista_ticker.loc[(lista_ticker[\"Ticker\"] != simbolo_test) & (lista_ticker[\"Ticker\"] != simbolo_validazione) & (lista_ticker[\"Categoria\"] != \"D\"), :]\n",
    "\n",
    "if os.path.exists('LSTM.keras'):\n",
    "    print(\"Caricamento modello esistente\")\n",
    "    model = load_model(\"LSTM.keras\")\n",
    "else:\n",
    "    print(\"Creazione modello\")\n",
    "    model = crea_modello(giorni_previsione, n_targets, n_features)\n",
    "\n",
    "def to_XY(dati_ticker, n_timesteps, giorni_previsione, addestramento=True):\n",
    "    new_dates = pd.bdate_range(start=dati_ticker.index[-1] + pd.Timedelta(days=1), periods=giorni_previsione)\n",
    "    df_new = pd.DataFrame(index=new_dates)\n",
    "    dati_ticker = pd.concat([dati_ticker, df_new])\n",
    "\n",
    "    features = dati_ticker[elenco_features]\n",
    "    targets = dati_ticker[elenco_target]\n",
    "\n",
    "    if addestramento:\n",
    "        i_tot = len(features) - giorni_previsione*2\n",
    "    else:\n",
    "        i_tot = len(features) - giorni_previsione\n",
    "    X, Y = [], []\n",
    "    for i in range(n_timesteps - 1, i_tot):\n",
    "        X.append(features.iloc[i - (n_timesteps - 1):i + 1])\n",
    "        Y.append(targets.iloc[i + 1:i + 1 + giorni_previsione])\n",
    "    \n",
    "    idx = dati_ticker.index[n_timesteps - 1:i_tot]\n",
    "    \n",
    "    return idx, np.array(X), np.array(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c6e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Download dati ticker validazione\")\n",
    "ticker_val = yf.download(simbolo_validazione, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "ticker_val.index = ticker_val.index.date\n",
    "print(\"Calcolo indicatori ticker validazione\")\n",
    "ticker_val = fx.crea_indicatori(ticker_val)\n",
    "ticker_val.dropna(axis=0, inplace=True)\n",
    "\n",
    "for i_ticker in range (n_simboli_addestramento + 1):\n",
    "    nome_simbolo = lista_ticker[\"Ticker\"].iloc[i_ticker]\n",
    "    print(f\"\\033[48;5;42m{i_ticker} di {n_simboli_addestramento}: Ticker {nome_simbolo}\\033[0m\")\n",
    "    print(\"Download dati ticker\")\n",
    "    ticker = yf.download(nome_simbolo, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "    if ticker[\"Close\"].iloc[-1] >= 1:\n",
    "        ticker.index = ticker.index.date\n",
    "        print(\"Calcolo indicatori ticker validazione\")\n",
    "        ticker = fx.crea_indicatori(ticker)\n",
    "        ticker.dropna(axis=0, inplace=True)\n",
    "\n",
    "        print(\"Definizione features e target\")\n",
    "        idx, X, Y = to_XY(ticker, n_timesteps, giorni_previsione, addestramento=True)\n",
    "        idx_val, X_val, Y_val = to_XY(ticker_val, n_timesteps, giorni_previsione, addestramento=True)\n",
    "\n",
    "        print(\"Scaler\")\n",
    "        X = X.reshape((-1, n_timesteps * n_features))\n",
    "        Y = Y.reshape((-1, giorni_previsione * n_targets))\n",
    "        X_val = X_val.reshape((-1, n_timesteps * n_features))\n",
    "        Y_val = Y_val.reshape((-1, giorni_previsione * n_targets))\n",
    "\n",
    "        #X_train, X_test, Y_train, Y_test, idx_train, idx_test = train_test_split(X, Y, idx, test_size=0.2, random_state=seed)\n",
    "        X_train = X\n",
    "        Y_train = Y\n",
    "\n",
    "        X_scaler = clone(scaler)\n",
    "        Y_scaler = clone(scaler)\n",
    "        X_scaler_val = clone(scaler)\n",
    "        Y_scaler_val = clone(scaler)\n",
    "        X_scaler.fit(X_train)\n",
    "        Y_scaler.fit(Y_train)\n",
    "        X_scaler_val.fit(X_val)\n",
    "        Y_scaler_val.fit(Y_val)\n",
    "        X_train = X_scaler.fit_transform(X_train)\n",
    "        #X_test = X_scaler.fit_transform(X_test)\n",
    "        Y_train = Y_scaler.fit_transform(Y_train)\n",
    "        #Y_test = Y_scaler.fit_transform(Y_test)\n",
    "        X_val = X_scaler_val.fit_transform(X_val)\n",
    "        Y_val = Y_scaler_val.fit_transform(Y_val)\n",
    "\n",
    "        X_train = X_train.reshape((-1, n_timesteps, n_features))\n",
    "        X_val = X_val.reshape((-1, n_timesteps, n_features))\n",
    "        #X_test = X_test.reshape((-1, n_timesteps, n_features))\n",
    "        Y_train = Y_train.reshape((-1, giorni_previsione, n_targets))\n",
    "        Y_val = Y_val.reshape((-1, giorni_previsione, n_targets))\n",
    "        #Y_test = Y_test.reshape((-1, giorni_previsione, n_targets))\n",
    "\n",
    "        print(f\"Addestramento modello epochs={epochs}, batch_size={batch_size}\")\n",
    "        model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, Y_val))\n",
    "        model.save(\"LSTM.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7dc8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Download dati ticker per previsione\")\n",
    "dati_previsione = yf.download(simbolo_test, start='2010-01-01', end='2023-12-31', progress=False)\n",
    "dati_previsione.index = dati_previsione.index.date\n",
    "dati_previsione = fx.crea_indicatori(dati_previsione)\n",
    "dati_previsione.iloc[:100] = dati_previsione.iloc[:100].dropna(axis=0)\n",
    "\n",
    "indice_prev, X_prev, Y_prev = to_XY(dati_previsione, n_timesteps, giorni_previsione, addestramento=False)\n",
    "\n",
    "X_prev = X_prev.reshape(-1, n_timesteps * n_features)\n",
    "Y_prev = Y_prev.reshape(-1, giorni_previsione * n_targets)\n",
    "X_scaler_prev = clone(scaler)\n",
    "Y_scaler_prev = clone(scaler)\n",
    "X_prev = X_scaler_prev.fit_transform(X_prev)\n",
    "Y_prev = Y_scaler_prev.fit_transform(Y_prev)\n",
    "X_prev = X_prev.reshape(-1, n_timesteps, n_features)\n",
    "Y_prev = Y_prev.reshape(-1, giorni_previsione, n_targets)\n",
    "\n",
    "pred = model.predict(X_prev)\n",
    "#pred_loss, pred_mae = model.evaluate(X_prev, Y_prev)\n",
    "\n",
    "X_prev = X_prev.reshape(-1, n_timesteps * n_features)\n",
    "X_prev = X_scaler_prev.inverse_transform(X_prev)\n",
    "X_prev = X_prev.reshape(-1, n_timesteps, n_features)\n",
    "\n",
    "pred = pred.reshape(-1, giorni_previsione * n_targets)\n",
    "pred = Y_scaler_prev.inverse_transform(pred)\n",
    "pred = pred.reshape(-1, giorni_previsione, n_targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f0df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dati_previsione = dati_previsione.loc[indice_prev]\n",
    "new_dates = pd.bdate_range(start=dati_previsione.index[-1] + pd.Timedelta(days=1), periods=giorni_previsione)\n",
    "df_new = pd.DataFrame(index=new_dates.date)\n",
    "dati_previsione = pd.concat([dati_previsione, df_new])\n",
    "\n",
    "col_analisi = \"EMA_20\"\n",
    "risultato = pd.DataFrame({\"Previsione\": pred[:, giorni_previsione-1, col_targets[col_analisi]].round(2)}, index=dati_previsione.index[giorni_previsione:])\n",
    "risultato = pd.concat([dati_previsione[col_analisi], risultato], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69284f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "import plotly.subplots as sp\n",
    "import yfinance as yf\n",
    "\n",
    "target = go.Scatter(\n",
    "    x = risultato.index,\n",
    "    y = risultato[col_analisi],\n",
    "    mode = 'lines',\n",
    "    line = dict(color='rgba(0, 0, 0, .9)'),\n",
    "    name = col_analisi\n",
    ")\n",
    "\n",
    "previsione = go.Scatter(\n",
    "    x = risultato.index,\n",
    "    y = risultato['Previsione'],\n",
    "    mode = 'lines',\n",
    "    line = dict(color='rgba(0, 0, 250, .9)'),\n",
    "    name = 'Previsione'\n",
    ")\n",
    "'''\n",
    "err_meno = go.Scatter(\n",
    "    x = risultato.index,\n",
    "    y = risultato['Previsione'] - err, \n",
    "    mode = 'lines',\n",
    "    line = dict(\n",
    "        color='rgba(0, 0, 250, .9)',\n",
    "        width=1\n",
    "    ),\n",
    "    connectgaps = False,\n",
    "    name = 'err-'\n",
    ")                \n",
    "err_piu = go.Scatter(\n",
    "    x = risultato.index,\n",
    "    y = risultato['Previsione'] + err, \n",
    "    mode = 'lines',\n",
    "    line = dict(\n",
    "        color='rgba(0, 0, 250, .9)',\n",
    "        width=1\n",
    "    ),\n",
    "    fill='tonexty',\n",
    "    fillcolor='rgba(0, 0, 250, .2)', # Puoi cambiare il valore di alpha per regolare la trasparenza\n",
    "    connectgaps = False,\n",
    "    name = 'err+'\n",
    ")\n",
    "'''\n",
    "layout = dict(xaxis = dict(autorange=True),\n",
    "              yaxis = dict(title = 'Previsioni', autorange=True),\n",
    "              autosize = True,\n",
    "              margin = go.layout.Margin(\n",
    "                  l=0,  # Sinistra\n",
    "                  r=0,  # Destra\n",
    "                  b=0,  # Basso\n",
    "                  t=50,  # Alto\n",
    "                  pad=0  # Padding\n",
    "              ),\n",
    "              legend = dict(traceorder = 'normal', bordercolor = 'black')\n",
    ")\n",
    "fig = sp.make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "fig.update_layout(layout)\n",
    "fig.add_trace(target, row=1, col=1)\n",
    "fig.add_trace(previsione, row=1, col=1)\n",
    "#fig.add_trace(err_meno, row=1, col=1)\n",
    "#fig.add_trace(err_piu, row=1, col=1)\n",
    "pyo.plot(fig, filename=\"regressione.html\", auto_open=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ff63e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
