{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99bae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "n_timesteps = 120 # n. barre del periodo passato per la ricerca di pattern, inclusa ultima data disponibile\n",
    "giorni_previsione = 1 # n. barre nel futuro di cui si desidera prevedere il prezzo\n",
    "seed = 10 \n",
    "\n",
    "def crea_modello(n_timesteps, n_features):\n",
    "    model = Sequential([\n",
    "        #BatchNormalization(input_shape=(n_timesteps, n_features)),\n",
    "        LSTM(50, return_sequences=True, recurrent_initializer=\"glorot_uniform\", kernel_initializer=\"uniform\"),\n",
    "        LSTM(50, recurrent_initializer=\"glorot_uniform\", kernel_initializer=\"uniform\"),\n",
    "        Dense(64, activation='relu', kernel_initializer=\"glorot_uniform\"),\n",
    "        Dense(1, activation='linear', kernel_initializer=\"glorot_uniform\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def to_ft(dati_ticker, giorni_pervisione):\n",
    "    features = dati_ticker[[\n",
    "        \"Close\", \n",
    "        \"Open\", \n",
    "        \"High\",\n",
    "        \"Low\",\n",
    "        \"Volume\"\n",
    "    ]]\n",
    "    target = dati_ticker[[\"Close\"]].shift(-giorni_previsione)\n",
    "    return features.iloc[:-giorni_previsione], target.iloc[:-giorni_previsione]\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.base import clone\n",
    "scaler = PowerTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25570dc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download dati ticker\n",
      "Definizione features e target\n",
      "Preparazione array X e Y\n",
      "Creazione modello\n",
      "Compilazione modello\n",
      "Reshape\n",
      "Reshape ai valori originari\n",
      "Addestramento modello epochs=50, batch_size=32\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 17s 116ms/step - loss: 0.2282 - mae: 0.3338 - val_loss: 0.0646 - val_mae: 0.1975\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0546 - mae: 0.1789 - val_loss: 0.0499 - val_mae: 0.1720\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0459 - mae: 0.1619 - val_loss: 0.0441 - val_mae: 0.1626\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0396 - mae: 0.1511 - val_loss: 0.0394 - val_mae: 0.1486\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0340 - mae: 0.1393 - val_loss: 0.0316 - val_mae: 0.1345\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0322 - mae: 0.1341 - val_loss: 0.0295 - val_mae: 0.1287\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 5s 81ms/step - loss: 0.0303 - mae: 0.1319 - val_loss: 0.0271 - val_mae: 0.1223\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 5s 84ms/step - loss: 0.0282 - mae: 0.1256 - val_loss: 0.0257 - val_mae: 0.1203\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0256 - mae: 0.1195 - val_loss: 0.0247 - val_mae: 0.1175\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0229 - mae: 0.1109 - val_loss: 0.0232 - val_mae: 0.1128\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 5s 85ms/step - loss: 0.0222 - mae: 0.1099 - val_loss: 0.0247 - val_mae: 0.1176\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0222 - mae: 0.1101 - val_loss: 0.0296 - val_mae: 0.1278\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 5s 77ms/step - loss: 0.0207 - mae: 0.1047 - val_loss: 0.0204 - val_mae: 0.1036\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0190 - mae: 0.1014 - val_loss: 0.0195 - val_mae: 0.1034\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0197 - mae: 0.1031 - val_loss: 0.0201 - val_mae: 0.1068\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0186 - mae: 0.1005 - val_loss: 0.0213 - val_mae: 0.1089\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0177 - mae: 0.0974 - val_loss: 0.0197 - val_mae: 0.1033\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0174 - mae: 0.0968 - val_loss: 0.0199 - val_mae: 0.1049\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0177 - mae: 0.0976 - val_loss: 0.0187 - val_mae: 0.1025\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0186 - mae: 0.1002 - val_loss: 0.0192 - val_mae: 0.1034\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0183 - mae: 0.0991 - val_loss: 0.0186 - val_mae: 0.1005\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0171 - mae: 0.0961 - val_loss: 0.0183 - val_mae: 0.1013\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0172 - mae: 0.0959 - val_loss: 0.0196 - val_mae: 0.1066\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0173 - mae: 0.0962 - val_loss: 0.0179 - val_mae: 0.0995\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0170 - mae: 0.0952 - val_loss: 0.0173 - val_mae: 0.0968\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0175 - mae: 0.0963 - val_loss: 0.0181 - val_mae: 0.1019\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0166 - mae: 0.0949 - val_loss: 0.0178 - val_mae: 0.0990\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 0.0166 - mae: 0.0940 - val_loss: 0.0200 - val_mae: 0.1048\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 5s 85ms/step - loss: 0.0175 - mae: 0.0961 - val_loss: 0.0181 - val_mae: 0.0997\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0186 - mae: 0.0990 - val_loss: 0.0196 - val_mae: 0.1054\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 0.0164 - mae: 0.0937 - val_loss: 0.0179 - val_mae: 0.0999\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 5s 81ms/step - loss: 0.0168 - mae: 0.0946 - val_loss: 0.0174 - val_mae: 0.0978\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0163 - mae: 0.0931 - val_loss: 0.0177 - val_mae: 0.0993\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0176 - mae: 0.0982 - val_loss: 0.0175 - val_mae: 0.0981\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0163 - mae: 0.0932 - val_loss: 0.0182 - val_mae: 0.1008\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 0.0165 - mae: 0.0938 - val_loss: 0.0173 - val_mae: 0.0970\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 0.0164 - mae: 0.0937 - val_loss: 0.0182 - val_mae: 0.1007\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0166 - mae: 0.0950 - val_loss: 0.0175 - val_mae: 0.0972\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 5s 83ms/step - loss: 0.0167 - mae: 0.0944 - val_loss: 0.0181 - val_mae: 0.0980\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 5s 81ms/step - loss: 0.0164 - mae: 0.0933 - val_loss: 0.0170 - val_mae: 0.0960\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0162 - mae: 0.0935 - val_loss: 0.0180 - val_mae: 0.1002\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 5s 82ms/step - loss: 0.0162 - mae: 0.0930 - val_loss: 0.0198 - val_mae: 0.1068\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0170 - mae: 0.0967 - val_loss: 0.0179 - val_mae: 0.0990\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 5s 81ms/step - loss: 0.0171 - mae: 0.0960 - val_loss: 0.0181 - val_mae: 0.0989\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0163 - mae: 0.0932 - val_loss: 0.0188 - val_mae: 0.1006\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0160 - mae: 0.0929 - val_loss: 0.0180 - val_mae: 0.0991\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0160 - mae: 0.0918 - val_loss: 0.0175 - val_mae: 0.0986\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0159 - mae: 0.0916 - val_loss: 0.0181 - val_mae: 0.0992\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0160 - mae: 0.0924 - val_loss: 0.0181 - val_mae: 0.0983\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0160 - mae: 0.0931 - val_loss: 0.0176 - val_mae: 0.0984\n",
      "Scrittura risultati su file parquet\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.0176 - mae: 0.0984\n",
      "Download dati ticker per previsione\n",
      "27/27 [==============================] - 3s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import fx_com\n",
    "\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "print(\"Download dati ticker\")\n",
    "ticker = yf.download(\"BTG\", start='2010-01-01', end='2019-12-31', progress=False)\n",
    "ticker.index = ticker.index.date\n",
    "#ticker = fx.crea_indicatori(ticker)\n",
    "\n",
    "print(\"Definizione features e target\")\n",
    "features, target = to_ft(ticker, giorni_previsione)\n",
    "n_features = features.shape[1]\n",
    "\n",
    "print(\"Preparazione array X e Y\")\n",
    "def to_XY(features, target, n_timesteps):\n",
    "    i_tot = len(features) - n_timesteps + 1\n",
    "    idx, X, Y = [], [], []\n",
    "    for i in range(i_tot):\n",
    "        idx.append(features.index[i + n_timesteps - 1])\n",
    "        X.append(features.iloc[i:i + n_timesteps])\n",
    "        Y.append(target.iloc[i + n_timesteps - 1])\n",
    "    return idx, np.array(X), np.array(Y)\n",
    "\n",
    "idx, X, Y = to_XY(features, target, n_timesteps)\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization\n",
    "\n",
    "print(\"Creazione modello\")\n",
    "model = crea_modello(n_timesteps, n_features)\n",
    "\n",
    "print(\"Compilazione modello\")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "print(\"Reshape\")\n",
    "n_samples = X.shape[0]\n",
    "X = X.reshape((n_samples, n_timesteps * n_features))\n",
    "\n",
    "X_scaler = clone(scaler)\n",
    "Y_scaler = clone(scaler)\n",
    "X = X_scaler.fit_transform(X)\n",
    "Y = Y_scaler.fit_transform(Y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test, idx_train, idx_test = train_test_split(X, Y, idx, test_size=0.2, random_state=seed)\n",
    "\n",
    "print(\"Reshape ai valori originari\")\n",
    "X_train = X_train.reshape((X_train.shape[0], n_timesteps, n_features))\n",
    "X_test = X_test.reshape((X_test.shape[0], n_timesteps, n_features))\n",
    "\n",
    "print(f\"Addestramento modello epochs={epochs}, batch_size={batch_size}\")\n",
    "model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, Y_test))\n",
    "\n",
    "print(\"Scrittura risultati su file parquet\")\n",
    "import os\n",
    "test_loss, test_mae = model.evaluate(X_test, Y_test)\n",
    "if os.path.exists('metriche.parquet'):\n",
    "    metriche = pd.read_parquet(\"metriche.parquet\")\n",
    "else:\n",
    "    metriche = pd.DataFrame()\n",
    "nuova_riga_metriche = pd.DataFrame([{\n",
    "    \"scaler\": type(scaler).__name__,\n",
    "    \"epochs\": epochs,\n",
    "    \"eatch_size\": batch_size,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"n_timesteps\": n_timesteps,\n",
    "    \"giorni_previsione\": giorni_previsione,\n",
    "    \"seed\": seed,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_mae\": test_mae\n",
    "}])\n",
    "metriche = pd.concat([metriche, nuova_riga_metriche], ignore_index=True)\n",
    "metriche.to_parquet(\"metriche.parquet\")\n",
    "\n",
    "print(\"Download dati ticker per previsione\")\n",
    "dati_previsione = yf.download(\"BTG\", start='2020-01-01', end='2023-12-31', progress=False)\n",
    "\n",
    "features_prev, target_prev = to_ft(dati_previsione, giorni_previsione)\n",
    "idx_prev, X_prev, Y_prev = to_XY(features_prev, target_prev, n_timesteps)\n",
    "\n",
    "X_prev = X_prev.reshape(-1, n_timesteps * n_features)\n",
    "X_scaler_prev = clone(scaler)\n",
    "Y_scaler_prev = clone(scaler)\n",
    "X_prev = X_scaler_prev.fit_transform(X_prev)\n",
    "Y_prev = Y_scaler_prev.fit_transform(Y_prev)\n",
    "X_prev = X_prev.reshape(-1, n_timesteps, n_features)\n",
    "\n",
    "pred = model.predict(X_prev)\n",
    "\n",
    "X_prev = X_prev.reshape(-1, n_timesteps * n_features)\n",
    "X_prev = X_scaler_prev.inverse_transform(X_prev)\n",
    "X_prev = X_prev.reshape(-1, n_timesteps, n_features)\n",
    "\n",
    "Y_prev = Y_scaler_prev.inverse_transform(Y_prev)\n",
    "pred = Y_scaler_prev.inverse_transform(pred)\n",
    "\n",
    "risultato = pd.DataFrame({\"Close\": X_prev[:, n_timesteps-1, 0], \"Target\": Y_prev.reshape(-1), \"Previsione\": pred.reshape(-1).round(2), \"Diff\": (Y_prev.reshape(-1) - pred.reshape(-1)).round(2)}, index=idx_prev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65e43f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "grafico() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfx_com\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fx_com\u001b[38;5;241m.\u001b[39mgrafico(risultato)\n",
      "\u001b[1;31mTypeError\u001b[0m: grafico() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "fx_com.grafico(risultato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4799b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaler</th>\n",
       "      <th>epochs</th>\n",
       "      <th>eatch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_timesteps</th>\n",
       "      <th>giorni_previsione</th>\n",
       "      <th>seed</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.019046</td>\n",
       "      <td>0.103922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.019723</td>\n",
       "      <td>0.098877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PowerTransformer</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.017568</td>\n",
       "      <td>0.098379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scaler  epochs  eatch_size  learning_rate  n_timesteps  \\\n",
       "0  PowerTransformer      50          32          0.001           30   \n",
       "1  PowerTransformer      50          32          0.001           60   \n",
       "2  PowerTransformer      50          32          0.001           90   \n",
       "\n",
       "   giorni_previsione  seed  test_loss  test_mae  \n",
       "0                  1    10   0.019046  0.103922  \n",
       "1                  1    10   0.019723  0.098877  \n",
       "2                  1    10   0.017568  0.098379  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad8fe5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
